2019-09-13 05:21:27,981 - Number of CPUs: 128
2019-09-13 05:21:28,048 - Number of GPUs: 4
2019-09-13 05:21:28,048 - CUDA version: 9.2.148
2019-09-13 05:21:28,054 - CUDNN version: 7301
2019-09-13 05:21:28,054 - Kernel: 4.14.0-115.6.1.el7a.ppc64le
2019-09-13 05:21:28,054 - Python: 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:34:02) 
[GCC 7.3.0]
2019-09-13 05:21:28,055 - PyTorch: 0.4.1
2019-09-13 05:21:28,055 - Numpy: 1.14.5
2019-09-13 05:21:28,055 - Cannot find a Git repository.  You probably downloaded an archive of Distiller.
2019-09-13 05:21:28,055 - App args: ['compress_classifier.py', '-a', 'resnet18', '--lr', '0.001', '-b', '256', '-p', '50', '/home/mdl/mzk591/dataset/data.imagenet', '-j', '16', '--epochs', '10', '--vs', '0', '--gpus', '0,1', '--pretrained', '--compress=../quant_YAML/imagenet/res18_8b.yaml', '-o', '8b_logs', '-n', 'res18']
2019-09-13 05:21:28,056 - ==> using imagenet dataset
2019-09-13 05:21:28,056 - => using pretrained resnet18 model for ImageNet
2019-09-13 05:21:31,292 - Optimizer Type: <class 'torch.optim.sgd.SGD'>
2019-09-13 05:21:31,297 - Optimizer Args: {'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0.0001, 'nesterov': False}
2019-09-13 05:21:44,469 - Dataset sizes:
	training=1281167
	validation=50000
	test=50000
2019-09-13 05:21:44,471 - Reading compression schedule from: ../quant_YAML/imagenet/res18_8b.yaml
2019-09-13 05:21:44,479 - Schedule contents:
{
  "quantizers": {
    "pact_quantizer": {
      "class": "PACTQuantizer",
      "bits_activations": 8,
      "bits_weights": 8,
      "bits_overrides": {
        "conv1": {
          "wts": 8,
          "acts": 8
        },
        "fc": {
          "wts": 8,
          "acts": 8
        }
      }
    }
  },
  "lr_schedulers": {
    "training_lr": {
      "class": "StepLR",
      "step_size": 2,
      "gamma": 0.89
    }
  },
  "policies": [
    {
      "quantizer": {
        "instance_name": "pact_quantizer"
      },
      "starting_epoch": 0,
      "ending_epoch": 800,
      "frequency": 1
    },
    {
      "lr_scheduler": {
        "instance_name": "training_lr"
      },
      "starting_epoch": 0,
      "ending_epoch": 800,
      "frequency": 1
    }
  ]
}
2019-09-13 05:21:44,483 - Preparing model for quantization using PACTQuantizer
2019-09-13 05:21:44,486 - Parameter 'module.conv1.weight' will be quantized to 8 bits
2019-09-13 05:21:44,486 - Parameter 'module.layer1.0.conv1.weight' will be quantized to 8 bits
2019-09-13 05:21:44,486 - Parameter 'module.layer1.0.conv2.weight' will be quantized to 8 bits
2019-09-13 05:21:44,486 - Parameter 'module.layer1.1.conv1.weight' will be quantized to 8 bits
2019-09-13 05:21:44,486 - Parameter 'module.layer1.1.conv2.weight' will be quantized to 8 bits
2019-09-13 05:21:44,486 - Parameter 'module.layer2.0.conv1.weight' will be quantized to 8 bits
2019-09-13 05:21:44,488 - Parameter 'module.layer2.0.conv2.weight' will be quantized to 8 bits
2019-09-13 05:21:44,488 - Parameter 'module.layer2.0.downsample.0.weight' will be quantized to 8 bits
2019-09-13 05:21:44,488 - Parameter 'module.layer2.1.conv1.weight' will be quantized to 8 bits
2019-09-13 05:21:44,489 - Parameter 'module.layer2.1.conv2.weight' will be quantized to 8 bits
2019-09-13 05:21:44,489 - Parameter 'module.layer3.0.conv1.weight' will be quantized to 8 bits
2019-09-13 05:21:44,492 - Parameter 'module.layer3.0.conv2.weight' will be quantized to 8 bits
2019-09-13 05:21:44,492 - Parameter 'module.layer3.0.downsample.0.weight' will be quantized to 8 bits
2019-09-13 05:21:44,493 - Parameter 'module.layer3.1.conv1.weight' will be quantized to 8 bits
2019-09-13 05:21:44,494 - Parameter 'module.layer3.1.conv2.weight' will be quantized to 8 bits
2019-09-13 05:21:44,494 - Parameter 'module.layer4.0.conv1.weight' will be quantized to 8 bits
2019-09-13 05:21:44,496 - Parameter 'module.layer4.0.conv2.weight' will be quantized to 8 bits
2019-09-13 05:21:44,497 - Parameter 'module.layer4.0.downsample.0.weight' will be quantized to 8 bits
2019-09-13 05:21:44,497 - Parameter 'module.layer4.1.conv1.weight' will be quantized to 8 bits
2019-09-13 05:21:44,498 - Parameter 'module.layer4.1.conv2.weight' will be quantized to 8 bits
2019-09-13 05:21:44,498 - Parameter 'module.fc.weight' will be quantized to 8 bits
2019-09-13 05:21:44,501 - Quantized model:

DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): LearnedClippedLinearQuantization(num_bits=8, clip_val=8.0, inplace)
      )
    )
    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)
    (fc): Linear(in_features=512, out_features=1000, bias=True)
  )
)

2019-09-13 05:21:44,552 - Writing Clip Parameter Value... ... ... ...
2019-09-13 05:21:44,559 - 

2019-09-13 05:21:44,559 - +--------------------------------+--------------+
| Layers                         |   PACT_alpha |
|--------------------------------+--------------|
| module.relu.clip_val           |            8 |
| module.layer1.0.relu1.clip_val |            8 |
| module.layer1.0.relu2.clip_val |            8 |
| module.layer1.1.relu1.clip_val |            8 |
| module.layer1.1.relu2.clip_val |            8 |
| module.layer2.0.relu1.clip_val |            8 |
| module.layer2.0.relu2.clip_val |            8 |
| module.layer2.1.relu1.clip_val |            8 |
| module.layer2.1.relu2.clip_val |            8 |
| module.layer3.0.relu1.clip_val |            8 |
| module.layer3.0.relu2.clip_val |            8 |
| module.layer3.1.relu1.clip_val |            8 |
| module.layer3.1.relu2.clip_val |            8 |
| module.layer4.0.relu1.clip_val |            8 |
| module.layer4.0.relu2.clip_val |            8 |
| module.layer4.1.relu1.clip_val |            8 |
| module.layer4.1.relu2.clip_val |            8 |
+--------------------------------+--------------+
2019-09-13 05:21:44,559 - 

2019-09-13 05:21:44,560 - Training epoch: 1281167 samples (256 per mini-batch)
2019-09-13 05:22:02,314 - Epoch: [0][   50/ 5005]    Overall Loss 1.433731    Objective Loss 1.433731    Top1 68.281250    Top5 86.710938    LR 0.001000    Time 0.354918    
2019-09-13 05:22:11,286 - Epoch: [0][  100/ 5005]    Overall Loss 1.423597    Objective Loss 1.423597    Top1 68.093750    Top5 86.605469    LR 0.001000    Time 0.267142    
2019-09-13 05:22:20,847 - Epoch: [0][  150/ 5005]    Overall Loss 1.392470    Objective Loss 1.392470    Top1 68.286458    Top5 86.830729    LR 0.001000    Time 0.241811    
2019-09-13 05:22:30,143 - Epoch: [0][  200/ 5005]    Overall Loss 1.391254    Objective Loss 1.391254    Top1 68.183594    Top5 86.777344    LR 0.001000    Time 0.227809    
2019-09-13 05:22:39,224 - Epoch: [0][  250/ 5005]    Overall Loss 1.382932    Objective Loss 1.382932    Top1 68.207813    Top5 86.785938    LR 0.001000    Time 0.218557    
2019-09-13 05:22:48,340 - Epoch: [0][  300/ 5005]    Overall Loss 1.376024    Objective Loss 1.376024    Top1 68.213542    Top5 86.848958    LR 0.001000    Time 0.212506    
2019-09-13 05:22:57,390 - Epoch: [0][  350/ 5005]    Overall Loss 1.371019    Objective Loss 1.371019    Top1 68.158482    Top5 86.886161    LR 0.001000    Time 0.207995    
2019-09-13 05:23:06,380 - Epoch: [0][  400/ 5005]    Overall Loss 1.364902    Objective Loss 1.364902    Top1 68.228516    Top5 86.897461    LR 0.001000    Time 0.204464    
2019-09-13 05:23:15,325 - Epoch: [0][  450/ 5005]    Overall Loss 1.362243    Objective Loss 1.362243    Top1 68.278646    Top5 86.868056    LR 0.001000    Time 0.201615    
2019-09-13 05:23:24,282 - Epoch: [0][  500/ 5005]    Overall Loss 1.362474    Objective Loss 1.362474    Top1 68.247656    Top5 86.818750    LR 0.001000    Time 0.199363    
2019-09-13 05:23:33,242 - Epoch: [0][  550/ 5005]    Overall Loss 1.363785    Objective Loss 1.363785    Top1 68.191051    Top5 86.757102    LR 0.001000    Time 0.197523    
2019-09-13 05:23:42,496 - Epoch: [0][  600/ 5005]    Overall Loss 1.358966    Objective Loss 1.358966    Top1 68.213542    Top5 86.798177    LR 0.001000    Time 0.196480    
2019-09-13 05:23:51,532 - Epoch: [0][  650/ 5005]    Overall Loss 1.357713    Objective Loss 1.357713    Top1 68.169471    Top5 86.792668    LR 0.001000    Time 0.195264    
2019-09-13 05:24:00,559 - Epoch: [0][  700/ 5005]    Overall Loss 1.356732    Objective Loss 1.356732    Top1 68.172433    Top5 86.815848    LR 0.001000    Time 0.194207    
2019-09-13 05:24:09,626 - Epoch: [0][  750/ 5005]    Overall Loss 1.355899    Objective Loss 1.355899    Top1 68.207292    Top5 86.815625    LR 0.001000    Time 0.193345    
2019-09-13 05:24:18,842 - Epoch: [0][  800/ 5005]    Overall Loss 1.353210    Objective Loss 1.353210    Top1 68.212891    Top5 86.843750    LR 0.000999    Time 0.192777    
2019-09-13 05:24:27,862 - Epoch: [0][  850/ 5005]    Overall Loss 1.353948    Objective Loss 1.353948    Top1 68.198529    Top5 86.822151    LR 0.000999    Time 0.192045    
2019-09-13 05:24:36,891 - Epoch: [0][  900/ 5005]    Overall Loss 1.351422    Objective Loss 1.351422    Top1 68.226128    Top5 86.871094    LR 0.000999    Time 0.191405    
2019-09-13 05:24:46,077 - Epoch: [0][  950/ 5005]    Overall Loss 1.349869    Objective Loss 1.349869    Top1 68.236842    Top5 86.875411    LR 0.000999    Time 0.190997    
2019-09-13 05:24:55,179 - Epoch: [0][ 1000/ 5005]    Overall Loss 1.348161    Objective Loss 1.348161    Top1 68.277734    Top5 86.883984    LR 0.000999    Time 0.190546    
2019-09-13 05:25:04,516 - Epoch: [0][ 1050/ 5005]    Overall Loss 1.348197    Objective Loss 1.348197    Top1 68.281994    Top5 86.872768    LR 0.000999    Time 0.190362    
2019-09-13 05:25:13,479 - Epoch: [0][ 1100/ 5005]    Overall Loss 1.347638    Objective Loss 1.347638    Top1 68.291193    Top5 86.884233    LR 0.000999    Time 0.189854    
2019-09-13 05:25:22,464 - Epoch: [0][ 1150/ 5005]    Overall Loss 1.346477    Objective Loss 1.346477    Top1 68.300272    Top5 86.902514    LR 0.000999    Time 0.189410    
2019-09-13 05:25:31,512 - Epoch: [0][ 1200/ 5005]    Overall Loss 1.345473    Objective Loss 1.345473    Top1 68.314453    Top5 86.906901    LR 0.000999    Time 0.189056    
2019-09-13 05:25:40,490 - Epoch: [0][ 1250/ 5005]    Overall Loss 1.345507    Objective Loss 1.345507    Top1 68.326875    Top5 86.890625    LR 0.000999    Time 0.188673    
2019-09-13 05:25:49,485 - Epoch: [0][ 1300/ 5005]    Overall Loss 1.343730    Objective Loss 1.343730    Top1 68.354267    Top5 86.909856    LR 0.000999    Time 0.188332    
2019-09-13 05:25:58,617 - Epoch: [0][ 1350/ 5005]    Overall Loss 1.343012    Objective Loss 1.343012    Top1 68.364583    Top5 86.902778    LR 0.000998    Time 0.188118    
2019-09-13 05:26:07,663 - Epoch: [0][ 1400/ 5005]    Overall Loss 1.341775    Objective Loss 1.341775    Top1 68.396484    Top5 86.908203    LR 0.000998    Time 0.187859    
2019-09-13 05:26:16,712 - Epoch: [0][ 1450/ 5005]    Overall Loss 1.341851    Objective Loss 1.341851    Top1 68.394127    Top5 86.901940    LR 0.000998    Time 0.187620    
2019-09-13 05:26:25,888 - Epoch: [0][ 1500/ 5005]    Overall Loss 1.342324    Objective Loss 1.342324    Top1 68.374479    Top5 86.895313    LR 0.000998    Time 0.187481    
2019-09-13 05:26:34,978 - Epoch: [0][ 1550/ 5005]    Overall Loss 1.342273    Objective Loss 1.342273    Top1 68.376260    Top5 86.889617    LR 0.000998    Time 0.187296    
2019-09-13 05:26:43,870 - Epoch: [0][ 1600/ 5005]    Overall Loss 1.341991    Objective Loss 1.341991    Top1 68.373535    Top5 86.896484    LR 0.000998    Time 0.186998    
2019-09-13 05:26:52,735 - Epoch: [0][ 1650/ 5005]    Overall Loss 1.341966    Objective Loss 1.341966    Top1 68.371922    Top5 86.893703    LR 0.000998    Time 0.186701    
2019-09-13 05:27:01,794 - Epoch: [0][ 1700/ 5005]    Overall Loss 1.341313    Objective Loss 1.341313    Top1 68.391314    Top5 86.901195    LR 0.000997    Time 0.186537    
2019-09-13 05:27:10,804 - Epoch: [0][ 1750/ 5005]    Overall Loss 1.342086    Objective Loss 1.342086    Top1 68.383705    Top5 86.886607    LR 0.000997    Time 0.186353    
2019-09-13 05:27:19,885 - Epoch: [0][ 1800/ 5005]    Overall Loss 1.342198    Objective Loss 1.342198    Top1 68.382812    Top5 86.888889    LR 0.000997    Time 0.186220    
2019-09-13 05:27:28,780 - Epoch: [0][ 1850/ 5005]    Overall Loss 1.341746    Objective Loss 1.341746    Top1 68.384713    Top5 86.887247    LR 0.000997    Time 0.185994    
2019-09-13 05:27:37,668 - Epoch: [0][ 1900/ 5005]    Overall Loss 1.341728    Objective Loss 1.341728    Top1 68.375411    Top5 86.883018    LR 0.000997    Time 0.185775    
2019-09-13 05:27:46,875 - Epoch: [0][ 1950/ 5005]    Overall Loss 1.341064    Objective Loss 1.341064    Top1 68.384014    Top5 86.891827    LR 0.000997    Time 0.185731    
2019-09-13 05:27:55,768 - Epoch: [0][ 2000/ 5005]    Overall Loss 1.341188    Objective Loss 1.341188    Top1 68.385937    Top5 86.884570    LR 0.000996    Time 0.185532    
2019-09-13 05:28:04,726 - Epoch: [0][ 2050/ 5005]    Overall Loss 1.340930    Objective Loss 1.340930    Top1 68.386052    Top5 86.894436    LR 0.000996    Time 0.185374    
2019-09-13 05:28:13,658 - Epoch: [0][ 2100/ 5005]    Overall Loss 1.340250    Objective Loss 1.340250    Top1 68.391741    Top5 86.910156    LR 0.000996    Time 0.185212    
2019-09-13 05:28:22,632 - Epoch: [0][ 2150/ 5005]    Overall Loss 1.340254    Objective Loss 1.340254    Top1 68.401344    Top5 86.918605    LR 0.000996    Time 0.185077    
2019-09-13 05:28:31,655 - Epoch: [0][ 2200/ 5005]    Overall Loss 1.340163    Objective Loss 1.340163    Top1 68.398260    Top5 86.917614    LR 0.000996    Time 0.184971    
2019-09-13 05:28:40,616 - Epoch: [0][ 2250/ 5005]    Overall Loss 1.339998    Objective Loss 1.339998    Top1 68.395486    Top5 86.914583    LR 0.000996    Time 0.184841    
2019-09-13 05:28:49,534 - Epoch: [0][ 2300/ 5005]    Overall Loss 1.339988    Objective Loss 1.339988    Top1 68.392323    Top5 86.910326    LR 0.000995    Time 0.184699    
2019-09-13 05:28:58,562 - Epoch: [0][ 2350/ 5005]    Overall Loss 1.339563    Objective Loss 1.339563    Top1 68.396609    Top5 86.910406    LR 0.000995    Time 0.184609    
2019-09-13 05:29:07,697 - Epoch: [0][ 2400/ 5005]    Overall Loss 1.339763    Objective Loss 1.339763    Top1 68.391276    Top5 86.903971    LR 0.000995    Time 0.184567    
2019-09-13 05:29:16,678 - Epoch: [0][ 2450/ 5005]    Overall Loss 1.339201    Objective Loss 1.339201    Top1 68.396205    Top5 86.904656    LR 0.000995    Time 0.184465    
2019-09-13 05:29:25,624 - Epoch: [0][ 2500/ 5005]    Overall Loss 1.338324    Objective Loss 1.338324    Top1 68.411719    Top5 86.912188    LR 0.000994    Time 0.184352    
2019-09-13 05:29:34,536 - Epoch: [0][ 2550/ 5005]    Overall Loss 1.338148    Objective Loss 1.338148    Top1 68.408701    Top5 86.910080    LR 0.000994    Time 0.184231    
2019-09-13 05:29:43,673 - Epoch: [0][ 2600/ 5005]    Overall Loss 1.338265    Objective Loss 1.338265    Top1 68.397686    Top5 86.908353    LR 0.000994    Time 0.184201    
2019-09-13 05:29:52,645 - Epoch: [0][ 2650/ 5005]    Overall Loss 1.338196    Objective Loss 1.338196    Top1 68.394015    Top5 86.907282    LR 0.000994    Time 0.184110    
2019-09-13 05:30:01,628 - Epoch: [0][ 2700/ 5005]    Overall Loss 1.337781    Objective Loss 1.337781    Top1 68.399161    Top5 86.918403    LR 0.000994    Time 0.184025    
2019-09-13 05:30:10,552 - Epoch: [0][ 2750/ 5005]    Overall Loss 1.337948    Objective Loss 1.337948    Top1 68.389347    Top5 86.912642    LR 0.000993    Time 0.183923    
2019-09-13 05:30:19,498 - Epoch: [0][ 2800/ 5005]    Overall Loss 1.337440    Objective Loss 1.337440    Top1 68.393834    Top5 86.916016    LR 0.000993    Time 0.183832    
2019-09-13 05:30:28,635 - Epoch: [0][ 2850/ 5005]    Overall Loss 1.337031    Objective Loss 1.337031    Top1 68.402549    Top5 86.918723    LR 0.000993    Time 0.183812    
2019-09-13 05:30:37,562 - Epoch: [0][ 2900/ 5005]    Overall Loss 1.337231    Objective Loss 1.337231    Top1 68.401401    Top5 86.916218    LR 0.000993    Time 0.183720    
2019-09-13 05:30:46,422 - Epoch: [0][ 2950/ 5005]    Overall Loss 1.336948    Objective Loss 1.336948    Top1 68.407177    Top5 86.915122    LR 0.000992    Time 0.183608    
2019-09-13 05:30:55,311 - Epoch: [0][ 3000/ 5005]    Overall Loss 1.337328    Objective Loss 1.337328    Top1 68.403385    Top5 86.908073    LR 0.000992    Time 0.183510    
2019-09-13 05:31:04,327 - Epoch: [0][ 3050/ 5005]    Overall Loss 1.336757    Objective Loss 1.336757    Top1 68.418161    Top5 86.914575    LR 0.000992    Time 0.183456    
2019-09-13 05:31:13,343 - Epoch: [0][ 3100/ 5005]    Overall Loss 1.336910    Objective Loss 1.336910    Top1 68.412676    Top5 86.908392    LR 0.000992    Time 0.183404    
2019-09-13 05:31:22,374 - Epoch: [0][ 3150/ 5005]    Overall Loss 1.336616    Objective Loss 1.336616    Top1 68.415675    Top5 86.911830    LR 0.000991    Time 0.183359    
2019-09-13 05:31:31,409 - Epoch: [0][ 3200/ 5005]    Overall Loss 1.336244    Objective Loss 1.336244    Top1 68.425293    Top5 86.916870    LR 0.000991    Time 0.183316    
2019-09-13 05:31:40,386 - Epoch: [0][ 3250/ 5005]    Overall Loss 1.336497    Objective Loss 1.336497    Top1 68.418389    Top5 86.912740    LR 0.000991    Time 0.183257    
2019-09-13 05:31:49,355 - Epoch: [0][ 3300/ 5005]    Overall Loss 1.335966    Objective Loss 1.335966    Top1 68.429806    Top5 86.917259    LR 0.000990    Time 0.183197    
2019-09-13 05:31:58,514 - Epoch: [0][ 3350/ 5005]    Overall Loss 1.335925    Objective Loss 1.335925    Top1 68.418610    Top5 86.915695    LR 0.000990    Time 0.183195    
2019-09-13 05:32:07,425 - Epoch: [0][ 3400/ 5005]    Overall Loss 1.335771    Objective Loss 1.335771    Top1 68.422105    Top5 86.916245    LR 0.000990    Time 0.183121    
2019-09-13 05:32:16,440 - Epoch: [0][ 3450/ 5005]    Overall Loss 1.335978    Objective Loss 1.335978    Top1 68.417346    Top5 86.912024    LR 0.000989    Time 0.183079    
2019-09-13 05:32:25,489 - Epoch: [0][ 3500/ 5005]    Overall Loss 1.335920    Objective Loss 1.335920    Top1 68.423661    Top5 86.912277    LR 0.000989    Time 0.183048    
2019-09-13 05:32:34,559 - Epoch: [0][ 3550/ 5005]    Overall Loss 1.336183    Objective Loss 1.336183    Top1 68.424076    Top5 86.905040    LR 0.000989    Time 0.183024    
2019-09-13 05:32:43,621 - Epoch: [0][ 3600/ 5005]    Overall Loss 1.335555    Objective Loss 1.335555    Top1 68.430013    Top5 86.910265    LR 0.000989    Time 0.182998    
2019-09-13 05:32:52,610 - Epoch: [0][ 3650/ 5005]    Overall Loss 1.335472    Objective Loss 1.335472    Top1 68.433112    Top5 86.906678    LR 0.000988    Time 0.182953    
2019-09-13 05:33:01,507 - Epoch: [0][ 3700/ 5005]    Overall Loss 1.335286    Objective Loss 1.335286    Top1 68.438556    Top5 86.903188    LR 0.000988    Time 0.182884    
2019-09-13 05:33:10,464 - Epoch: [0][ 3750/ 5005]    Overall Loss 1.335392    Objective Loss 1.335392    Top1 68.428229    Top5 86.897604    LR 0.000988    Time 0.182833    
2019-09-13 05:33:19,576 - Epoch: [0][ 3800/ 5005]    Overall Loss 1.334982    Objective Loss 1.334982    Top1 68.436780    Top5 86.906456    LR 0.000987    Time 0.182824    
2019-09-13 05:33:28,590 - Epoch: [0][ 3850/ 5005]    Overall Loss 1.334567    Objective Loss 1.334567    Top1 68.445312    Top5 86.912236    LR 0.000987    Time 0.182791    
2019-09-13 05:33:37,635 - Epoch: [0][ 3900/ 5005]    Overall Loss 1.334581    Objective Loss 1.334581    Top1 68.444611    Top5 86.910657    LR 0.000987    Time 0.182765    
2019-09-13 05:33:46,593 - Epoch: [0][ 3950/ 5005]    Overall Loss 1.334377    Objective Loss 1.334377    Top1 68.446796    Top5 86.914260    LR 0.000986    Time 0.182719    
2019-09-13 05:33:55,655 - Epoch: [0][ 4000/ 5005]    Overall Loss 1.334454    Objective Loss 1.334454    Top1 68.449121    Top5 86.911426    LR 0.000986    Time 0.182700    
2019-09-13 05:34:04,641 - Epoch: [0][ 4050/ 5005]    Overall Loss 1.334630    Objective Loss 1.334630    Top1 68.440586    Top5 86.904803    LR 0.000986    Time 0.182662    
2019-09-13 05:34:13,723 - Epoch: [0][ 4100/ 5005]    Overall Loss 1.334754    Objective Loss 1.334754    Top1 68.437786    Top5 86.902725    LR 0.000985    Time 0.182649    
2019-09-13 05:34:22,778 - Epoch: [0][ 4150/ 5005]    Overall Loss 1.334799    Objective Loss 1.334799    Top1 68.440512    Top5 86.901073    LR 0.000985    Time 0.182629    
2019-09-13 05:34:31,899 - Epoch: [0][ 4200/ 5005]    Overall Loss 1.334822    Objective Loss 1.334822    Top1 68.446150    Top5 86.898531    LR 0.000984    Time 0.182626    
2019-09-13 05:34:41,124 - Epoch: [0][ 4250/ 5005]    Overall Loss 1.335010    Objective Loss 1.335010    Top1 68.445496    Top5 86.897059    LR 0.000984    Time 0.182647    
2019-09-13 05:34:50,234 - Epoch: [0][ 4300/ 5005]    Overall Loss 1.335087    Objective Loss 1.335087    Top1 68.446857    Top5 86.895985    LR 0.000984    Time 0.182641    
2019-09-13 05:34:59,395 - Epoch: [0][ 4350/ 5005]    Overall Loss 1.334648    Objective Loss 1.334648    Top1 68.459860    Top5 86.899605    LR 0.000983    Time 0.182647    
2019-09-13 05:35:08,430 - Epoch: [0][ 4400/ 5005]    Overall Loss 1.334828    Objective Loss 1.334828    Top1 68.454457    Top5 86.896129    LR 0.000983    Time 0.182624    
2019-09-13 05:35:17,466 - Epoch: [0][ 4450/ 5005]    Overall Loss 1.334768    Objective Loss 1.334768    Top1 68.453827    Top5 86.896857    LR 0.000983    Time 0.182602    
2019-09-13 05:35:26,511 - Epoch: [0][ 4500/ 5005]    Overall Loss 1.335176    Objective Loss 1.335176    Top1 68.446875    Top5 86.892622    LR 0.000982    Time 0.182582    
2019-09-13 05:35:35,574 - Epoch: [0][ 4550/ 5005]    Overall Loss 1.335240    Objective Loss 1.335240    Top1 68.444111    Top5 86.894231    LR 0.000982    Time 0.182567    
2019-09-13 05:35:44,640 - Epoch: [0][ 4600/ 5005]    Overall Loss 1.335350    Objective Loss 1.335350    Top1 68.445907    Top5 86.890540    LR 0.000981    Time 0.182553    
2019-09-13 05:35:53,668 - Epoch: [0][ 4650/ 5005]    Overall Loss 1.335315    Objective Loss 1.335315    Top1 68.448925    Top5 86.890205    LR 0.000981    Time 0.182530    
2019-09-13 05:36:02,835 - Epoch: [0][ 4700/ 5005]    Overall Loss 1.334979    Objective Loss 1.334979    Top1 68.453291    Top5 86.889794    LR 0.000981    Time 0.182538    
2019-09-13 05:36:11,841 - Epoch: [0][ 4750/ 5005]    Overall Loss 1.334913    Objective Loss 1.334913    Top1 68.455757    Top5 86.887747    LR 0.000980    Time 0.182512    
2019-09-13 05:36:20,864 - Epoch: [0][ 4800/ 5005]    Overall Loss 1.334887    Objective Loss 1.334887    Top1 68.452474    Top5 86.883708    LR 0.000980    Time 0.182490    
2019-09-13 05:36:29,907 - Epoch: [0][ 4850/ 5005]    Overall Loss 1.334884    Objective Loss 1.334884    Top1 68.448937    Top5 86.882974    LR 0.000979    Time 0.182473    
2019-09-13 05:36:39,059 - Epoch: [0][ 4900/ 5005]    Overall Loss 1.334873    Objective Loss 1.334873    Top1 68.447624    Top5 86.884247    LR 0.000979    Time 0.182478    
2019-09-13 05:36:48,059 - Epoch: [0][ 4950/ 5005]    Overall Loss 1.334859    Objective Loss 1.334859    Top1 68.443182    Top5 86.883444    LR 0.000978    Time 0.182452    
2019-09-13 05:36:56,956 - Epoch: [0][ 5000/ 5005]    Overall Loss 1.335043    Objective Loss 1.335043    Top1 68.440391    Top5 86.883437    LR 0.000978    Time 0.182406    
2019-09-13 05:36:58,768 - 
Parameters:
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                      | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.float_weight                 | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12914 |  0.00005 |    0.07574 |
|  1 | module.conv1.weight                       | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16045 |  0.00015 |    0.09717 |
|  2 | module.layer1.0.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05317 | -0.00312 |    0.03149 |
|  3 | module.layer1.0.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07918 | -0.00432 |    0.04802 |
|  4 | module.layer1.0.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04501 | -0.00092 |    0.03187 |
|  5 | module.layer1.0.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09990 | -0.00202 |    0.07098 |
|  6 | module.layer1.1.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05062 | -0.00237 |    0.03412 |
|  7 | module.layer1.1.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08813 | -0.00416 |    0.05997 |
|  8 | module.layer1.1.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04379 | -0.00124 |    0.03137 |
|  9 | module.layer1.1.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12155 | -0.00345 |    0.08732 |
| 10 | module.layer2.0.conv1.float_weight        | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04141 | -0.00142 |    0.02928 |
| 11 | module.layer2.0.conv1.weight              | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12791 | -0.00441 |    0.09067 |
| 12 | module.layer2.0.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03387 | -0.00124 |    0.02384 |
| 13 | module.layer2.0.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08505 | -0.00315 |    0.06005 |
| 14 | module.layer2.0.downsample.0.float_weight | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07031 | -0.00260 |    0.04418 |
| 15 | module.layer2.0.downsample.0.weight       | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10545 | -0.00393 |    0.06735 |
| 16 | module.layer2.1.conv1.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03403 | -0.00150 |    0.02415 |
| 17 | module.layer2.1.conv1.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08303 | -0.00368 |    0.05911 |
| 18 | module.layer2.1.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02992 | -0.00127 |    0.02215 |
| 19 | module.layer2.1.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08900 | -0.00378 |    0.06599 |
| 20 | module.layer3.0.conv1.float_weight        | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02892 | -0.00135 |    0.02084 |
| 21 | module.layer3.0.conv1.weight              | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07920 | -0.00371 |    0.05721 |
| 22 | module.layer3.0.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02494 | -0.00078 |    0.01827 |
| 23 | module.layer3.0.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08009 | -0.00250 |    0.05878 |
| 24 | module.layer3.0.downsample.0.float_weight | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03280 | -0.00186 |    0.02367 |
| 25 | module.layer3.0.downsample.0.weight       | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12591 | -0.00718 |    0.09104 |
| 26 | module.layer3.1.conv1.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02227 | -0.00165 |    0.01658 |
| 27 | module.layer3.1.conv1.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07913 | -0.00587 |    0.05898 |
| 28 | module.layer3.1.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02058 | -0.00143 |    0.01546 |
| 29 | module.layer3.1.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06616 | -0.00458 |    0.04975 |
| 30 | module.layer4.0.conv1.float_weight        | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01979 | -0.00155 |    0.01515 |
| 31 | module.layer4.0.conv1.weight              | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05709 | -0.00447 |    0.04376 |
| 32 | module.layer4.0.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01725 | -0.00130 |    0.01333 |
| 33 | module.layer4.0.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05421 | -0.00408 |    0.04193 |
| 34 | module.layer4.0.downsample.0.float_weight | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03264 | -0.00084 |    0.02377 |
| 35 | module.layer4.0.downsample.0.weight       | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05180 | -0.00133 |    0.03788 |
| 36 | module.layer4.1.conv1.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01775 | -0.00225 |    0.01397 |
| 37 | module.layer4.1.conv1.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07127 | -0.00902 |    0.05614 |
| 38 | module.layer4.1.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01314 | -0.00009 |    0.01004 |
| 39 | module.layer4.1.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05167 | -0.00037 |    0.03954 |
| 40 | module.fc.float_weight                    | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06911 |  0.00000 |    0.05068 |
| 41 | module.fc.weight                          | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08446 | -0.00019 |    0.06233 |
| 42 | Total sparsity:                           | -                |      23357824 |       23357824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2019-09-13 05:36:58,768 - Total sparsity: 0.00

2019-09-13 05:36:58,768 - --- validate (epoch=0)-----------
2019-09-13 05:36:58,768 - 50000 samples (256 per mini-batch)
2019-09-13 05:37:10,047 - Epoch: [0][   50/  195]    Loss 0.937864    Top1 75.757812    Top5 92.914062    
2019-09-13 05:37:18,150 - Epoch: [0][  100/  195]    Loss 1.068202    Top1 73.355469    Top5 91.503906    
2019-09-13 05:37:25,780 - Epoch: [0][  150/  195]    Loss 1.208478    Top1 70.617188    Top5 89.565104    
2019-09-13 05:37:33,482 - ==> Top1: 69.512    Top5: 88.940    Loss: 1.268

2019-09-13 05:37:33,491 - ==> Best Top1: 69.512 on Epoch: 0
2019-09-13 05:37:33,491 - Saving checkpoint to: 8b_logs/res18___2019.09.13-052127/res18_checkpoint.pth.tar
2019-09-13 05:37:40,357 - Saving PACT param_value.......
2019-09-13 05:37:40,358 - The PACT Clip Parameter Value............
2019-09-13 05:37:40,363 - 

2019-09-13 05:37:40,363 - +--------------------------------+--------------+
| Layers                         |   PACT_alpha |
|--------------------------------+--------------|
| module.relu.clip_val           |      7.96006 |
| module.layer1.0.relu1.clip_val |      7.96008 |
| module.layer1.0.relu2.clip_val |      7.96008 |
| module.layer1.1.relu1.clip_val |      7.96008 |
| module.layer1.1.relu2.clip_val |      7.96009 |
| module.layer2.0.relu1.clip_val |      7.96008 |
| module.layer2.0.relu2.clip_val |      7.96012 |
| module.layer2.1.relu1.clip_val |      7.96008 |
| module.layer2.1.relu2.clip_val |      7.96014 |
| module.layer3.0.relu1.clip_val |      7.96008 |
| module.layer3.0.relu2.clip_val |      7.96008 |
| module.layer3.1.relu1.clip_val |      7.96008 |
| module.layer3.1.relu2.clip_val |      7.96014 |
| module.layer4.0.relu1.clip_val |      7.96008 |
| module.layer4.0.relu2.clip_val |      7.96022 |
| module.layer4.1.relu1.clip_val |      7.96008 |
| module.layer4.1.relu2.clip_val |      8.01718 |
+--------------------------------+--------------+
2019-09-13 05:37:40,366 - 

2019-09-13 05:37:40,367 - Training epoch: 1281167 samples (256 per mini-batch)
2019-09-13 05:37:53,309 - Epoch: [1][   50/ 5005]    Overall Loss 1.298855    Objective Loss 1.298855    Top1 68.890625    Top5 87.156250    LR 0.000978    Time 0.258748    
2019-09-13 05:38:02,465 - Epoch: [1][  100/ 5005]    Overall Loss 1.309808    Objective Loss 1.309808    Top1 69.011719    Top5 87.027344    LR 0.000977    Time 0.220899    
2019-09-13 05:38:11,435 - Epoch: [1][  150/ 5005]    Overall Loss 1.307472    Objective Loss 1.307472    Top1 68.927083    Top5 87.143229    LR 0.000977    Time 0.207041    
2019-09-13 05:38:20,458 - Epoch: [1][  200/ 5005]    Overall Loss 1.311964    Objective Loss 1.311964    Top1 68.814453    Top5 87.136719    LR 0.000976    Time 0.200379    
2019-09-13 05:38:29,443 - Epoch: [1][  250/ 5005]    Overall Loss 1.310770    Objective Loss 1.310770    Top1 68.731250    Top5 87.067188    LR 0.000976    Time 0.196232    
2019-09-13 05:38:38,499 - Epoch: [1][  300/ 5005]    Overall Loss 1.310157    Objective Loss 1.310157    Top1 68.759115    Top5 87.102865    LR 0.000975    Time 0.193698    
2019-09-13 05:38:47,578 - Epoch: [1][  350/ 5005]    Overall Loss 1.311557    Objective Loss 1.311557    Top1 68.679688    Top5 87.128348    LR 0.000975    Time 0.191959    
2019-09-13 05:38:56,750 - Epoch: [1][  400/ 5005]    Overall Loss 1.314870    Objective Loss 1.314870    Top1 68.668945    Top5 87.074219    LR 0.000974    Time 0.190886    
2019-09-13 05:39:05,786 - Epoch: [1][  450/ 5005]    Overall Loss 1.314575    Objective Loss 1.314575    Top1 68.645833    Top5 87.076389    LR 0.000974    Time 0.189748    
2019-09-13 05:39:14,937 - Epoch: [1][  500/ 5005]    Overall Loss 1.317800    Objective Loss 1.317800    Top1 68.575781    Top5 87.033594    LR 0.000973    Time 0.189069    
2019-09-13 05:39:24,074 - Epoch: [1][  550/ 5005]    Overall Loss 1.317462    Objective Loss 1.317462    Top1 68.622869    Top5 87.062500    LR 0.000973    Time 0.188488    
2019-09-13 05:39:33,217 - Epoch: [1][  600/ 5005]    Overall Loss 1.319433    Objective Loss 1.319433    Top1 68.624349    Top5 87.033203    LR 0.000972    Time 0.188013    
2019-09-13 05:39:42,144 - Epoch: [1][  650/ 5005]    Overall Loss 1.322591    Objective Loss 1.322591    Top1 68.570313    Top5 86.993389    LR 0.000972    Time 0.187279    
2019-09-13 05:39:51,128 - Epoch: [1][  700/ 5005]    Overall Loss 1.323508    Objective Loss 1.323508    Top1 68.568080    Top5 86.981585    LR 0.000971    Time 0.186732    
2019-09-13 05:40:00,209 - Epoch: [1][  750/ 5005]    Overall Loss 1.323929    Objective Loss 1.323929    Top1 68.547917    Top5 86.964583    LR 0.000971    Time 0.186387    
2019-09-13 05:40:09,370 - Epoch: [1][  800/ 5005]    Overall Loss 1.325179    Objective Loss 1.325179    Top1 68.547363    Top5 86.938965    LR 0.000970    Time 0.186184    
2019-09-13 05:40:18,522 - Epoch: [1][  850/ 5005]    Overall Loss 1.323168    Objective Loss 1.323168    Top1 68.579963    Top5 86.964154    LR 0.000970    Time 0.185995    
2019-09-13 05:40:27,505 - Epoch: [1][  900/ 5005]    Overall Loss 1.324502    Objective Loss 1.324502    Top1 68.532986    Top5 86.943576    LR 0.000969    Time 0.185639    
2019-09-13 05:40:36,607 - Epoch: [1][  950/ 5005]    Overall Loss 1.323965    Objective Loss 1.323965    Top1 68.561678    Top5 86.948602    LR 0.000969    Time 0.185446    
2019-09-13 05:40:45,707 - Epoch: [1][ 1000/ 5005]    Overall Loss 1.324201    Objective Loss 1.324201    Top1 68.543359    Top5 86.949609    LR 0.000968    Time 0.185271    
2019-09-13 05:40:54,762 - Epoch: [1][ 1050/ 5005]    Overall Loss 1.323781    Objective Loss 1.323781    Top1 68.566592    Top5 86.949033    LR 0.000968    Time 0.185069    
2019-09-13 05:41:03,772 - Epoch: [1][ 1100/ 5005]    Overall Loss 1.324446    Objective Loss 1.324446    Top1 68.562855    Top5 86.952415    LR 0.000967    Time 0.184845    
2019-09-13 05:41:12,827 - Epoch: [1][ 1150/ 5005]    Overall Loss 1.325762    Objective Loss 1.325762    Top1 68.530910    Top5 86.935802    LR 0.000967    Time 0.184680    
2019-09-13 05:41:21,837 - Epoch: [1][ 1200/ 5005]    Overall Loss 1.324797    Objective Loss 1.324797    Top1 68.550130    Top5 86.956706    LR 0.000966    Time 0.184489    
2019-09-13 05:41:30,929 - Epoch: [1][ 1250/ 5005]    Overall Loss 1.325300    Objective Loss 1.325300    Top1 68.553125    Top5 86.940625    LR 0.000966    Time 0.184381    
2019-09-13 05:41:40,039 - Epoch: [1][ 1300/ 5005]    Overall Loss 1.325037    Objective Loss 1.325037    Top1 68.560096    Top5 86.945012    LR 0.000965    Time 0.184295    
2019-09-13 05:41:49,010 - Epoch: [1][ 1350/ 5005]    Overall Loss 1.324219    Objective Loss 1.324219    Top1 68.581887    Top5 86.965567    LR 0.000965    Time 0.184112    
2019-09-13 05:41:58,038 - Epoch: [1][ 1400/ 5005]    Overall Loss 1.323094    Objective Loss 1.323094    Top1 68.602121    Top5 86.983817    LR 0.000964    Time 0.183982    
2019-09-13 05:42:07,045 - Epoch: [1][ 1450/ 5005]    Overall Loss 1.323715    Objective Loss 1.323715    Top1 68.593750    Top5 86.976293    LR 0.000964    Time 0.183847    
2019-09-13 05:42:16,120 - Epoch: [1][ 1500/ 5005]    Overall Loss 1.323615    Objective Loss 1.323615    Top1 68.583073    Top5 86.976042    LR 0.000963    Time 0.183767    
2019-09-13 05:42:25,170 - Epoch: [1][ 1550/ 5005]    Overall Loss 1.323761    Objective Loss 1.323761    Top1 68.584929    Top5 86.977319    LR 0.000962    Time 0.183675    
2019-09-13 05:42:34,110 - Epoch: [1][ 1600/ 5005]    Overall Loss 1.323324    Objective Loss 1.323324    Top1 68.591309    Top5 86.984131    LR 0.000962    Time 0.183521    
2019-09-13 05:42:43,167 - Epoch: [1][ 1650/ 5005]    Overall Loss 1.323344    Objective Loss 1.323344    Top1 68.589015    Top5 86.984138    LR 0.000961    Time 0.183447    
2019-09-13 05:42:52,197 - Epoch: [1][ 1700/ 5005]    Overall Loss 1.322461    Objective Loss 1.322461    Top1 68.619256    Top5 86.998621    LR 0.000961    Time 0.183361    
2019-09-13 05:43:01,372 - Epoch: [1][ 1750/ 5005]    Overall Loss 1.322944    Objective Loss 1.322944    Top1 68.611161    Top5 86.992188    LR 0.000960    Time 0.183363    
2019-09-13 05:43:10,365 - Epoch: [1][ 1800/ 5005]    Overall Loss 1.323348    Objective Loss 1.323348    Top1 68.595920    Top5 86.988281    LR 0.000960    Time 0.183264    
2019-09-13 05:43:19,289 - Epoch: [1][ 1850/ 5005]    Overall Loss 1.323186    Objective Loss 1.323186    Top1 68.600296    Top5 86.994088    LR 0.000959    Time 0.183133    
2019-09-13 05:43:28,300 - Epoch: [1][ 1900/ 5005]    Overall Loss 1.323632    Objective Loss 1.323632    Top1 68.599712    Top5 86.976974    LR 0.000958    Time 0.183054    
2019-09-13 05:43:37,302 - Epoch: [1][ 1950/ 5005]    Overall Loss 1.323374    Objective Loss 1.323374    Top1 68.612380    Top5 86.983774    LR 0.000958    Time 0.182975    
2019-09-13 05:43:46,302 - Epoch: [1][ 2000/ 5005]    Overall Loss 1.323941    Objective Loss 1.323941    Top1 68.589453    Top5 86.981836    LR 0.000957    Time 0.182899    
2019-09-13 05:43:55,349 - Epoch: [1][ 2050/ 5005]    Overall Loss 1.324733    Objective Loss 1.324733    Top1 68.578697    Top5 86.973133    LR 0.000957    Time 0.182849    
2019-09-13 05:44:04,386 - Epoch: [1][ 2100/ 5005]    Overall Loss 1.324353    Objective Loss 1.324353    Top1 68.592634    Top5 86.980469    LR 0.000956    Time 0.182797    
2019-09-13 05:44:13,353 - Epoch: [1][ 2150/ 5005]    Overall Loss 1.325159    Objective Loss 1.325159    Top1 68.571948    Top5 86.972202    LR 0.000955    Time 0.182715    
2019-09-13 05:44:22,501 - Epoch: [1][ 2200/ 5005]    Overall Loss 1.325425    Objective Loss 1.325425    Top1 68.566406    Top5 86.962891    LR 0.000955    Time 0.182719    
2019-09-13 05:44:31,498 - Epoch: [1][ 2250/ 5005]    Overall Loss 1.325582    Objective Loss 1.325582    Top1 68.560590    Top5 86.956250    LR 0.000954    Time 0.182656    
2019-09-13 05:44:40,474 - Epoch: [1][ 2300/ 5005]    Overall Loss 1.325560    Objective Loss 1.325560    Top1 68.562500    Top5 86.961957    LR 0.000954    Time 0.182587    
2019-09-13 05:44:49,533 - Epoch: [1][ 2350/ 5005]    Overall Loss 1.325462    Objective Loss 1.325462    Top1 68.568650    Top5 86.962600    LR 0.000953    Time 0.182555    
2019-09-13 05:44:58,580 - Epoch: [1][ 2400/ 5005]    Overall Loss 1.325187    Objective Loss 1.325187    Top1 68.572754    Top5 86.963542    LR 0.000952    Time 0.182520    
2019-09-13 05:45:07,563 - Epoch: [1][ 2450/ 5005]    Overall Loss 1.324693    Objective Loss 1.324693    Top1 68.574936    Top5 86.973533    LR 0.000952    Time 0.182461    
2019-09-13 05:45:16,561 - Epoch: [1][ 2500/ 5005]    Overall Loss 1.324383    Objective Loss 1.324383    Top1 68.570781    Top5 86.978594    LR 0.000951    Time 0.182410    
2019-09-13 05:45:25,551 - Epoch: [1][ 2550/ 5005]    Overall Loss 1.324787    Objective Loss 1.324787    Top1 68.578125    Top5 86.973039    LR 0.000950    Time 0.182357    
2019-09-13 05:45:34,601 - Epoch: [1][ 2600/ 5005]    Overall Loss 1.325284    Objective Loss 1.325284    Top1 68.571064    Top5 86.964543    LR 0.000950    Time 0.182329    
2019-09-13 05:45:43,631 - Epoch: [1][ 2650/ 5005]    Overall Loss 1.325346    Objective Loss 1.325346    Top1 68.561616    Top5 86.966244    LR 0.000949    Time 0.182296    
2019-09-13 05:45:52,743 - Epoch: [1][ 2700/ 5005]    Overall Loss 1.325325    Objective Loss 1.325325    Top1 68.569155    Top5 86.968461    LR 0.000948    Time 0.182294    
2019-09-13 05:46:01,847 - Epoch: [1][ 2750/ 5005]    Overall Loss 1.325320    Objective Loss 1.325320    Top1 68.561506    Top5 86.973295    LR 0.000948    Time 0.182288    
2019-09-13 05:46:10,801 - Epoch: [1][ 2800/ 5005]    Overall Loss 1.325709    Objective Loss 1.325709    Top1 68.553990    Top5 86.967355    LR 0.000947    Time 0.182230    
2019-09-13 05:46:19,831 - Epoch: [1][ 2850/ 5005]    Overall Loss 1.325796    Objective Loss 1.325796    Top1 68.550027    Top5 86.970258    LR 0.000946    Time 0.182200    
2019-09-13 05:46:28,869 - Epoch: [1][ 2900/ 5005]    Overall Loss 1.326376    Objective Loss 1.326376    Top1 68.544855    Top5 86.960938    LR 0.000946    Time 0.182174    
2019-09-13 05:46:37,999 - Epoch: [1][ 2950/ 5005]    Overall Loss 1.326618    Objective Loss 1.326618    Top1 68.545154    Top5 86.954184    LR 0.000945    Time 0.182180    
2019-09-13 05:46:46,934 - Epoch: [1][ 3000/ 5005]    Overall Loss 1.326602    Objective Loss 1.326602    Top1 68.533594    Top5 86.953255    LR 0.000944    Time 0.182121    
2019-09-13 05:46:55,961 - Epoch: [1][ 3050/ 5005]    Overall Loss 1.326249    Objective Loss 1.326249    Top1 68.536757    Top5 86.960553    LR 0.000944    Time 0.182094    
2019-09-13 05:47:04,989 - Epoch: [1][ 3100/ 5005]    Overall Loss 1.326322    Objective Loss 1.326322    Top1 68.529360    Top5 86.956779    LR 0.000943    Time 0.182068    
2019-09-13 05:47:14,294 - Epoch: [1][ 3150/ 5005]    Overall Loss 1.326591    Objective Loss 1.326591    Top1 68.521205    Top5 86.950769    LR 0.000942    Time 0.182131    
2019-09-13 05:47:23,311 - Epoch: [1][ 3200/ 5005]    Overall Loss 1.326608    Objective Loss 1.326608    Top1 68.521484    Top5 86.950317    LR 0.000942    Time 0.182102    
2019-09-13 05:47:32,348 - Epoch: [1][ 3250/ 5005]    Overall Loss 1.326715    Objective Loss 1.326715    Top1 68.517668    Top5 86.947356    LR 0.000941    Time 0.182080    
2019-09-13 05:47:41,402 - Epoch: [1][ 3300/ 5005]    Overall Loss 1.326619    Objective Loss 1.326619    Top1 68.524148    Top5 86.949574    LR 0.000940    Time 0.182064    
2019-09-13 05:47:50,416 - Epoch: [1][ 3350/ 5005]    Overall Loss 1.327170    Objective Loss 1.327170    Top1 68.516908    Top5 86.939016    LR 0.000940    Time 0.182037    
2019-09-13 05:47:59,495 - Epoch: [1][ 3400/ 5005]    Overall Loss 1.327266    Objective Loss 1.327266    Top1 68.515165    Top5 86.935432    LR 0.000939    Time 0.182029    
2019-09-13 05:48:08,608 - Epoch: [1][ 3450/ 5005]    Overall Loss 1.327022    Objective Loss 1.327022    Top1 68.518116    Top5 86.941463    LR 0.000938    Time 0.182031    
2019-09-13 05:48:17,697 - Epoch: [1][ 3500/ 5005]    Overall Loss 1.326962    Objective Loss 1.326962    Top1 68.516406    Top5 86.945647    LR 0.000937    Time 0.182027    
2019-09-13 05:48:26,828 - Epoch: [1][ 3550/ 5005]    Overall Loss 1.326858    Objective Loss 1.326858    Top1 68.520797    Top5 86.946083    LR 0.000937    Time 0.182034    
2019-09-13 05:48:36,024 - Epoch: [1][ 3600/ 5005]    Overall Loss 1.326935    Objective Loss 1.326935    Top1 68.519423    Top5 86.943034    LR 0.000936    Time 0.182059    
2019-09-13 05:48:45,193 - Epoch: [1][ 3650/ 5005]    Overall Loss 1.326747    Objective Loss 1.326747    Top1 68.521190    Top5 86.951306    LR 0.000935    Time 0.182076    
2019-09-13 05:48:54,144 - Epoch: [1][ 3700/ 5005]    Overall Loss 1.327511    Objective Loss 1.327511    Top1 68.506229    Top5 86.939189    LR 0.000934    Time 0.182034    
2019-09-13 05:49:03,213 - Epoch: [1][ 3750/ 5005]    Overall Loss 1.327796    Objective Loss 1.327796    Top1 68.505729    Top5 86.939271    LR 0.000934    Time 0.182025    
2019-09-13 05:49:12,262 - Epoch: [1][ 3800/ 5005]    Overall Loss 1.328281    Objective Loss 1.328281    Top1 68.496094    Top5 86.929790    LR 0.000933    Time 0.182010    
2019-09-13 05:49:21,363 - Epoch: [1][ 3850/ 5005]    Overall Loss 1.328300    Objective Loss 1.328300    Top1 68.499188    Top5 86.932021    LR 0.000932    Time 0.182009    
2019-09-13 05:49:30,301 - Epoch: [1][ 3900/ 5005]    Overall Loss 1.327959    Objective Loss 1.327959    Top1 68.505108    Top5 86.938502    LR 0.000932    Time 0.181967    
2019-09-13 05:49:39,298 - Epoch: [1][ 3950/ 5005]    Overall Loss 1.327747    Objective Loss 1.327747    Top1 68.508999    Top5 86.940566    LR 0.000931    Time 0.181940    
2019-09-13 05:49:48,254 - Epoch: [1][ 4000/ 5005]    Overall Loss 1.327499    Objective Loss 1.327499    Top1 68.513672    Top5 86.944629    LR 0.000930    Time 0.181904    
2019-09-13 05:49:57,325 - Epoch: [1][ 4050/ 5005]    Overall Loss 1.327646    Objective Loss 1.327646    Top1 68.508681    Top5 86.942805    LR 0.000929    Time 0.181897    
2019-09-13 05:50:06,256 - Epoch: [1][ 4100/ 5005]    Overall Loss 1.327618    Objective Loss 1.327618    Top1 68.503049    Top5 86.943216    LR 0.000929    Time 0.181857    
2019-09-13 05:50:15,267 - Epoch: [1][ 4150/ 5005]    Overall Loss 1.327570    Objective Loss 1.327570    Top1 68.502541    Top5 86.941077    LR 0.000928    Time 0.181836    
2019-09-13 05:50:24,399 - Epoch: [1][ 4200/ 5005]    Overall Loss 1.327175    Objective Loss 1.327175    Top1 68.511533    Top5 86.946429    LR 0.000927    Time 0.181844    
2019-09-13 05:50:33,592 - Epoch: [1][ 4250/ 5005]    Overall Loss 1.327374    Objective Loss 1.327374    Top1 68.510110    Top5 86.940717    LR 0.000926    Time 0.181867    
2019-09-13 05:50:42,594 - Epoch: [1][ 4300/ 5005]    Overall Loss 1.327486    Objective Loss 1.327486    Top1 68.509993    Top5 86.939862    LR 0.000925    Time 0.181845    
2019-09-13 05:50:51,576 - Epoch: [1][ 4350/ 5005]    Overall Loss 1.327551    Objective Loss 1.327551    Top1 68.509339    Top5 86.940463    LR 0.000925    Time 0.181819    
2019-09-13 05:51:00,541 - Epoch: [1][ 4400/ 5005]    Overall Loss 1.327317    Objective Loss 1.327317    Top1 68.511985    Top5 86.944513    LR 0.000924    Time 0.181790    
2019-09-13 05:51:09,639 - Epoch: [1][ 4450/ 5005]    Overall Loss 1.327305    Objective Loss 1.327305    Top1 68.514659    Top5 86.944171    LR 0.000923    Time 0.181791    
2019-09-13 05:51:18,757 - Epoch: [1][ 4500/ 5005]    Overall Loss 1.327575    Objective Loss 1.327575    Top1 68.508333    Top5 86.943229    LR 0.000922    Time 0.181797    
2019-09-13 05:51:27,747 - Epoch: [1][ 4550/ 5005]    Overall Loss 1.327580    Objective Loss 1.327580    Top1 68.505495    Top5 86.946343    LR 0.000921    Time 0.181774    
2019-09-13 05:51:36,824 - Epoch: [1][ 4600/ 5005]    Overall Loss 1.327312    Objective Loss 1.327312    Top1 68.509681    Top5 86.952106    LR 0.000921    Time 0.181771    
2019-09-13 05:51:45,963 - Epoch: [1][ 4650/ 5005]    Overall Loss 1.327403    Objective Loss 1.327403    Top1 68.508149    Top5 86.951361    LR 0.000920    Time 0.181781    
2019-09-13 05:51:55,072 - Epoch: [1][ 4700/ 5005]    Overall Loss 1.327337    Objective Loss 1.327337    Top1 68.509558    Top5 86.954621    LR 0.000919    Time 0.181784    
2019-09-13 05:52:04,050 - Epoch: [1][ 4750/ 5005]    Overall Loss 1.327468    Objective Loss 1.327468    Top1 68.507155    Top5 86.952467    LR 0.000918    Time 0.181760    
2019-09-13 05:52:13,099 - Epoch: [1][ 4800/ 5005]    Overall Loss 1.327189    Objective Loss 1.327189    Top1 68.510335    Top5 86.957926    LR 0.000917    Time 0.181751    
2019-09-13 05:52:22,231 - Epoch: [1][ 4850/ 5005]    Overall Loss 1.327190    Objective Loss 1.327190    Top1 68.515464    Top5 86.958038    LR 0.000917    Time 0.181760    
2019-09-13 05:52:31,206 - Epoch: [1][ 4900/ 5005]    Overall Loss 1.326827    Objective Loss 1.326827    Top1 68.520010    Top5 86.965003    LR 0.000916    Time 0.181736    
2019-09-13 05:52:40,463 - Epoch: [1][ 4950/ 5005]    Overall Loss 1.326677    Objective Loss 1.326677    Top1 68.529908    Top5 86.964252    LR 0.000915    Time 0.181770    
2019-09-13 05:52:49,320 - Epoch: [1][ 5000/ 5005]    Overall Loss 1.326279    Objective Loss 1.326279    Top1 68.534609    Top5 86.968359    LR 0.000914    Time 0.181723    
2019-09-13 05:52:50,475 - 
Parameters:
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                      | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.float_weight                 | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12861 |  0.00014 |    0.07541 |
|  1 | module.conv1.weight                       | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16054 |  0.00030 |    0.09719 |
|  2 | module.layer1.0.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05296 | -0.00309 |    0.03136 |
|  3 | module.layer1.0.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07950 | -0.00433 |    0.04819 |
|  4 | module.layer1.0.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04482 | -0.00085 |    0.03174 |
|  5 | module.layer1.0.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10080 | -0.00190 |    0.07163 |
|  6 | module.layer1.1.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05041 | -0.00236 |    0.03398 |
|  7 | module.layer1.1.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08834 | -0.00415 |    0.06012 |
|  8 | module.layer1.1.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04361 | -0.00122 |    0.03124 |
|  9 | module.layer1.1.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12291 | -0.00343 |    0.08829 |
| 10 | module.layer2.0.conv1.float_weight        | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04123 | -0.00138 |    0.02915 |
| 11 | module.layer2.0.conv1.weight              | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12867 | -0.00434 |    0.09121 |
| 12 | module.layer2.0.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03372 | -0.00124 |    0.02374 |
| 13 | module.layer2.0.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08602 | -0.00317 |    0.06073 |
| 14 | module.layer2.0.downsample.0.float_weight | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07001 | -0.00261 |    0.04397 |
| 15 | module.layer2.0.downsample.0.weight       | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10547 | -0.00391 |    0.06733 |
| 16 | module.layer2.1.conv1.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03389 | -0.00148 |    0.02406 |
| 17 | module.layer2.1.conv1.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08400 | -0.00369 |    0.05980 |
| 18 | module.layer2.1.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02980 | -0.00126 |    0.02206 |
| 19 | module.layer2.1.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08996 | -0.00379 |    0.06670 |
| 20 | module.layer3.0.conv1.float_weight        | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02880 | -0.00135 |    0.02075 |
| 21 | module.layer3.0.conv1.weight              | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07997 | -0.00375 |    0.05775 |
| 22 | module.layer3.0.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02484 | -0.00077 |    0.01820 |
| 23 | module.layer3.0.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08144 | -0.00253 |    0.05977 |
| 24 | module.layer3.0.downsample.0.float_weight | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03266 | -0.00186 |    0.02357 |
| 25 | module.layer3.0.downsample.0.weight       | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12621 | -0.00718 |    0.09124 |
| 26 | module.layer3.1.conv1.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02218 | -0.00164 |    0.01651 |
| 27 | module.layer3.1.conv1.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08046 | -0.00595 |    0.05998 |
| 28 | module.layer3.1.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02050 | -0.00142 |    0.01540 |
| 29 | module.layer3.1.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06816 | -0.00471 |    0.05125 |
| 30 | module.layer4.0.conv1.float_weight        | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01971 | -0.00154 |    0.01508 |
| 31 | module.layer4.0.conv1.weight              | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05982 | -0.00467 |    0.04585 |
| 32 | module.layer4.0.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01718 | -0.00129 |    0.01327 |
| 33 | module.layer4.0.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05608 | -0.00422 |    0.04338 |
| 34 | module.layer4.0.downsample.0.float_weight | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03250 | -0.00084 |    0.02368 |
| 35 | module.layer4.0.downsample.0.weight       | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05206 | -0.00135 |    0.03808 |
| 36 | module.layer4.1.conv1.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01768 | -0.00223 |    0.01392 |
| 37 | module.layer4.1.conv1.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07337 | -0.00926 |    0.05780 |
| 38 | module.layer4.1.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01309 | -0.00009 |    0.01000 |
| 39 | module.layer4.1.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05277 | -0.00037 |    0.04039 |
| 40 | module.fc.float_weight                    | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06879 |  0.00000 |    0.05045 |
| 41 | module.fc.weight                          | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08694 | -0.00020 |    0.06418 |
| 42 | Total sparsity:                           | -                |      23357824 |       23357824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2019-09-13 05:52:50,476 - Total sparsity: 0.00

2019-09-13 05:52:50,476 - --- validate (epoch=1)-----------
2019-09-13 05:52:50,476 - 50000 samples (256 per mini-batch)
2019-09-13 05:53:01,919 - Epoch: [1][   50/  195]    Loss 0.936601    Top1 75.664062    Top5 93.187500    
2019-09-13 05:53:09,751 - Epoch: [1][  100/  195]    Loss 1.070653    Top1 73.390625    Top5 91.558594    
2019-09-13 05:53:17,598 - Epoch: [1][  150/  195]    Loss 1.211861    Top1 70.585938    Top5 89.614583    
2019-09-13 05:53:25,235 - ==> Top1: 69.476    Top5: 88.946    Loss: 1.271

2019-09-13 05:53:25,243 - ==> Best Top1: 69.512 on Epoch: 0
2019-09-13 05:53:25,244 - Saving checkpoint to: 8b_logs/res18___2019.09.13-052127/res18_checkpoint.pth.tar
2019-09-13 05:53:28,359 - Saving PACT param_value.......
2019-09-13 05:53:28,360 - The PACT Clip Parameter Value............
2019-09-13 05:53:28,367 - 

2019-09-13 05:53:28,367 - +--------------------------------+--------------+
| Layers                         |   PACT_alpha |
|--------------------------------+--------------|
| module.relu.clip_val           |      7.92244 |
| module.layer1.0.relu1.clip_val |      7.92243 |
| module.layer1.0.relu2.clip_val |      7.92244 |
| module.layer1.1.relu1.clip_val |      7.92243 |
| module.layer1.1.relu2.clip_val |      7.92243 |
| module.layer2.0.relu1.clip_val |      7.92243 |
| module.layer2.0.relu2.clip_val |      7.92247 |
| module.layer2.1.relu1.clip_val |      7.92243 |
| module.layer2.1.relu2.clip_val |      7.9225  |
| module.layer3.0.relu1.clip_val |      7.92243 |
| module.layer3.0.relu2.clip_val |      7.92243 |
| module.layer3.1.relu1.clip_val |      7.92243 |
| module.layer3.1.relu2.clip_val |      7.92253 |
| module.layer4.0.relu1.clip_val |      7.92243 |
| module.layer4.0.relu2.clip_val |      7.92255 |
| module.layer4.1.relu1.clip_val |      7.92243 |
| module.layer4.1.relu2.clip_val |      8.04952 |
+--------------------------------+--------------+
2019-09-13 05:53:28,371 - 

2019-09-13 05:53:28,371 - Training epoch: 1281167 samples (256 per mini-batch)
2019-09-13 05:53:40,321 - Epoch: [2][   50/ 5005]    Overall Loss 1.318141    Objective Loss 1.318141    Top1 69.679688    Top5 86.929688    LR 0.000913    Time 0.238892    
2019-09-13 05:53:49,409 - Epoch: [2][  100/ 5005]    Overall Loss 1.314014    Objective Loss 1.314014    Top1 69.363281    Top5 87.062500    LR 0.000912    Time 0.210295    
2019-09-13 05:53:58,551 - Epoch: [2][  150/ 5005]    Overall Loss 1.319477    Objective Loss 1.319477    Top1 69.075521    Top5 86.898438    LR 0.000912    Time 0.201120    
2019-09-13 05:54:07,783 - Epoch: [2][  200/ 5005]    Overall Loss 1.313364    Objective Loss 1.313364    Top1 69.103516    Top5 87.072266    LR 0.000911    Time 0.196984    
2019-09-13 05:54:16,782 - Epoch: [2][  250/ 5005]    Overall Loss 1.306391    Objective Loss 1.306391    Top1 69.184375    Top5 87.204688    LR 0.000910    Time 0.193569    
2019-09-13 05:54:25,837 - Epoch: [2][  300/ 5005]    Overall Loss 1.306747    Objective Loss 1.306747    Top1 69.197917    Top5 87.242188    LR 0.000909    Time 0.191476    
2019-09-13 05:54:34,894 - Epoch: [2][  350/ 5005]    Overall Loss 1.308922    Objective Loss 1.308922    Top1 69.091518    Top5 87.216518    LR 0.000908    Time 0.189988    
2019-09-13 05:54:43,994 - Epoch: [2][  400/ 5005]    Overall Loss 1.307190    Objective Loss 1.307190    Top1 69.101562    Top5 87.232422    LR 0.000907    Time 0.188981    
2019-09-13 05:54:53,082 - Epoch: [2][  450/ 5005]    Overall Loss 1.307674    Objective Loss 1.307674    Top1 69.052951    Top5 87.241319    LR 0.000906    Time 0.188170    
2019-09-13 05:55:02,135 - Epoch: [2][  500/ 5005]    Overall Loss 1.308370    Objective Loss 1.308370    Top1 69.073437    Top5 87.228125    LR 0.000906    Time 0.187453    
2019-09-13 05:55:11,163 - Epoch: [2][  550/ 5005]    Overall Loss 1.307193    Objective Loss 1.307193    Top1 69.064631    Top5 87.233665    LR 0.000905    Time 0.186820    
2019-09-13 05:55:20,135 - Epoch: [2][  600/ 5005]    Overall Loss 1.305971    Objective Loss 1.305971    Top1 69.053385    Top5 87.260417    LR 0.000904    Time 0.186200    
2019-09-13 05:55:29,398 - Epoch: [2][  650/ 5005]    Overall Loss 1.305884    Objective Loss 1.305884    Top1 69.028245    Top5 87.268630    LR 0.000903    Time 0.186120    
2019-09-13 05:55:38,408 - Epoch: [2][  700/ 5005]    Overall Loss 1.307094    Objective Loss 1.307094    Top1 69.004464    Top5 87.242188    LR 0.000902    Time 0.185691    
2019-09-13 05:55:47,392 - Epoch: [2][  750/ 5005]    Overall Loss 1.307607    Objective Loss 1.307607    Top1 68.998437    Top5 87.226042    LR 0.000901    Time 0.185288    
2019-09-13 05:55:56,528 - Epoch: [2][  800/ 5005]    Overall Loss 1.309135    Objective Loss 1.309135    Top1 68.961914    Top5 87.211426    LR 0.000900    Time 0.185122    
2019-09-13 05:56:05,577 - Epoch: [2][  850/ 5005]    Overall Loss 1.311007    Objective Loss 1.311007    Top1 68.936121    Top5 87.182445    LR 0.000899    Time 0.184876    
2019-09-13 05:56:14,622 - Epoch: [2][  900/ 5005]    Overall Loss 1.309486    Objective Loss 1.309486    Top1 68.990885    Top5 87.188802    LR 0.000899    Time 0.184651    
2019-09-13 05:56:23,625 - Epoch: [2][  950/ 5005]    Overall Loss 1.307466    Objective Loss 1.307466    Top1 69.030016    Top5 87.217105    LR 0.000898    Time 0.184405    
2019-09-13 05:56:32,595 - Epoch: [2][ 1000/ 5005]    Overall Loss 1.308845    Objective Loss 1.308845    Top1 69.001563    Top5 87.194141    LR 0.000897    Time 0.184152    
2019-09-13 05:56:41,610 - Epoch: [2][ 1050/ 5005]    Overall Loss 1.309891    Objective Loss 1.309891    Top1 68.979167    Top5 87.163690    LR 0.000896    Time 0.183965    
2019-09-13 05:56:50,590 - Epoch: [2][ 1100/ 5005]    Overall Loss 1.311015    Objective Loss 1.311015    Top1 68.963423    Top5 87.139560    LR 0.000895    Time 0.183764    
2019-09-13 05:56:59,763 - Epoch: [2][ 1150/ 5005]    Overall Loss 1.311546    Objective Loss 1.311546    Top1 68.957880    Top5 87.136549    LR 0.000894    Time 0.183748    
2019-09-13 05:57:08,784 - Epoch: [2][ 1200/ 5005]    Overall Loss 1.311544    Objective Loss 1.311544    Top1 68.972982    Top5 87.128255    LR 0.000893    Time 0.183606    
2019-09-13 05:57:17,909 - Epoch: [2][ 1250/ 5005]    Overall Loss 1.313035    Objective Loss 1.313035    Top1 68.932813    Top5 87.106250    LR 0.000892    Time 0.183560    
2019-09-13 05:57:27,013 - Epoch: [2][ 1300/ 5005]    Overall Loss 1.313430    Objective Loss 1.313430    Top1 68.926382    Top5 87.125601    LR 0.000891    Time 0.183500    
2019-09-13 05:57:35,886 - Epoch: [2][ 1350/ 5005]    Overall Loss 1.314069    Objective Loss 1.314069    Top1 68.905671    Top5 87.117477    LR 0.000890    Time 0.183273    
2019-09-13 05:57:44,826 - Epoch: [2][ 1400/ 5005]    Overall Loss 1.313845    Objective Loss 1.313845    Top1 68.916853    Top5 87.120257    LR 0.000889    Time 0.183111    
2019-09-13 05:57:53,773 - Epoch: [2][ 1450/ 5005]    Overall Loss 1.313455    Objective Loss 1.313455    Top1 68.919720    Top5 87.122306    LR 0.000889    Time 0.182965    
2019-09-13 05:58:02,728 - Epoch: [2][ 1500/ 5005]    Overall Loss 1.313924    Objective Loss 1.313924    Top1 68.908073    Top5 87.109375    LR 0.000888    Time 0.182834    
2019-09-13 05:58:11,728 - Epoch: [2][ 1550/ 5005]    Overall Loss 1.313446    Objective Loss 1.313446    Top1 68.925403    Top5 87.109375    LR 0.000887    Time 0.182740    
2019-09-13 05:58:20,783 - Epoch: [2][ 1600/ 5005]    Overall Loss 1.313741    Objective Loss 1.313741    Top1 68.918213    Top5 87.109131    LR 0.000886    Time 0.182687    
2019-09-13 05:58:29,774 - Epoch: [2][ 1650/ 5005]    Overall Loss 1.313646    Objective Loss 1.313646    Top1 68.918797    Top5 87.102036    LR 0.000885    Time 0.182598    
2019-09-13 05:58:38,642 - Epoch: [2][ 1700/ 5005]    Overall Loss 1.314658    Objective Loss 1.314658    Top1 68.893842    Top5 87.090993    LR 0.000884    Time 0.182442    
2019-09-13 05:58:47,601 - Epoch: [2][ 1750/ 5005]    Overall Loss 1.315012    Objective Loss 1.315012    Top1 68.888839    Top5 87.093080    LR 0.000883    Time 0.182347    
2019-09-13 05:58:56,663 - Epoch: [2][ 1800/ 5005]    Overall Loss 1.315351    Objective Loss 1.315351    Top1 68.884332    Top5 87.091146    LR 0.000882    Time 0.182315    
2019-09-13 05:59:05,705 - Epoch: [2][ 1850/ 5005]    Overall Loss 1.314467    Objective Loss 1.314467    Top1 68.899071    Top5 87.100718    LR 0.000881    Time 0.182273    
2019-09-13 05:59:14,754 - Epoch: [2][ 1900/ 5005]    Overall Loss 1.314715    Objective Loss 1.314715    Top1 68.894531    Top5 87.094572    LR 0.000880    Time 0.182237    
2019-09-13 05:59:23,840 - Epoch: [2][ 1950/ 5005]    Overall Loss 1.314146    Objective Loss 1.314146    Top1 68.905048    Top5 87.098558    LR 0.000879    Time 0.182223    
2019-09-13 05:59:32,782 - Epoch: [2][ 2000/ 5005]    Overall Loss 1.314714    Objective Loss 1.314714    Top1 68.899023    Top5 87.094531    LR 0.000878    Time 0.182137    
2019-09-13 05:59:41,822 - Epoch: [2][ 2050/ 5005]    Overall Loss 1.314594    Objective Loss 1.314594    Top1 68.900152    Top5 87.098895    LR 0.000877    Time 0.182102    
2019-09-13 05:59:50,734 - Epoch: [2][ 2100/ 5005]    Overall Loss 1.313964    Objective Loss 1.313964    Top1 68.901228    Top5 87.106027    LR 0.000876    Time 0.182009    
2019-09-13 05:59:59,640 - Epoch: [2][ 2150/ 5005]    Overall Loss 1.314307    Objective Loss 1.314307    Top1 68.894622    Top5 87.099201    LR 0.000875    Time 0.181917    
2019-09-13 06:00:08,581 - Epoch: [2][ 2200/ 5005]    Overall Loss 1.314117    Objective Loss 1.314117    Top1 68.897905    Top5 87.106534    LR 0.000874    Time 0.181845    
2019-09-13 06:00:17,636 - Epoch: [2][ 2250/ 5005]    Overall Loss 1.314066    Objective Loss 1.314066    Top1 68.892014    Top5 87.101215    LR 0.000873    Time 0.181827    
2019-09-13 06:00:26,763 - Epoch: [2][ 2300/ 5005]    Overall Loss 1.314398    Objective Loss 1.314398    Top1 68.892323    Top5 87.091202    LR 0.000872    Time 0.181841    
2019-09-13 06:00:35,705 - Epoch: [2][ 2350/ 5005]    Overall Loss 1.314438    Objective Loss 1.314438    Top1 68.885971    Top5 87.088597    LR 0.000871    Time 0.181775    
2019-09-13 06:00:44,606 - Epoch: [2][ 2400/ 5005]    Overall Loss 1.314742    Objective Loss 1.314742    Top1 68.880534    Top5 87.079915    LR 0.000870    Time 0.181696    
2019-09-13 06:00:53,584 - Epoch: [2][ 2450/ 5005]    Overall Loss 1.315201    Objective Loss 1.315201    Top1 68.875957    Top5 87.073661    LR 0.000869    Time 0.181651    
2019-09-13 06:01:02,742 - Epoch: [2][ 2500/ 5005]    Overall Loss 1.315458    Objective Loss 1.315458    Top1 68.869687    Top5 87.069531    LR 0.000868    Time 0.181680    
2019-09-13 06:01:11,722 - Epoch: [2][ 2550/ 5005]    Overall Loss 1.315504    Objective Loss 1.315504    Top1 68.870404    Top5 87.071078    LR 0.000867    Time 0.181638    
2019-09-13 06:01:20,612 - Epoch: [2][ 2600/ 5005]    Overall Loss 1.315895    Objective Loss 1.315895    Top1 68.859976    Top5 87.071665    LR 0.000866    Time 0.181562    
2019-09-13 06:01:29,514 - Epoch: [2][ 2650/ 5005]    Overall Loss 1.315836    Objective Loss 1.315836    Top1 68.854068    Top5 87.074735    LR 0.000865    Time 0.181495    
2019-09-13 06:01:38,503 - Epoch: [2][ 2700/ 5005]    Overall Loss 1.315923    Objective Loss 1.315923    Top1 68.855469    Top5 87.073061    LR 0.000864    Time 0.181462    
2019-09-13 06:01:47,376 - Epoch: [2][ 2750/ 5005]    Overall Loss 1.315506    Objective Loss 1.315506    Top1 68.865057    Top5 87.077699    LR 0.000863    Time 0.181388    
2019-09-13 06:01:56,284 - Epoch: [2][ 2800/ 5005]    Overall Loss 1.315558    Objective Loss 1.315558    Top1 68.859375    Top5 87.081334    LR 0.000862    Time 0.181329    
2019-09-13 06:02:05,316 - Epoch: [2][ 2850/ 5005]    Overall Loss 1.315871    Objective Loss 1.315871    Top1 68.853481    Top5 87.076343    LR 0.000861    Time 0.181316    
2019-09-13 06:02:14,254 - Epoch: [2][ 2900/ 5005]    Overall Loss 1.315955    Objective Loss 1.315955    Top1 68.849677    Top5 87.069504    LR 0.000860    Time 0.181271    
2019-09-13 06:02:23,370 - Epoch: [2][ 2950/ 5005]    Overall Loss 1.316267    Objective Loss 1.316267    Top1 68.846266    Top5 87.061970    LR 0.000859    Time 0.181288    
2019-09-13 06:02:32,366 - Epoch: [2][ 3000/ 5005]    Overall Loss 1.316771    Objective Loss 1.316771    Top1 68.838151    Top5 87.063281    LR 0.000858    Time 0.181264    
2019-09-13 06:02:41,311 - Epoch: [2][ 3050/ 5005]    Overall Loss 1.316774    Objective Loss 1.316774    Top1 68.836322    Top5 87.066726    LR 0.000857    Time 0.181224    
2019-09-13 06:02:50,275 - Epoch: [2][ 3100/ 5005]    Overall Loss 1.317069    Objective Loss 1.317069    Top1 68.830645    Top5 87.062500    LR 0.000856    Time 0.181192    
2019-09-13 06:02:59,280 - Epoch: [2][ 3150/ 5005]    Overall Loss 1.317571    Objective Loss 1.317571    Top1 68.818328    Top5 87.056052    LR 0.000855    Time 0.181173    
2019-09-13 06:03:08,295 - Epoch: [2][ 3200/ 5005]    Overall Loss 1.317956    Objective Loss 1.317956    Top1 68.802734    Top5 87.051514    LR 0.000854    Time 0.181159    
2019-09-13 06:03:17,249 - Epoch: [2][ 3250/ 5005]    Overall Loss 1.318104    Objective Loss 1.318104    Top1 68.800481    Top5 87.048558    LR 0.000853    Time 0.181125    
2019-09-13 06:03:26,159 - Epoch: [2][ 3300/ 5005]    Overall Loss 1.317875    Objective Loss 1.317875    Top1 68.804924    Top5 87.048295    LR 0.000852    Time 0.181080    
2019-09-13 06:03:35,191 - Epoch: [2][ 3350/ 5005]    Overall Loss 1.317739    Objective Loss 1.317739    Top1 68.805737    Top5 87.049557    LR 0.000851    Time 0.181072    
2019-09-13 06:03:44,450 - Epoch: [2][ 3400/ 5005]    Overall Loss 1.317742    Objective Loss 1.317742    Top1 68.803883    Top5 87.050551    LR 0.000850    Time 0.181132    
2019-09-13 06:03:53,528 - Epoch: [2][ 3450/ 5005]    Overall Loss 1.317611    Objective Loss 1.317611    Top1 68.808990    Top5 87.053216    LR 0.000849    Time 0.181137    
2019-09-13 06:04:02,541 - Epoch: [2][ 3500/ 5005]    Overall Loss 1.317749    Objective Loss 1.317749    Top1 68.800112    Top5 87.049888    LR 0.000848    Time 0.181123    
2019-09-13 06:04:11,572 - Epoch: [2][ 3550/ 5005]    Overall Loss 1.317132    Objective Loss 1.317132    Top1 68.813490    Top5 87.057328    LR 0.000847    Time 0.181115    
2019-09-13 06:04:20,582 - Epoch: [2][ 3600/ 5005]    Overall Loss 1.317274    Objective Loss 1.317274    Top1 68.810981    Top5 87.053928    LR 0.000846    Time 0.181101    
2019-09-13 06:04:29,643 - Epoch: [2][ 3650/ 5005]    Overall Loss 1.316987    Objective Loss 1.316987    Top1 68.810360    Top5 87.060039    LR 0.000844    Time 0.181101    
2019-09-13 06:04:38,738 - Epoch: [2][ 3700/ 5005]    Overall Loss 1.316944    Objective Loss 1.316944    Top1 68.813133    Top5 87.057116    LR 0.000843    Time 0.181111    
2019-09-13 06:04:47,800 - Epoch: [2][ 3750/ 5005]    Overall Loss 1.317548    Objective Loss 1.317548    Top1 68.804479    Top5 87.049375    LR 0.000842    Time 0.181112    
2019-09-13 06:04:56,864 - Epoch: [2][ 3800/ 5005]    Overall Loss 1.317577    Objective Loss 1.317577    Top1 68.798520    Top5 87.047595    LR 0.000841    Time 0.181113    
2019-09-13 06:05:06,163 - Epoch: [2][ 3850/ 5005]    Overall Loss 1.317525    Objective Loss 1.317525    Top1 68.794136    Top5 87.049107    LR 0.000840    Time 0.181175    
2019-09-13 06:05:15,184 - Epoch: [2][ 3900/ 5005]    Overall Loss 1.317324    Objective Loss 1.317324    Top1 68.802384    Top5 87.048878    LR 0.000839    Time 0.181164    
2019-09-13 06:05:24,164 - Epoch: [2][ 3950/ 5005]    Overall Loss 1.317196    Objective Loss 1.317196    Top1 68.802116    Top5 87.052413    LR 0.000838    Time 0.181143    
2019-09-13 06:05:33,164 - Epoch: [2][ 4000/ 5005]    Overall Loss 1.317242    Objective Loss 1.317242    Top1 68.798437    Top5 87.050879    LR 0.000837    Time 0.181128    
2019-09-13 06:05:42,195 - Epoch: [2][ 4050/ 5005]    Overall Loss 1.317292    Objective Loss 1.317292    Top1 68.797357    Top5 87.048322    LR 0.000836    Time 0.181121    
2019-09-13 06:05:51,258 - Epoch: [2][ 4100/ 5005]    Overall Loss 1.317616    Objective Loss 1.317616    Top1 68.789539    Top5 87.040587    LR 0.000835    Time 0.181122    
2019-09-13 06:06:00,234 - Epoch: [2][ 4150/ 5005]    Overall Loss 1.317969    Objective Loss 1.317969    Top1 68.784074    Top5 87.034733    LR 0.000834    Time 0.181101    
2019-09-13 06:06:09,278 - Epoch: [2][ 4200/ 5005]    Overall Loss 1.317915    Objective Loss 1.317915    Top1 68.784040    Top5 87.033389    LR 0.000833    Time 0.181097    
2019-09-13 06:06:18,293 - Epoch: [2][ 4250/ 5005]    Overall Loss 1.317898    Objective Loss 1.317898    Top1 68.783272    Top5 87.031434    LR 0.000831    Time 0.181087    
2019-09-13 06:06:27,285 - Epoch: [2][ 4300/ 5005]    Overall Loss 1.318358    Objective Loss 1.318358    Top1 68.773528    Top5 87.024346    LR 0.000830    Time 0.181072    
2019-09-13 06:06:36,588 - Epoch: [2][ 4350/ 5005]    Overall Loss 1.317990    Objective Loss 1.317990    Top1 68.779364    Top5 87.029544    LR 0.000829    Time 0.181128    
2019-09-13 06:06:45,611 - Epoch: [2][ 4400/ 5005]    Overall Loss 1.318210    Objective Loss 1.318210    Top1 68.779031    Top5 87.027521    LR 0.000828    Time 0.181120    
2019-09-13 06:06:54,838 - Epoch: [2][ 4450/ 5005]    Overall Loss 1.318190    Objective Loss 1.318190    Top1 68.779143    Top5 87.031426    LR 0.000827    Time 0.181157    
2019-09-13 06:07:03,992 - Epoch: [2][ 4500/ 5005]    Overall Loss 1.318352    Objective Loss 1.318352    Top1 68.776649    Top5 87.028733    LR 0.000826    Time 0.181178    
2019-09-13 06:07:13,115 - Epoch: [2][ 4550/ 5005]    Overall Loss 1.318621    Objective Loss 1.318621    Top1 68.770862    Top5 87.026614    LR 0.000825    Time 0.181191    
2019-09-13 06:07:22,138 - Epoch: [2][ 4600/ 5005]    Overall Loss 1.318448    Objective Loss 1.318448    Top1 68.770975    Top5 87.030146    LR 0.000824    Time 0.181182    
2019-09-13 06:07:31,162 - Epoch: [2][ 4650/ 5005]    Overall Loss 1.318663    Objective Loss 1.318663    Top1 68.761593    Top5 87.027302    LR 0.000823    Time 0.181173    
2019-09-13 06:07:40,237 - Epoch: [2][ 4700/ 5005]    Overall Loss 1.318472    Objective Loss 1.318472    Top1 68.766041    Top5 87.032330    LR 0.000821    Time 0.181176    
2019-09-13 06:07:49,249 - Epoch: [2][ 4750/ 5005]    Overall Loss 1.318305    Objective Loss 1.318305    Top1 68.768586    Top5 87.032484    LR 0.000820    Time 0.181165    
2019-09-13 06:07:58,475 - Epoch: [2][ 4800/ 5005]    Overall Loss 1.318320    Objective Loss 1.318320    Top1 68.768473    Top5 87.033122    LR 0.000819    Time 0.181199    
2019-09-13 06:08:07,499 - Epoch: [2][ 4850/ 5005]    Overall Loss 1.318175    Objective Loss 1.318175    Top1 68.767236    Top5 87.034633    LR 0.000818    Time 0.181191    
2019-09-13 06:08:16,555 - Epoch: [2][ 4900/ 5005]    Overall Loss 1.318128    Objective Loss 1.318128    Top1 68.769292    Top5 87.034518    LR 0.000817    Time 0.181190    
2019-09-13 06:08:25,625 - Epoch: [2][ 4950/ 5005]    Overall Loss 1.318185    Objective Loss 1.318185    Top1 68.770202    Top5 87.035669    LR 0.000816    Time 0.181191    
2019-09-13 06:08:34,451 - Epoch: [2][ 5000/ 5005]    Overall Loss 1.318264    Objective Loss 1.318264    Top1 68.767969    Top5 87.037813    LR 0.000815    Time 0.181144    
2019-09-13 06:08:35,598 - 
Parameters:
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                      | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.float_weight                 | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12813 |  0.00003 |    0.07513 |
|  1 | module.conv1.weight                       | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16048 |  0.00013 |    0.09716 |
|  2 | module.layer1.0.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05276 | -0.00312 |    0.03124 |
|  3 | module.layer1.0.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07974 | -0.00440 |    0.04832 |
|  4 | module.layer1.0.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04465 | -0.00083 |    0.03162 |
|  5 | module.layer1.0.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10114 | -0.00186 |    0.07185 |
|  6 | module.layer1.1.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05022 | -0.00235 |    0.03385 |
|  7 | module.layer1.1.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08860 | -0.00417 |    0.06028 |
|  8 | module.layer1.1.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04344 | -0.00119 |    0.03112 |
|  9 | module.layer1.1.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12354 | -0.00339 |    0.08873 |
| 10 | module.layer2.0.conv1.float_weight        | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04108 | -0.00136 |    0.02904 |
| 11 | module.layer2.0.conv1.weight              | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12896 | -0.00427 |    0.09140 |
| 12 | module.layer2.0.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03359 | -0.00124 |    0.02364 |
| 13 | module.layer2.0.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08672 | -0.00322 |    0.06122 |
| 14 | module.layer2.0.downsample.0.float_weight | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06973 | -0.00261 |    0.04377 |
| 15 | module.layer2.0.downsample.0.weight       | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10542 | -0.00396 |    0.06726 |
| 16 | module.layer2.1.conv1.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03376 | -0.00147 |    0.02396 |
| 17 | module.layer2.1.conv1.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08466 | -0.00370 |    0.06027 |
| 18 | module.layer2.1.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02969 | -0.00125 |    0.02198 |
| 19 | module.layer2.1.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09142 | -0.00386 |    0.06776 |
| 20 | module.layer3.0.conv1.float_weight        | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02869 | -0.00135 |    0.02067 |
| 21 | module.layer3.0.conv1.weight              | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08087 | -0.00382 |    0.05840 |
| 22 | module.layer3.0.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02474 | -0.00076 |    0.01813 |
| 23 | module.layer3.0.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08244 | -0.00256 |    0.06049 |
| 24 | module.layer3.0.downsample.0.float_weight | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03253 | -0.00185 |    0.02347 |
| 25 | module.layer3.0.downsample.0.weight       | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12687 | -0.00725 |    0.09170 |
| 26 | module.layer3.1.conv1.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02210 | -0.00163 |    0.01645 |
| 27 | module.layer3.1.conv1.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08145 | -0.00600 |    0.06071 |
| 28 | module.layer3.1.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02043 | -0.00141 |    0.01534 |
| 29 | module.layer3.1.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06940 | -0.00479 |    0.05219 |
| 30 | module.layer4.0.conv1.float_weight        | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01963 | -0.00153 |    0.01503 |
| 31 | module.layer4.0.conv1.weight              | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06205 | -0.00482 |    0.04756 |
| 32 | module.layer4.0.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01712 | -0.00129 |    0.01322 |
| 33 | module.layer4.0.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05773 | -0.00434 |    0.04466 |
| 34 | module.layer4.0.downsample.0.float_weight | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03238 | -0.00083 |    0.02359 |
| 35 | module.layer4.0.downsample.0.weight       | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05230 | -0.00135 |    0.03825 |
| 36 | module.layer4.1.conv1.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01762 | -0.00222 |    0.01387 |
| 37 | module.layer4.1.conv1.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07510 | -0.00946 |    0.05916 |
| 38 | module.layer4.1.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01304 | -0.00009 |    0.00997 |
| 39 | module.layer4.1.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05358 | -0.00036 |    0.04103 |
| 40 | module.fc.float_weight                    | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06850 |  0.00000 |    0.05024 |
| 41 | module.fc.weight                          | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08832 | -0.00019 |    0.06520 |
| 42 | Total sparsity:                           | -                |      23357824 |       23357824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2019-09-13 06:08:35,598 - Total sparsity: 0.00

2019-09-13 06:08:35,598 - --- validate (epoch=2)-----------
2019-09-13 06:08:35,598 - 50000 samples (256 per mini-batch)
2019-09-13 06:08:46,614 - Epoch: [2][   50/  195]    Loss 0.937862    Top1 75.554688    Top5 93.218750    
2019-09-13 06:08:55,044 - Epoch: [2][  100/  195]    Loss 1.070574    Top1 73.312500    Top5 91.640625    
2019-09-13 06:09:02,663 - Epoch: [2][  150/  195]    Loss 1.211520    Top1 70.559896    Top5 89.648438    
2019-09-13 06:09:10,175 - ==> Top1: 69.550    Top5: 88.932    Loss: 1.271

2019-09-13 06:09:10,180 - ==> Best Top1: 69.550 on Epoch: 2
2019-09-13 06:09:10,180 - Saving checkpoint to: 8b_logs/res18___2019.09.13-052127/res18_checkpoint.pth.tar
2019-09-13 06:09:16,607 - Saving PACT param_value.......
2019-09-13 06:09:16,608 - The PACT Clip Parameter Value............
2019-09-13 06:09:16,616 - 

2019-09-13 06:09:16,616 - +--------------------------------+--------------+
| Layers                         |   PACT_alpha |
|--------------------------------+--------------|
| module.relu.clip_val           |      7.888   |
| module.layer1.0.relu1.clip_val |      7.88801 |
| module.layer1.0.relu2.clip_val |      7.88801 |
| module.layer1.1.relu1.clip_val |      7.88801 |
| module.layer1.1.relu2.clip_val |      7.88799 |
| module.layer2.0.relu1.clip_val |      7.88801 |
| module.layer2.0.relu2.clip_val |      7.88804 |
| module.layer2.1.relu1.clip_val |      7.88801 |
| module.layer2.1.relu2.clip_val |      7.88805 |
| module.layer3.0.relu1.clip_val |      7.88801 |
| module.layer3.0.relu2.clip_val |      7.88801 |
| module.layer3.1.relu1.clip_val |      7.88801 |
| module.layer3.1.relu2.clip_val |      7.88811 |
| module.layer4.0.relu1.clip_val |      7.88801 |
| module.layer4.0.relu2.clip_val |      7.88817 |
| module.layer4.1.relu1.clip_val |      7.88801 |
| module.layer4.1.relu2.clip_val |      8.07259 |
+--------------------------------+--------------+
2019-09-13 06:09:16,620 - 

2019-09-13 06:09:16,620 - Training epoch: 1281167 samples (256 per mini-batch)
2019-09-13 06:09:28,999 - Epoch: [3][   50/ 5005]    Overall Loss 1.312090    Objective Loss 1.312090    Top1 68.531250    Top5 87.367188    LR 0.000813    Time 0.247491    
2019-09-13 06:09:37,939 - Epoch: [3][  100/ 5005]    Overall Loss 1.305246    Objective Loss 1.305246    Top1 68.914062    Top5 87.316406    LR 0.000812    Time 0.213121    
2019-09-13 06:09:46,894 - Epoch: [3][  150/ 5005]    Overall Loss 1.312828    Objective Loss 1.312828    Top1 68.742188    Top5 87.117188    LR 0.000811    Time 0.201760    
2019-09-13 06:09:55,912 - Epoch: [3][  200/ 5005]    Overall Loss 1.317494    Objective Loss 1.317494    Top1 68.667969    Top5 87.054688    LR 0.000810    Time 0.196395    
2019-09-13 06:10:04,819 - Epoch: [3][  250/ 5005]    Overall Loss 1.312350    Objective Loss 1.312350    Top1 68.756250    Top5 87.195312    LR 0.000809    Time 0.192730    
2019-09-13 06:10:13,675 - Epoch: [3][  300/ 5005]    Overall Loss 1.312728    Objective Loss 1.312728    Top1 68.708333    Top5 87.213542    LR 0.000808    Time 0.190118    
2019-09-13 06:10:22,608 - Epoch: [3][  350/ 5005]    Overall Loss 1.307526    Objective Loss 1.307526    Top1 68.742188    Top5 87.338170    LR 0.000806    Time 0.188471    
2019-09-13 06:10:31,469 - Epoch: [3][  400/ 5005]    Overall Loss 1.306134    Objective Loss 1.306134    Top1 68.793945    Top5 87.335938    LR 0.000805    Time 0.187056    
2019-09-13 06:10:40,287 - Epoch: [3][  450/ 5005]    Overall Loss 1.306989    Objective Loss 1.306989    Top1 68.759549    Top5 87.301215    LR 0.000804    Time 0.185860    
2019-09-13 06:10:49,507 - Epoch: [3][  500/ 5005]    Overall Loss 1.307991    Objective Loss 1.307991    Top1 68.723438    Top5 87.240625    LR 0.000803    Time 0.185709    
2019-09-13 06:10:58,755 - Epoch: [3][  550/ 5005]    Overall Loss 1.306302    Objective Loss 1.306302    Top1 68.789773    Top5 87.266335    LR 0.000802    Time 0.185636    
2019-09-13 06:11:07,982 - Epoch: [3][  600/ 5005]    Overall Loss 1.305733    Objective Loss 1.305733    Top1 68.832031    Top5 87.274089    LR 0.000801    Time 0.185538    
2019-09-13 06:11:17,360 - Epoch: [3][  650/ 5005]    Overall Loss 1.305468    Objective Loss 1.305468    Top1 68.847957    Top5 87.273438    LR 0.000799    Time 0.185689    
2019-09-13 06:11:26,497 - Epoch: [3][  700/ 5005]    Overall Loss 1.304797    Objective Loss 1.304797    Top1 68.852679    Top5 87.284040    LR 0.000798    Time 0.185472    
2019-09-13 06:11:43,156 - Epoch: [3][  750/ 5005]    Overall Loss 1.304128    Objective Loss 1.304128    Top1 68.852604    Top5 87.292708    LR 0.000797    Time 0.195314    
2019-09-13 06:11:52,476 - Epoch: [3][  800/ 5005]    Overall Loss 1.303809    Objective Loss 1.303809    Top1 68.870117    Top5 87.287109    LR 0.000796    Time 0.194754    
2019-09-13 06:12:01,451 - Epoch: [3][  850/ 5005]    Overall Loss 1.306645    Objective Loss 1.306645    Top1 68.825827    Top5 87.228860    LR 0.000795    Time 0.193854    
2019-09-13 06:12:10,381 - Epoch: [3][  900/ 5005]    Overall Loss 1.305921    Objective Loss 1.305921    Top1 68.858073    Top5 87.236979    LR 0.000794    Time 0.193002    
2019-09-13 06:12:19,381 - Epoch: [3][  950/ 5005]    Overall Loss 1.304400    Objective Loss 1.304400    Top1 68.875822    Top5 87.264391    LR 0.000792    Time 0.192314    
2019-09-13 06:12:28,305 - Epoch: [3][ 1000/ 5005]    Overall Loss 1.302582    Objective Loss 1.302582    Top1 68.911328    Top5 87.300000    LR 0.000791    Time 0.191619    
2019-09-13 06:12:37,275 - Epoch: [3][ 1050/ 5005]    Overall Loss 1.303236    Objective Loss 1.303236    Top1 68.919643    Top5 87.276786    LR 0.000790    Time 0.191035    
2019-09-13 06:12:46,084 - Epoch: [3][ 1100/ 5005]    Overall Loss 1.303132    Objective Loss 1.303132    Top1 68.914418    Top5 87.284801    LR 0.000789    Time 0.190355    
2019-09-13 06:12:54,875 - Epoch: [3][ 1150/ 5005]    Overall Loss 1.304262    Objective Loss 1.304262    Top1 68.889606    Top5 87.274796    LR 0.000788    Time 0.189720    
2019-09-13 06:13:03,672 - Epoch: [3][ 1200/ 5005]    Overall Loss 1.304153    Objective Loss 1.304153    Top1 68.900065    Top5 87.272461    LR 0.000786    Time 0.189144    
2019-09-13 06:13:12,575 - Epoch: [3][ 1250/ 5005]    Overall Loss 1.305959    Objective Loss 1.305959    Top1 68.869687    Top5 87.251250    LR 0.000785    Time 0.188698    
2019-09-13 06:13:21,521 - Epoch: [3][ 1300/ 5005]    Overall Loss 1.306785    Objective Loss 1.306785    Top1 68.836238    Top5 87.243690    LR 0.000784    Time 0.188319    
2019-09-13 06:13:30,429 - Epoch: [3][ 1350/ 5005]    Overall Loss 1.307505    Objective Loss 1.307505    Top1 68.825810    Top5 87.229745    LR 0.000783    Time 0.187940    
2019-09-13 06:13:39,427 - Epoch: [3][ 1400/ 5005]    Overall Loss 1.307299    Objective Loss 1.307299    Top1 68.838728    Top5 87.230469    LR 0.000782    Time 0.187653    
2019-09-13 06:13:48,380 - Epoch: [3][ 1450/ 5005]    Overall Loss 1.306989    Objective Loss 1.306989    Top1 68.847522    Top5 87.224407    LR 0.000780    Time 0.187354    
2019-09-13 06:13:57,372 - Epoch: [3][ 1500/ 5005]    Overall Loss 1.306565    Objective Loss 1.306565    Top1 68.856771    Top5 87.228385    LR 0.000779    Time 0.187101    
2019-09-13 06:14:06,402 - Epoch: [3][ 1550/ 5005]    Overall Loss 1.306649    Objective Loss 1.306649    Top1 68.859627    Top5 87.228579    LR 0.000778    Time 0.186889    
2019-09-13 06:14:15,409 - Epoch: [3][ 1600/ 5005]    Overall Loss 1.307107    Objective Loss 1.307107    Top1 68.859863    Top5 87.220459    LR 0.000777    Time 0.186676    
2019-09-13 06:14:24,379 - Epoch: [3][ 1650/ 5005]    Overall Loss 1.307344    Objective Loss 1.307344    Top1 68.860559    Top5 87.210227    LR 0.000775    Time 0.186453    
2019-09-13 06:14:33,343 - Epoch: [3][ 1700/ 5005]    Overall Loss 1.308105    Objective Loss 1.308105    Top1 68.857996    Top5 87.195312    LR 0.000774    Time 0.186240    
2019-09-13 06:14:42,244 - Epoch: [3][ 1750/ 5005]    Overall Loss 1.307915    Objective Loss 1.307915    Top1 68.867634    Top5 87.194866    LR 0.000773    Time 0.186004    
2019-09-13 06:14:51,077 - Epoch: [3][ 1800/ 5005]    Overall Loss 1.308024    Objective Loss 1.308024    Top1 68.867622    Top5 87.184245    LR 0.000772    Time 0.185742    
2019-09-13 06:15:00,105 - Epoch: [3][ 1850/ 5005]    Overall Loss 1.308183    Objective Loss 1.308183    Top1 68.868243    Top5 87.176731    LR 0.000771    Time 0.185600    
2019-09-13 06:15:08,905 - Epoch: [3][ 1900/ 5005]    Overall Loss 1.307487    Objective Loss 1.307487    Top1 68.894942    Top5 87.189967    LR 0.000769    Time 0.185346    
2019-09-13 06:15:17,759 - Epoch: [3][ 1950/ 5005]    Overall Loss 1.307960    Objective Loss 1.307960    Top1 68.881611    Top5 87.177684    LR 0.000768    Time 0.185132    
2019-09-13 06:15:26,708 - Epoch: [3][ 2000/ 5005]    Overall Loss 1.308719    Objective Loss 1.308719    Top1 68.877148    Top5 87.166211    LR 0.000767    Time 0.184977    
2019-09-13 06:15:35,656 - Epoch: [3][ 2050/ 5005]    Overall Loss 1.308384    Objective Loss 1.308384    Top1 68.890244    Top5 87.172066    LR 0.000766    Time 0.184828    
2019-09-13 06:15:44,577 - Epoch: [3][ 2100/ 5005]    Overall Loss 1.307646    Objective Loss 1.307646    Top1 68.911644    Top5 87.184710    LR 0.000764    Time 0.184674    
2019-09-13 06:15:53,396 - Epoch: [3][ 2150/ 5005]    Overall Loss 1.307873    Objective Loss 1.307873    Top1 68.913517    Top5 87.171693    LR 0.000763    Time 0.184479    
2019-09-13 06:16:02,203 - Epoch: [3][ 2200/ 5005]    Overall Loss 1.308015    Objective Loss 1.308015    Top1 68.899325    Top5 87.175249    LR 0.000762    Time 0.184289    
2019-09-13 06:16:11,089 - Epoch: [3][ 2250/ 5005]    Overall Loss 1.308619    Objective Loss 1.308619    Top1 68.891667    Top5 87.173611    LR 0.000761    Time 0.184142    
2019-09-13 06:16:20,025 - Epoch: [3][ 2300/ 5005]    Overall Loss 1.309027    Objective Loss 1.309027    Top1 68.879925    Top5 87.165931    LR 0.000759    Time 0.184022    
2019-09-13 06:16:28,868 - Epoch: [3][ 2350/ 5005]    Overall Loss 1.309448    Objective Loss 1.309448    Top1 68.880652    Top5 87.165060    LR 0.000758    Time 0.183868    
2019-09-13 06:16:37,688 - Epoch: [3][ 2400/ 5005]    Overall Loss 1.309555    Objective Loss 1.309555    Top1 68.884277    Top5 87.163737    LR 0.000757    Time 0.183711    
2019-09-13 06:16:46,521 - Epoch: [3][ 2450/ 5005]    Overall Loss 1.308877    Objective Loss 1.308877    Top1 68.900191    Top5 87.168527    LR 0.000756    Time 0.183566    
2019-09-13 06:16:55,341 - Epoch: [3][ 2500/ 5005]    Overall Loss 1.309001    Objective Loss 1.309001    Top1 68.906875    Top5 87.173906    LR 0.000754    Time 0.183422    
2019-09-13 06:17:04,185 - Epoch: [3][ 2550/ 5005]    Overall Loss 1.308684    Objective Loss 1.308684    Top1 68.906250    Top5 87.170803    LR 0.000753    Time 0.183293    
2019-09-13 06:17:13,077 - Epoch: [3][ 2600/ 5005]    Overall Loss 1.309029    Objective Loss 1.309029    Top1 68.901442    Top5 87.167218    LR 0.000752    Time 0.183187    
2019-09-13 06:17:22,090 - Epoch: [3][ 2650/ 5005]    Overall Loss 1.309651    Objective Loss 1.309651    Top1 68.890920    Top5 87.157429    LR 0.000751    Time 0.183130    
2019-09-13 06:17:30,912 - Epoch: [3][ 2700/ 5005]    Overall Loss 1.309633    Objective Loss 1.309633    Top1 68.899161    Top5 87.154369    LR 0.000749    Time 0.183005    
2019-09-13 06:17:39,916 - Epoch: [3][ 2750/ 5005]    Overall Loss 1.309687    Objective Loss 1.309687    Top1 68.897443    Top5 87.150710    LR 0.000748    Time 0.182950    
2019-09-13 06:17:48,884 - Epoch: [3][ 2800/ 5005]    Overall Loss 1.309675    Objective Loss 1.309675    Top1 68.900112    Top5 87.152204    LR 0.000747    Time 0.182885    
2019-09-13 06:17:57,828 - Epoch: [3][ 2850/ 5005]    Overall Loss 1.309919    Objective Loss 1.309919    Top1 68.898300    Top5 87.150082    LR 0.000746    Time 0.182813    
2019-09-13 06:18:06,697 - Epoch: [3][ 2900/ 5005]    Overall Loss 1.309977    Objective Loss 1.309977    Top1 68.895205    Top5 87.148303    LR 0.000744    Time 0.182718    
2019-09-13 06:18:15,602 - Epoch: [3][ 2950/ 5005]    Overall Loss 1.309718    Objective Loss 1.309718    Top1 68.898173    Top5 87.154529    LR 0.000743    Time 0.182639    
2019-09-13 06:18:24,487 - Epoch: [3][ 3000/ 5005]    Overall Loss 1.310389    Objective Loss 1.310389    Top1 68.882292    Top5 87.138542    LR 0.000742    Time 0.182556    
2019-09-13 06:18:33,417 - Epoch: [3][ 3050/ 5005]    Overall Loss 1.310166    Objective Loss 1.310166    Top1 68.882684    Top5 87.139472    LR 0.000740    Time 0.182490    
2019-09-13 06:18:42,361 - Epoch: [3][ 3100/ 5005]    Overall Loss 1.310147    Objective Loss 1.310147    Top1 68.893649    Top5 87.141129    LR 0.000739    Time 0.182431    
2019-09-13 06:18:51,297 - Epoch: [3][ 3150/ 5005]    Overall Loss 1.310543    Objective Loss 1.310543    Top1 68.880828    Top5 87.138393    LR 0.000738    Time 0.182371    
2019-09-13 06:19:00,237 - Epoch: [3][ 3200/ 5005]    Overall Loss 1.310508    Objective Loss 1.310508    Top1 68.884033    Top5 87.143311    LR 0.000737    Time 0.182314    
2019-09-13 06:19:09,283 - Epoch: [3][ 3250/ 5005]    Overall Loss 1.310875    Objective Loss 1.310875    Top1 68.870312    Top5 87.139543    LR 0.000735    Time 0.182291    
2019-09-13 06:19:18,289 - Epoch: [3][ 3300/ 5005]    Overall Loss 1.310912    Objective Loss 1.310912    Top1 68.872159    Top5 87.141927    LR 0.000734    Time 0.182258    
2019-09-13 06:19:27,230 - Epoch: [3][ 3350/ 5005]    Overall Loss 1.310847    Objective Loss 1.310847    Top1 68.869636    Top5 87.139226    LR 0.000733    Time 0.182205    
2019-09-13 06:19:36,217 - Epoch: [3][ 3400/ 5005]    Overall Loss 1.310753    Objective Loss 1.310753    Top1 68.875804    Top5 87.143267    LR 0.000731    Time 0.182168    
2019-09-13 06:19:45,175 - Epoch: [3][ 3450/ 5005]    Overall Loss 1.311070    Objective Loss 1.311070    Top1 68.863678    Top5 87.133379    LR 0.000730    Time 0.182124    
2019-09-13 06:19:54,099 - Epoch: [3][ 3500/ 5005]    Overall Loss 1.311216    Objective Loss 1.311216    Top1 68.863728    Top5 87.129464    LR 0.000729    Time 0.182071    
2019-09-13 06:20:03,027 - Epoch: [3][ 3550/ 5005]    Overall Loss 1.311479    Objective Loss 1.311479    Top1 68.856294    Top5 87.123349    LR 0.000728    Time 0.182020    
2019-09-13 06:20:11,988 - Epoch: [3][ 3600/ 5005]    Overall Loss 1.311279    Objective Loss 1.311279    Top1 68.857096    Top5 87.123806    LR 0.000726    Time 0.181981    
2019-09-13 06:20:21,148 - Epoch: [3][ 3650/ 5005]    Overall Loss 1.311057    Objective Loss 1.311057    Top1 68.867188    Top5 87.122217    LR 0.000725    Time 0.181996    
2019-09-13 06:20:30,448 - Epoch: [3][ 3700/ 5005]    Overall Loss 1.311134    Objective Loss 1.311134    Top1 68.863915    Top5 87.121622    LR 0.000724    Time 0.182049    
2019-09-13 06:20:39,683 - Epoch: [3][ 3750/ 5005]    Overall Loss 1.311666    Objective Loss 1.311666    Top1 68.856042    Top5 87.113333    LR 0.000722    Time 0.182083    
2019-09-13 06:20:48,768 - Epoch: [3][ 3800/ 5005]    Overall Loss 1.311716    Objective Loss 1.311716    Top1 68.855983    Top5 87.112459    LR 0.000721    Time 0.182077    
2019-09-13 06:20:57,851 - Epoch: [3][ 3850/ 5005]    Overall Loss 1.312048    Objective Loss 1.312048    Top1 68.849127    Top5 87.108868    LR 0.000720    Time 0.182071    
2019-09-13 06:21:07,032 - Epoch: [3][ 3900/ 5005]    Overall Loss 1.312202    Objective Loss 1.312202    Top1 68.837540    Top5 87.108173    LR 0.000718    Time 0.182089    
2019-09-13 06:21:16,145 - Epoch: [3][ 3950/ 5005]    Overall Loss 1.312381    Objective Loss 1.312381    Top1 68.837619    Top5 87.106408    LR 0.000717    Time 0.182090    
2019-09-13 06:21:25,245 - Epoch: [3][ 4000/ 5005]    Overall Loss 1.312453    Objective Loss 1.312453    Top1 68.837305    Top5 87.106152    LR 0.000716    Time 0.182088    
2019-09-13 06:21:34,204 - Epoch: [3][ 4050/ 5005]    Overall Loss 1.312376    Objective Loss 1.312376    Top1 68.838638    Top5 87.109375    LR 0.000714    Time 0.182051    
2019-09-13 06:21:43,313 - Epoch: [3][ 4100/ 5005]    Overall Loss 1.312237    Objective Loss 1.312237    Top1 68.845274    Top5 87.110709    LR 0.000713    Time 0.182052    
2019-09-13 06:21:52,644 - Epoch: [3][ 4150/ 5005]    Overall Loss 1.312356    Objective Loss 1.312356    Top1 68.840738    Top5 87.106175    LR 0.000712    Time 0.182106    
2019-09-13 06:22:01,721 - Epoch: [3][ 4200/ 5005]    Overall Loss 1.312056    Objective Loss 1.312056    Top1 68.852214    Top5 87.110305    LR 0.000711    Time 0.182098    
2019-09-13 06:22:10,750 - Epoch: [3][ 4250/ 5005]    Overall Loss 1.311998    Objective Loss 1.311998    Top1 68.856158    Top5 87.109007    LR 0.000709    Time 0.182079    
2019-09-13 06:22:19,810 - Epoch: [3][ 4300/ 5005]    Overall Loss 1.311670    Objective Loss 1.311670    Top1 68.865825    Top5 87.112009    LR 0.000708    Time 0.182069    
2019-09-13 06:22:28,794 - Epoch: [3][ 4350/ 5005]    Overall Loss 1.311898    Objective Loss 1.311898    Top1 68.860363    Top5 87.109824    LR 0.000707    Time 0.182040    
2019-09-13 06:22:37,765 - Epoch: [3][ 4400/ 5005]    Overall Loss 1.312076    Objective Loss 1.312076    Top1 68.851740    Top5 87.107422    LR 0.000705    Time 0.182010    
2019-09-13 06:22:46,814 - Epoch: [3][ 4450/ 5005]    Overall Loss 1.312285    Objective Loss 1.312285    Top1 68.846910    Top5 87.106654    LR 0.000704    Time 0.181998    
2019-09-13 06:22:55,762 - Epoch: [3][ 4500/ 5005]    Overall Loss 1.312416    Objective Loss 1.312416    Top1 68.848438    Top5 87.105122    LR 0.000703    Time 0.181963    
2019-09-13 06:23:04,636 - Epoch: [3][ 4550/ 5005]    Overall Loss 1.312877    Objective Loss 1.312877    Top1 68.843149    Top5 87.099588    LR 0.000701    Time 0.181913    
2019-09-13 06:23:13,706 - Epoch: [3][ 4600/ 5005]    Overall Loss 1.312732    Objective Loss 1.312732    Top1 68.845703    Top5 87.103855    LR 0.000700    Time 0.181907    
2019-09-13 06:23:22,599 - Epoch: [3][ 4650/ 5005]    Overall Loss 1.312662    Objective Loss 1.312662    Top1 68.848454    Top5 87.107527    LR 0.000699    Time 0.181863    
2019-09-13 06:23:31,529 - Epoch: [3][ 4700/ 5005]    Overall Loss 1.312567    Objective Loss 1.312567    Top1 68.849817    Top5 87.109126    LR 0.000697    Time 0.181827    
2019-09-13 06:23:40,469 - Epoch: [3][ 4750/ 5005]    Overall Loss 1.312511    Objective Loss 1.312511    Top1 68.850000    Top5 87.107319    LR 0.000696    Time 0.181795    
2019-09-13 06:23:49,440 - Epoch: [3][ 4800/ 5005]    Overall Loss 1.312887    Objective Loss 1.312887    Top1 68.843831    Top5 87.103027    LR 0.000695    Time 0.181769    
2019-09-13 06:23:58,398 - Epoch: [3][ 4850/ 5005]    Overall Loss 1.313361    Objective Loss 1.313361    Top1 68.839320    Top5 87.099871    LR 0.000693    Time 0.181742    
2019-09-13 06:24:07,358 - Epoch: [3][ 4900/ 5005]    Overall Loss 1.313237    Objective Loss 1.313237    Top1 68.841677    Top5 87.102200    LR 0.000692    Time 0.181715    
2019-09-13 06:24:16,304 - Epoch: [3][ 4950/ 5005]    Overall Loss 1.313102    Objective Loss 1.313102    Top1 68.840436    Top5 87.101878    LR 0.000691    Time 0.181686    
2019-09-13 06:24:25,108 - Epoch: [3][ 5000/ 5005]    Overall Loss 1.313111    Objective Loss 1.313111    Top1 68.840078    Top5 87.103672    LR 0.000689    Time 0.181630    
2019-09-13 06:24:26,259 - 
Parameters:
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                      | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.float_weight                 | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12771 |  0.00002 |    0.07488 |
|  1 | module.conv1.weight                       | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16037 |  0.00013 |    0.09704 |
|  2 | module.layer1.0.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05259 | -0.00313 |    0.03113 |
|  3 | module.layer1.0.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07992 | -0.00444 |    0.04842 |
|  4 | module.layer1.0.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04450 | -0.00082 |    0.03151 |
|  5 | module.layer1.0.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10156 | -0.00185 |    0.07216 |
|  6 | module.layer1.1.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05006 | -0.00232 |    0.03373 |
|  7 | module.layer1.1.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08871 | -0.00412 |    0.06035 |
|  8 | module.layer1.1.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04330 | -0.00119 |    0.03102 |
|  9 | module.layer1.1.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12368 | -0.00339 |    0.08885 |
| 10 | module.layer2.0.conv1.float_weight        | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04094 | -0.00136 |    0.02894 |
| 11 | module.layer2.0.conv1.weight              | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12961 | -0.00431 |    0.09185 |
| 12 | module.layer2.0.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03348 | -0.00123 |    0.02356 |
| 13 | module.layer2.0.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08692 | -0.00323 |    0.06134 |
| 14 | module.layer2.0.downsample.0.float_weight | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06949 | -0.00257 |    0.04362 |
| 15 | module.layer2.0.downsample.0.weight       | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10536 | -0.00386 |    0.06717 |
| 16 | module.layer2.1.conv1.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03365 | -0.00146 |    0.02388 |
| 17 | module.layer2.1.conv1.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08494 | -0.00369 |    0.06046 |
| 18 | module.layer2.1.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02959 | -0.00124 |    0.02190 |
| 19 | module.layer2.1.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09240 | -0.00389 |    0.06849 |
| 20 | module.layer3.0.conv1.float_weight        | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02859 | -0.00133 |    0.02060 |
| 21 | module.layer3.0.conv1.weight              | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08139 | -0.00381 |    0.05877 |
| 22 | module.layer3.0.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02466 | -0.00076 |    0.01806 |
| 23 | module.layer3.0.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08352 | -0.00258 |    0.06128 |
| 24 | module.layer3.0.downsample.0.float_weight | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03242 | -0.00185 |    0.02339 |
| 25 | module.layer3.0.downsample.0.weight       | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12670 | -0.00723 |    0.09157 |
| 26 | module.layer3.1.conv1.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02202 | -0.00161 |    0.01640 |
| 27 | module.layer3.1.conv1.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08275 | -0.00607 |    0.06169 |
| 28 | module.layer3.1.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02036 | -0.00140 |    0.01529 |
| 29 | module.layer3.1.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07066 | -0.00487 |    0.05313 |
| 30 | module.layer4.0.conv1.float_weight        | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01957 | -0.00152 |    0.01498 |
| 31 | module.layer4.0.conv1.weight              | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06463 | -0.00501 |    0.04953 |
| 32 | module.layer4.0.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01706 | -0.00128 |    0.01318 |
| 33 | module.layer4.0.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05911 | -0.00443 |    0.04572 |
| 34 | module.layer4.0.downsample.0.float_weight | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03227 | -0.00082 |    0.02351 |
| 35 | module.layer4.0.downsample.0.weight       | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05253 | -0.00134 |    0.03842 |
| 36 | module.layer4.1.conv1.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01756 | -0.00221 |    0.01382 |
| 37 | module.layer4.1.conv1.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07644 | -0.00961 |    0.06022 |
| 38 | module.layer4.1.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01299 | -0.00008 |    0.00994 |
| 39 | module.layer4.1.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05447 | -0.00035 |    0.04172 |
| 40 | module.fc.float_weight                    | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06825 |  0.00000 |    0.05007 |
| 41 | module.fc.weight                          | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08981 | -0.00020 |    0.06631 |
| 42 | Total sparsity:                           | -                |      23357824 |       23357824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2019-09-13 06:24:26,259 - Total sparsity: 0.00

2019-09-13 06:24:26,259 - --- validate (epoch=3)-----------
2019-09-13 06:24:26,259 - 50000 samples (256 per mini-batch)
2019-09-13 06:24:37,332 - Epoch: [3][   50/  195]    Loss 0.931649    Top1 76.218750    Top5 93.195312    
2019-09-13 06:24:45,291 - Epoch: [3][  100/  195]    Loss 1.066253    Top1 73.601562    Top5 91.609375    
2019-09-13 06:24:53,490 - Epoch: [3][  150/  195]    Loss 1.207933    Top1 70.656250    Top5 89.677083    
2019-09-13 06:25:00,776 - ==> Top1: 69.622    Top5: 89.034    Loss: 1.266

2019-09-13 06:25:00,780 - ==> Best Top1: 69.622 on Epoch: 3
2019-09-13 06:25:00,780 - Saving checkpoint to: 8b_logs/res18___2019.09.13-052127/res18_checkpoint.pth.tar
2019-09-13 06:25:07,038 - Saving PACT param_value.......
2019-09-13 06:25:07,039 - The PACT Clip Parameter Value............
2019-09-13 06:25:07,045 - 

2019-09-13 06:25:07,045 - +--------------------------------+--------------+
| Layers                         |   PACT_alpha |
|--------------------------------+--------------|
| module.relu.clip_val           |      7.85836 |
| module.layer1.0.relu1.clip_val |      7.85838 |
| module.layer1.0.relu2.clip_val |      7.85837 |
| module.layer1.1.relu1.clip_val |      7.85838 |
| module.layer1.1.relu2.clip_val |      7.85834 |
| module.layer2.0.relu1.clip_val |      7.85838 |
| module.layer2.0.relu2.clip_val |      7.85843 |
| module.layer2.1.relu1.clip_val |      7.85838 |
| module.layer2.1.relu2.clip_val |      7.85842 |
| module.layer3.0.relu1.clip_val |      7.85838 |
| module.layer3.0.relu2.clip_val |      7.85838 |
| module.layer3.1.relu1.clip_val |      7.85838 |
| module.layer3.1.relu2.clip_val |      7.85848 |
| module.layer4.0.relu1.clip_val |      7.85838 |
| module.layer4.0.relu2.clip_val |      7.85853 |
| module.layer4.1.relu1.clip_val |      7.85838 |
| module.layer4.1.relu2.clip_val |      8.09005 |
+--------------------------------+--------------+
2019-09-13 06:25:07,049 - 

2019-09-13 06:25:07,049 - Training epoch: 1281167 samples (256 per mini-batch)
2019-09-13 06:25:19,455 - Epoch: [4][   50/ 5005]    Overall Loss 1.262548    Objective Loss 1.262548    Top1 69.234375    Top5 87.734375    LR 0.000688    Time 0.248018    
2019-09-13 06:25:28,367 - Epoch: [4][  100/ 5005]    Overall Loss 1.294467    Objective Loss 1.294467    Top1 68.859375    Top5 87.320312    LR 0.000686    Time 0.213095    
2019-09-13 06:25:37,414 - Epoch: [4][  150/ 5005]    Overall Loss 1.288809    Objective Loss 1.288809    Top1 69.223958    Top5 87.369792    LR 0.000685    Time 0.202355    
2019-09-13 06:25:46,476 - Epoch: [4][  200/ 5005]    Overall Loss 1.296084    Objective Loss 1.296084    Top1 69.087891    Top5 87.283203    LR 0.000684    Time 0.197057    
2019-09-13 06:25:55,394 - Epoch: [4][  250/ 5005]    Overall Loss 1.299314    Objective Loss 1.299314    Top1 68.992188    Top5 87.175000    LR 0.000682    Time 0.193306    
2019-09-13 06:26:04,489 - Epoch: [4][  300/ 5005]    Overall Loss 1.297191    Objective Loss 1.297191    Top1 69.024740    Top5 87.222656    LR 0.000681    Time 0.191389    
2019-09-13 06:26:13,373 - Epoch: [4][  350/ 5005]    Overall Loss 1.303937    Objective Loss 1.303937    Top1 68.929687    Top5 87.155134    LR 0.000680    Time 0.189422    
2019-09-13 06:26:22,307 - Epoch: [4][  400/ 5005]    Overall Loss 1.305376    Objective Loss 1.305376    Top1 68.912109    Top5 87.125000    LR 0.000678    Time 0.188072    
2019-09-13 06:26:31,370 - Epoch: [4][  450/ 5005]    Overall Loss 1.303757    Objective Loss 1.303757    Top1 68.976562    Top5 87.149306    LR 0.000677    Time 0.187309    
2019-09-13 06:26:40,442 - Epoch: [4][  500/ 5005]    Overall Loss 1.302870    Objective Loss 1.302870    Top1 68.989844    Top5 87.178906    LR 0.000676    Time 0.186716    
2019-09-13 06:26:49,337 - Epoch: [4][  550/ 5005]    Overall Loss 1.300859    Objective Loss 1.300859    Top1 68.990057    Top5 87.213068    LR 0.000674    Time 0.185908    
2019-09-13 06:26:58,222 - Epoch: [4][  600/ 5005]    Overall Loss 1.299381    Objective Loss 1.299381    Top1 69.040365    Top5 87.265625    LR 0.000673    Time 0.185219    
2019-09-13 06:27:07,120 - Epoch: [4][  650/ 5005]    Overall Loss 1.300391    Objective Loss 1.300391    Top1 68.990385    Top5 87.243990    LR 0.000672    Time 0.184655    
2019-09-13 06:27:16,129 - Epoch: [4][  700/ 5005]    Overall Loss 1.302797    Objective Loss 1.302797    Top1 68.923549    Top5 87.203125    LR 0.000670    Time 0.184331    
2019-09-13 06:27:25,461 - Epoch: [4][  750/ 5005]    Overall Loss 1.302199    Objective Loss 1.302199    Top1 68.961979    Top5 87.216146    LR 0.000669    Time 0.184480    
2019-09-13 06:27:34,506 - Epoch: [4][  800/ 5005]    Overall Loss 1.302673    Objective Loss 1.302673    Top1 68.950195    Top5 87.227539    LR 0.000667    Time 0.184251    
2019-09-13 06:27:43,616 - Epoch: [4][  850/ 5005]    Overall Loss 1.302117    Objective Loss 1.302117    Top1 68.945312    Top5 87.249081    LR 0.000666    Time 0.184125    
2019-09-13 06:27:52,559 - Epoch: [4][  900/ 5005]    Overall Loss 1.302094    Objective Loss 1.302094    Top1 68.960938    Top5 87.249566    LR 0.000665    Time 0.183829    
2019-09-13 06:28:01,695 - Epoch: [4][  950/ 5005]    Overall Loss 1.303879    Objective Loss 1.303879    Top1 68.937911    Top5 87.231908    LR 0.000663    Time 0.183767    
2019-09-13 06:28:10,794 - Epoch: [4][ 1000/ 5005]    Overall Loss 1.303523    Objective Loss 1.303523    Top1 68.953906    Top5 87.236328    LR 0.000662    Time 0.183673    
2019-09-13 06:28:19,899 - Epoch: [4][ 1050/ 5005]    Overall Loss 1.304014    Objective Loss 1.304014    Top1 68.927827    Top5 87.240699    LR 0.000661    Time 0.183594    
2019-09-13 06:28:28,968 - Epoch: [4][ 1100/ 5005]    Overall Loss 1.303659    Objective Loss 1.303659    Top1 68.920810    Top5 87.235085    LR 0.000659    Time 0.183490    
2019-09-13 06:28:38,022 - Epoch: [4][ 1150/ 5005]    Overall Loss 1.303947    Objective Loss 1.303947    Top1 68.907948    Top5 87.233696    LR 0.000658    Time 0.183382    
2019-09-13 06:28:47,105 - Epoch: [4][ 1200/ 5005]    Overall Loss 1.303625    Objective Loss 1.303625    Top1 68.917318    Top5 87.240885    LR 0.000656    Time 0.183307    
2019-09-13 06:28:56,363 - Epoch: [4][ 1250/ 5005]    Overall Loss 1.303061    Objective Loss 1.303061    Top1 68.916875    Top5 87.237188    LR 0.000655    Time 0.183378    
2019-09-13 06:29:05,392 - Epoch: [4][ 1300/ 5005]    Overall Loss 1.302546    Objective Loss 1.302546    Top1 68.926983    Top5 87.241887    LR 0.000654    Time 0.183268    
2019-09-13 06:29:14,433 - Epoch: [4][ 1350/ 5005]    Overall Loss 1.302417    Objective Loss 1.302417    Top1 68.937789    Top5 87.239005    LR 0.000652    Time 0.183173    
2019-09-13 06:29:23,496 - Epoch: [4][ 1400/ 5005]    Overall Loss 1.302653    Objective Loss 1.302653    Top1 68.942801    Top5 87.241071    LR 0.000651    Time 0.183102    
2019-09-13 06:29:32,503 - Epoch: [4][ 1450/ 5005]    Overall Loss 1.303531    Objective Loss 1.303531    Top1 68.934806    Top5 87.226832    LR 0.000650    Time 0.182997    
2019-09-13 06:29:41,484 - Epoch: [4][ 1500/ 5005]    Overall Loss 1.303719    Objective Loss 1.303719    Top1 68.931250    Top5 87.217448    LR 0.000648    Time 0.182882    
2019-09-13 06:29:50,453 - Epoch: [4][ 1550/ 5005]    Overall Loss 1.303923    Objective Loss 1.303923    Top1 68.944808    Top5 87.218246    LR 0.000647    Time 0.182767    
2019-09-13 06:29:59,509 - Epoch: [4][ 1600/ 5005]    Overall Loss 1.303972    Objective Loss 1.303972    Top1 68.945801    Top5 87.215820    LR 0.000645    Time 0.182713    
2019-09-13 06:30:08,560 - Epoch: [4][ 1650/ 5005]    Overall Loss 1.304084    Objective Loss 1.304084    Top1 68.947206    Top5 87.212358    LR 0.000644    Time 0.182659    
2019-09-13 06:30:17,793 - Epoch: [4][ 1700/ 5005]    Overall Loss 1.304288    Objective Loss 1.304288    Top1 68.954044    Top5 87.215533    LR 0.000643    Time 0.182715    
2019-09-13 06:30:26,804 - Epoch: [4][ 1750/ 5005]    Overall Loss 1.304093    Objective Loss 1.304093    Top1 68.960491    Top5 87.216071    LR 0.000641    Time 0.182641    
2019-09-13 06:30:35,873 - Epoch: [4][ 1800/ 5005]    Overall Loss 1.303897    Objective Loss 1.303897    Top1 68.979384    Top5 87.222873    LR 0.000640    Time 0.182603    
2019-09-13 06:30:44,853 - Epoch: [4][ 1850/ 5005]    Overall Loss 1.303035    Objective Loss 1.303035    Top1 69.001900    Top5 87.238176    LR 0.000639    Time 0.182520    
2019-09-13 06:30:53,771 - Epoch: [4][ 1900/ 5005]    Overall Loss 1.302684    Objective Loss 1.302684    Top1 69.005345    Top5 87.249383    LR 0.000637    Time 0.182409    
2019-09-13 06:31:02,802 - Epoch: [4][ 1950/ 5005]    Overall Loss 1.301804    Objective Loss 1.301804    Top1 69.027444    Top5 87.267829    LR 0.000636    Time 0.182361    
2019-09-13 06:31:11,721 - Epoch: [4][ 2000/ 5005]    Overall Loss 1.301236    Objective Loss 1.301236    Top1 69.042187    Top5 87.274219    LR 0.000634    Time 0.182260    
2019-09-13 06:31:20,626 - Epoch: [4][ 2050/ 5005]    Overall Loss 1.300933    Objective Loss 1.300933    Top1 69.052210    Top5 87.279726    LR 0.000633    Time 0.182156    
2019-09-13 06:31:29,821 - Epoch: [4][ 2100/ 5005]    Overall Loss 1.301397    Objective Loss 1.301397    Top1 69.049665    Top5 87.273065    LR 0.000632    Time 0.182196    
2019-09-13 06:31:39,113 - Epoch: [4][ 2150/ 5005]    Overall Loss 1.301287    Objective Loss 1.301287    Top1 69.048874    Top5 87.272892    LR 0.000630    Time 0.182279    
2019-09-13 06:31:48,134 - Epoch: [4][ 2200/ 5005]    Overall Loss 1.301304    Objective Loss 1.301304    Top1 69.047763    Top5 87.271662    LR 0.000629    Time 0.182235    
2019-09-13 06:31:57,065 - Epoch: [4][ 2250/ 5005]    Overall Loss 1.301611    Objective Loss 1.301611    Top1 69.043229    Top5 87.266840    LR 0.000627    Time 0.182153    
2019-09-13 06:32:06,040 - Epoch: [4][ 2300/ 5005]    Overall Loss 1.301575    Objective Loss 1.301575    Top1 69.045686    Top5 87.269192    LR 0.000626    Time 0.182093    
2019-09-13 06:32:15,245 - Epoch: [4][ 2350/ 5005]    Overall Loss 1.302021    Objective Loss 1.302021    Top1 69.028424    Top5 87.264628    LR 0.000625    Time 0.182135    
2019-09-13 06:32:24,339 - Epoch: [4][ 2400/ 5005]    Overall Loss 1.301976    Objective Loss 1.301976    Top1 69.028646    Top5 87.264811    LR 0.000623    Time 0.182127    
2019-09-13 06:32:33,375 - Epoch: [4][ 2450/ 5005]    Overall Loss 1.302560    Objective Loss 1.302560    Top1 69.013233    Top5 87.263712    LR 0.000622    Time 0.182097    
2019-09-13 06:32:42,433 - Epoch: [4][ 2500/ 5005]    Overall Loss 1.302909    Objective Loss 1.302909    Top1 69.010156    Top5 87.262500    LR 0.000620    Time 0.182077    
2019-09-13 06:32:51,599 - Epoch: [4][ 2550/ 5005]    Overall Loss 1.302776    Objective Loss 1.302776    Top1 69.015778    Top5 87.265012    LR 0.000619    Time 0.182100    
2019-09-13 06:33:01,028 - Epoch: [4][ 2600/ 5005]    Overall Loss 1.302814    Objective Loss 1.302814    Top1 69.020132    Top5 87.259916    LR 0.000618    Time 0.182223    
2019-09-13 06:33:09,995 - Epoch: [4][ 2650/ 5005]    Overall Loss 1.302665    Objective Loss 1.302665    Top1 69.021374    Top5 87.263119    LR 0.000616    Time 0.182167    
2019-09-13 06:33:19,025 - Epoch: [4][ 2700/ 5005]    Overall Loss 1.302736    Objective Loss 1.302736    Top1 69.015625    Top5 87.261429    LR 0.000615    Time 0.182137    
2019-09-13 06:33:28,082 - Epoch: [4][ 2750/ 5005]    Overall Loss 1.303200    Objective Loss 1.303200    Top1 69.014205    Top5 87.248153    LR 0.000614    Time 0.182117    
2019-09-13 06:33:37,066 - Epoch: [4][ 2800/ 5005]    Overall Loss 1.302949    Objective Loss 1.302949    Top1 69.023438    Top5 87.252651    LR 0.000612    Time 0.182073    
2019-09-13 06:33:46,078 - Epoch: [4][ 2850/ 5005]    Overall Loss 1.303613    Objective Loss 1.303613    Top1 69.015899    Top5 87.247944    LR 0.000611    Time 0.182039    
2019-09-13 06:33:55,039 - Epoch: [4][ 2900/ 5005]    Overall Loss 1.303453    Objective Loss 1.303453    Top1 69.024919    Top5 87.247306    LR 0.000609    Time 0.181989    
2019-09-13 06:34:04,042 - Epoch: [4][ 2950/ 5005]    Overall Loss 1.302992    Objective Loss 1.302992    Top1 69.036944    Top5 87.254370    LR 0.000608    Time 0.181955    
2019-09-13 06:34:12,954 - Epoch: [4][ 3000/ 5005]    Overall Loss 1.302844    Objective Loss 1.302844    Top1 69.042318    Top5 87.250391    LR 0.000607    Time 0.181892    
2019-09-13 06:34:22,118 - Epoch: [4][ 3050/ 5005]    Overall Loss 1.302942    Objective Loss 1.302942    Top1 69.038806    Top5 87.251665    LR 0.000605    Time 0.181914    
2019-09-13 06:34:31,050 - Epoch: [4][ 3100/ 5005]    Overall Loss 1.303254    Objective Loss 1.303254    Top1 69.036920    Top5 87.250378    LR 0.000604    Time 0.181860    
2019-09-13 06:34:40,004 - Epoch: [4][ 3150/ 5005]    Overall Loss 1.303194    Objective Loss 1.303194    Top1 69.030754    Top5 87.254092    LR 0.000602    Time 0.181815    
2019-09-13 06:34:48,964 - Epoch: [4][ 3200/ 5005]    Overall Loss 1.303427    Objective Loss 1.303427    Top1 69.022339    Top5 87.251099    LR 0.000601    Time 0.181773    
2019-09-13 06:34:57,908 - Epoch: [4][ 3250/ 5005]    Overall Loss 1.303706    Objective Loss 1.303706    Top1 69.019952    Top5 87.248918    LR 0.000599    Time 0.181727    
2019-09-13 06:35:06,734 - Epoch: [4][ 3300/ 5005]    Overall Loss 1.304241    Objective Loss 1.304241    Top1 69.010772    Top5 87.241241    LR 0.000598    Time 0.181648    
2019-09-13 06:35:15,713 - Epoch: [4][ 3350/ 5005]    Overall Loss 1.304047    Objective Loss 1.304047    Top1 69.011544    Top5 87.248018    LR 0.000597    Time 0.181616    
2019-09-13 06:35:24,650 - Epoch: [4][ 3400/ 5005]    Overall Loss 1.303716    Objective Loss 1.303716    Top1 69.015165    Top5 87.249540    LR 0.000595    Time 0.181573    
2019-09-13 06:35:33,727 - Epoch: [4][ 3450/ 5005]    Overall Loss 1.304193    Objective Loss 1.304193    Top1 69.002264    Top5 87.244565    LR 0.000594    Time 0.181571    
2019-09-13 06:35:42,881 - Epoch: [4][ 3500/ 5005]    Overall Loss 1.304443    Objective Loss 1.304443    Top1 68.997545    Top5 87.240848    LR 0.000592    Time 0.181592    
2019-09-13 06:35:51,829 - Epoch: [4][ 3550/ 5005]    Overall Loss 1.304688    Objective Loss 1.304688    Top1 68.991857    Top5 87.238446    LR 0.000591    Time 0.181554    
2019-09-13 06:36:00,822 - Epoch: [4][ 3600/ 5005]    Overall Loss 1.304630    Objective Loss 1.304630    Top1 68.993707    Top5 87.241428    LR 0.000590    Time 0.181529    
2019-09-13 06:36:09,784 - Epoch: [4][ 3650/ 5005]    Overall Loss 1.304383    Objective Loss 1.304383    Top1 68.995612    Top5 87.246361    LR 0.000588    Time 0.181497    
2019-09-13 06:36:18,740 - Epoch: [4][ 3700/ 5005]    Overall Loss 1.304226    Objective Loss 1.304226    Top1 68.993243    Top5 87.249789    LR 0.000587    Time 0.181464    
2019-09-13 06:36:27,647 - Epoch: [4][ 3750/ 5005]    Overall Loss 1.304033    Objective Loss 1.304033    Top1 68.995729    Top5 87.255104    LR 0.000585    Time 0.181419    
2019-09-13 06:36:36,514 - Epoch: [4][ 3800/ 5005]    Overall Loss 1.304365    Objective Loss 1.304365    Top1 68.991057    Top5 87.250308    LR 0.000584    Time 0.181364    
2019-09-13 06:36:45,484 - Epoch: [4][ 3850/ 5005]    Overall Loss 1.304233    Objective Loss 1.304233    Top1 68.995434    Top5 87.252131    LR 0.000583    Time 0.181338    
2019-09-13 06:36:54,460 - Epoch: [4][ 3900/ 5005]    Overall Loss 1.304442    Objective Loss 1.304442    Top1 68.993790    Top5 87.248397    LR 0.000581    Time 0.181313    
2019-09-13 06:37:03,497 - Epoch: [4][ 3950/ 5005]    Overall Loss 1.304644    Objective Loss 1.304644    Top1 68.992682    Top5 87.249604    LR 0.000580    Time 0.181306    
2019-09-13 06:37:12,388 - Epoch: [4][ 4000/ 5005]    Overall Loss 1.304771    Objective Loss 1.304771    Top1 68.993652    Top5 87.245410    LR 0.000578    Time 0.181261    
2019-09-13 06:37:21,414 - Epoch: [4][ 4050/ 5005]    Overall Loss 1.304567    Objective Loss 1.304567    Top1 68.994117    Top5 87.249035    LR 0.000577    Time 0.181251    
2019-09-13 06:37:30,411 - Epoch: [4][ 4100/ 5005]    Overall Loss 1.304467    Objective Loss 1.304467    Top1 68.998857    Top5 87.250381    LR 0.000576    Time 0.181235    
2019-09-13 06:37:39,271 - Epoch: [4][ 4150/ 5005]    Overall Loss 1.304708    Objective Loss 1.304708    Top1 69.000565    Top5 87.247553    LR 0.000574    Time 0.181185    
2019-09-13 06:37:48,235 - Epoch: [4][ 4200/ 5005]    Overall Loss 1.304725    Objective Loss 1.304725    Top1 69.003906    Top5 87.247861    LR 0.000573    Time 0.181162    
2019-09-13 06:37:57,167 - Epoch: [4][ 4250/ 5005]    Overall Loss 1.304569    Objective Loss 1.304569    Top1 69.013235    Top5 87.246415    LR 0.000571    Time 0.181131    
2019-09-13 06:38:06,163 - Epoch: [4][ 4300/ 5005]    Overall Loss 1.304322    Objective Loss 1.304322    Top1 69.020531    Top5 87.247275    LR 0.000570    Time 0.181117    
2019-09-13 06:38:15,175 - Epoch: [4][ 4350/ 5005]    Overall Loss 1.304610    Objective Loss 1.304610    Top1 69.016792    Top5 87.243175    LR 0.000569    Time 0.181106    
2019-09-13 06:38:24,122 - Epoch: [4][ 4400/ 5005]    Overall Loss 1.304898    Objective Loss 1.304898    Top1 69.005415    Top5 87.239347    LR 0.000567    Time 0.181080    
2019-09-13 06:38:33,141 - Epoch: [4][ 4450/ 5005]    Overall Loss 1.304902    Objective Loss 1.304902    Top1 69.004477    Top5 87.240344    LR 0.000566    Time 0.181072    
2019-09-13 06:38:42,093 - Epoch: [4][ 4500/ 5005]    Overall Loss 1.305206    Objective Loss 1.305206    Top1 69.000521    Top5 87.234896    LR 0.000564    Time 0.181048    
2019-09-13 06:38:51,034 - Epoch: [4][ 4550/ 5005]    Overall Loss 1.305206    Objective Loss 1.305206    Top1 69.001717    Top5 87.238238    LR 0.000563    Time 0.181023    
2019-09-13 06:38:59,982 - Epoch: [4][ 4600/ 5005]    Overall Loss 1.305122    Objective Loss 1.305122    Top1 69.000934    Top5 87.240234    LR 0.000561    Time 0.181000    
2019-09-13 06:39:08,999 - Epoch: [4][ 4650/ 5005]    Overall Loss 1.305096    Objective Loss 1.305096    Top1 69.003360    Top5 87.237315    LR 0.000560    Time 0.180993    
2019-09-13 06:39:17,992 - Epoch: [4][ 4700/ 5005]    Overall Loss 1.305005    Objective Loss 1.305005    Top1 69.006732    Top5 87.241689    LR 0.000559    Time 0.180980    
2019-09-13 06:39:27,002 - Epoch: [4][ 4750/ 5005]    Overall Loss 1.304882    Objective Loss 1.304882    Top1 69.008470    Top5 87.244737    LR 0.000557    Time 0.180971    
2019-09-13 06:39:35,995 - Epoch: [4][ 4800/ 5005]    Overall Loss 1.304871    Objective Loss 1.304871    Top1 69.007731    Top5 87.243652    LR 0.000556    Time 0.180959    
2019-09-13 06:39:45,005 - Epoch: [4][ 4850/ 5005]    Overall Loss 1.304716    Objective Loss 1.304716    Top1 69.003222    Top5 87.244443    LR 0.000554    Time 0.180950    
2019-09-13 06:39:54,132 - Epoch: [4][ 4900/ 5005]    Overall Loss 1.304765    Objective Loss 1.304765    Top1 69.003189    Top5 87.241709    LR 0.000553    Time 0.180966    
2019-09-13 06:40:03,017 - Epoch: [4][ 4950/ 5005]    Overall Loss 1.304927    Objective Loss 1.304927    Top1 69.000316    Top5 87.236900    LR 0.000552    Time 0.180932    
2019-09-13 06:40:11,843 - Epoch: [4][ 5000/ 5005]    Overall Loss 1.304883    Objective Loss 1.304883    Top1 69.002344    Top5 87.238906    LR 0.000550    Time 0.180887    
2019-09-13 06:40:12,997 - 
Parameters:
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                      | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.float_weight                 | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12736 |  0.00013 |    0.07464 |
|  1 | module.conv1.weight                       | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16025 |  0.00028 |    0.09697 |
|  2 | module.layer1.0.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05244 | -0.00313 |    0.03104 |
|  3 | module.layer1.0.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08008 | -0.00447 |    0.04851 |
|  4 | module.layer1.0.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04438 | -0.00084 |    0.03142 |
|  5 | module.layer1.0.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10205 | -0.00193 |    0.07250 |
|  6 | module.layer1.1.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04992 | -0.00232 |    0.03364 |
|  7 | module.layer1.1.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08880 | -0.00413 |    0.06040 |
|  8 | module.layer1.1.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04317 | -0.00118 |    0.03093 |
|  9 | module.layer1.1.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12369 | -0.00341 |    0.08885 |
| 10 | module.layer2.0.conv1.float_weight        | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04082 | -0.00135 |    0.02886 |
| 11 | module.layer2.0.conv1.weight              | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12997 | -0.00431 |    0.09212 |
| 12 | module.layer2.0.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03339 | -0.00122 |    0.02349 |
| 13 | module.layer2.0.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08731 | -0.00320 |    0.06162 |
| 14 | module.layer2.0.downsample.0.float_weight | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06929 | -0.00257 |    0.04348 |
| 15 | module.layer2.0.downsample.0.weight       | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10525 | -0.00388 |    0.06711 |
| 16 | module.layer2.1.conv1.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03355 | -0.00145 |    0.02382 |
| 17 | module.layer2.1.conv1.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08546 | -0.00371 |    0.06083 |
| 18 | module.layer2.1.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02951 | -0.00124 |    0.02184 |
| 19 | module.layer2.1.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09305 | -0.00392 |    0.06897 |
| 20 | module.layer3.0.conv1.float_weight        | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02851 | -0.00133 |    0.02054 |
| 21 | module.layer3.0.conv1.weight              | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08186 | -0.00381 |    0.05910 |
| 22 | module.layer3.0.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02459 | -0.00075 |    0.01801 |
| 23 | module.layer3.0.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08433 | -0.00258 |    0.06188 |
| 24 | module.layer3.0.downsample.0.float_weight | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03232 | -0.00183 |    0.02332 |
| 25 | module.layer3.0.downsample.0.weight       | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12712 | -0.00721 |    0.09187 |
| 26 | module.layer3.1.conv1.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02196 | -0.00161 |    0.01635 |
| 27 | module.layer3.1.conv1.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08360 | -0.00614 |    0.06232 |
| 28 | module.layer3.1.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02030 | -0.00140 |    0.01525 |
| 29 | module.layer3.1.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07127 | -0.00491 |    0.05360 |
| 30 | module.layer4.0.conv1.float_weight        | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01951 | -0.00151 |    0.01493 |
| 31 | module.layer4.0.conv1.weight              | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06588 | -0.00511 |    0.05048 |
| 32 | module.layer4.0.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01701 | -0.00127 |    0.01314 |
| 33 | module.layer4.0.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06008 | -0.00450 |    0.04647 |
| 34 | module.layer4.0.downsample.0.float_weight | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03218 | -0.00083 |    0.02344 |
| 35 | module.layer4.0.downsample.0.weight       | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05272 | -0.00136 |    0.03856 |
| 36 | module.layer4.1.conv1.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01751 | -0.00220 |    0.01378 |
| 37 | module.layer4.1.conv1.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07772 | -0.00975 |    0.06122 |
| 38 | module.layer4.1.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01296 | -0.00008 |    0.00991 |
| 39 | module.layer4.1.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05509 | -0.00036 |    0.04220 |
| 40 | module.fc.float_weight                    | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06804 |  0.00000 |    0.04992 |
| 41 | module.fc.weight                          | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09082 | -0.00020 |    0.06706 |
| 42 | Total sparsity:                           | -                |      23357824 |       23357824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2019-09-13 06:40:12,997 - Total sparsity: 0.00

2019-09-13 06:40:12,997 - --- validate (epoch=4)-----------
2019-09-13 06:40:12,997 - 50000 samples (256 per mini-batch)
2019-09-13 06:40:24,507 - Epoch: [4][   50/  195]    Loss 0.938368    Top1 75.851562    Top5 93.226562    
2019-09-13 06:40:32,289 - Epoch: [4][  100/  195]    Loss 1.070132    Top1 73.519531    Top5 91.722656    
2019-09-13 06:40:40,310 - Epoch: [4][  150/  195]    Loss 1.205540    Top1 70.833333    Top5 89.822917    
2019-09-13 06:40:47,915 - ==> Top1: 69.774    Top5: 89.080    Loss: 1.264

2019-09-13 06:40:47,921 - ==> Best Top1: 69.774 on Epoch: 4
2019-09-13 06:40:47,922 - Saving checkpoint to: 8b_logs/res18___2019.09.13-052127/res18_checkpoint.pth.tar
2019-09-13 06:40:54,401 - Saving PACT param_value.......
2019-09-13 06:40:54,405 - The PACT Clip Parameter Value............
2019-09-13 06:40:54,412 - 

2019-09-13 06:40:54,412 - +--------------------------------+--------------+
| Layers                         |   PACT_alpha |
|--------------------------------+--------------|
| module.relu.clip_val           |      7.83409 |
| module.layer1.0.relu1.clip_val |      7.8341  |
| module.layer1.0.relu2.clip_val |      7.8341  |
| module.layer1.1.relu1.clip_val |      7.8341  |
| module.layer1.1.relu2.clip_val |      7.83408 |
| module.layer2.0.relu1.clip_val |      7.8341  |
| module.layer2.0.relu2.clip_val |      7.83412 |
| module.layer2.1.relu1.clip_val |      7.8341  |
| module.layer2.1.relu2.clip_val |      7.83416 |
| module.layer3.0.relu1.clip_val |      7.8341  |
| module.layer3.0.relu2.clip_val |      7.8341  |
| module.layer3.1.relu1.clip_val |      7.8341  |
| module.layer3.1.relu2.clip_val |      7.83415 |
| module.layer4.0.relu1.clip_val |      7.8341  |
| module.layer4.0.relu2.clip_val |      7.83422 |
| module.layer4.1.relu1.clip_val |      7.8341  |
| module.layer4.1.relu2.clip_val |      8.10257 |
+--------------------------------+--------------+
2019-09-13 06:40:54,416 - 

2019-09-13 06:40:54,416 - Training epoch: 1281167 samples (256 per mini-batch)
2019-09-13 06:41:07,037 - Epoch: [5][   50/ 5005]    Overall Loss 1.305880    Objective Loss 1.305880    Top1 68.929687    Top5 87.132812    LR 0.000549    Time 0.252323    
2019-09-13 06:41:16,040 - Epoch: [5][  100/ 5005]    Overall Loss 1.305689    Objective Loss 1.305689    Top1 69.000000    Top5 87.261719    LR 0.000547    Time 0.216143    
2019-09-13 06:41:25,249 - Epoch: [5][  150/ 5005]    Overall Loss 1.304082    Objective Loss 1.304082    Top1 68.960938    Top5 87.247396    LR 0.000546    Time 0.205467    
2019-09-13 06:41:34,234 - Epoch: [5][  200/ 5005]    Overall Loss 1.298329    Objective Loss 1.298329    Top1 69.128906    Top5 87.365234    LR 0.000544    Time 0.199000    
2019-09-13 06:41:43,250 - Epoch: [5][  250/ 5005]    Overall Loss 1.301242    Objective Loss 1.301242    Top1 69.082813    Top5 87.246875    LR 0.000543    Time 0.195250    
2019-09-13 06:41:52,251 - Epoch: [5][  300/ 5005]    Overall Loss 1.300686    Objective Loss 1.300686    Top1 69.123698    Top5 87.291667    LR 0.000542    Time 0.192701    
2019-09-13 06:42:01,239 - Epoch: [5][  350/ 5005]    Overall Loss 1.297306    Objective Loss 1.297306    Top1 69.191964    Top5 87.358259    LR 0.000540    Time 0.190844    
2019-09-13 06:42:10,348 - Epoch: [5][  400/ 5005]    Overall Loss 1.297914    Objective Loss 1.297914    Top1 69.253906    Top5 87.343750    LR 0.000539    Time 0.189752    
2019-09-13 06:42:19,259 - Epoch: [5][  450/ 5005]    Overall Loss 1.296537    Objective Loss 1.296537    Top1 69.263889    Top5 87.347222    LR 0.000537    Time 0.188463    
2019-09-13 06:42:28,229 - Epoch: [5][  500/ 5005]    Overall Loss 1.293504    Objective Loss 1.293504    Top1 69.327344    Top5 87.385937    LR 0.000536    Time 0.187551    
2019-09-13 06:42:37,162 - Epoch: [5][  550/ 5005]    Overall Loss 1.293710    Objective Loss 1.293710    Top1 69.289773    Top5 87.387784    LR 0.000534    Time 0.186737    
2019-09-13 06:42:46,343 - Epoch: [5][  600/ 5005]    Overall Loss 1.294470    Objective Loss 1.294470    Top1 69.259766    Top5 87.367839    LR 0.000533    Time 0.186471    
2019-09-13 06:42:55,296 - Epoch: [5][  650/ 5005]    Overall Loss 1.294588    Objective Loss 1.294588    Top1 69.270433    Top5 87.359976    LR 0.000532    Time 0.185894    
2019-09-13 06:43:04,243 - Epoch: [5][  700/ 5005]    Overall Loss 1.294161    Objective Loss 1.294161    Top1 69.273996    Top5 87.373884    LR 0.000530    Time 0.185392    
2019-09-13 06:43:13,264 - Epoch: [5][  750/ 5005]    Overall Loss 1.296075    Objective Loss 1.296075    Top1 69.243229    Top5 87.332292    LR 0.000529    Time 0.185054    
2019-09-13 06:43:22,211 - Epoch: [5][  800/ 5005]    Overall Loss 1.295891    Objective Loss 1.295891    Top1 69.255859    Top5 87.348633    LR 0.000527    Time 0.184667    
2019-09-13 06:43:31,259 - Epoch: [5][  850/ 5005]    Overall Loss 1.295034    Objective Loss 1.295034    Top1 69.255055    Top5 87.355239    LR 0.000526    Time 0.184445    
2019-09-13 06:43:40,301 - Epoch: [5][  900/ 5005]    Overall Loss 1.297130    Objective Loss 1.297130    Top1 69.224826    Top5 87.315104    LR 0.000525    Time 0.184242    
2019-09-13 06:43:49,389 - Epoch: [5][  950/ 5005]    Overall Loss 1.296790    Objective Loss 1.296790    Top1 69.257401    Top5 87.319079    LR 0.000523    Time 0.184108    
2019-09-13 06:43:58,396 - Epoch: [5][ 1000/ 5005]    Overall Loss 1.298346    Objective Loss 1.298346    Top1 69.218359    Top5 87.285938    LR 0.000522    Time 0.183905    
2019-09-13 06:44:07,638 - Epoch: [5][ 1050/ 5005]    Overall Loss 1.297657    Objective Loss 1.297657    Top1 69.233259    Top5 87.299479    LR 0.000520    Time 0.183948    
2019-09-13 06:44:16,665 - Epoch: [5][ 1100/ 5005]    Overall Loss 1.297280    Objective Loss 1.297280    Top1 69.243253    Top5 87.294744    LR 0.000519    Time 0.183789    
2019-09-13 06:44:25,695 - Epoch: [5][ 1150/ 5005]    Overall Loss 1.296568    Objective Loss 1.296568    Top1 69.272758    Top5 87.299932    LR 0.000518    Time 0.183647    
2019-09-13 06:44:34,722 - Epoch: [5][ 1200/ 5005]    Overall Loss 1.296066    Objective Loss 1.296066    Top1 69.296224    Top5 87.303711    LR 0.000516    Time 0.183515    
2019-09-13 06:44:43,641 - Epoch: [5][ 1250/ 5005]    Overall Loss 1.296118    Objective Loss 1.296118    Top1 69.266875    Top5 87.310937    LR 0.000515    Time 0.183308    
2019-09-13 06:44:52,613 - Epoch: [5][ 1300/ 5005]    Overall Loss 1.296350    Objective Loss 1.296350    Top1 69.257812    Top5 87.301683    LR 0.000513    Time 0.183157    
2019-09-13 06:45:01,603 - Epoch: [5][ 1350/ 5005]    Overall Loss 1.296611    Objective Loss 1.296611    Top1 69.253762    Top5 87.300347    LR 0.000512    Time 0.183030    
2019-09-13 06:45:10,568 - Epoch: [5][ 1400/ 5005]    Overall Loss 1.296063    Objective Loss 1.296063    Top1 69.271484    Top5 87.306362    LR 0.000511    Time 0.182894    
2019-09-13 06:45:19,616 - Epoch: [5][ 1450/ 5005]    Overall Loss 1.295574    Objective Loss 1.295574    Top1 69.269397    Top5 87.310345    LR 0.000509    Time 0.182825    
2019-09-13 06:45:28,921 - Epoch: [5][ 1500/ 5005]    Overall Loss 1.295973    Objective Loss 1.295973    Top1 69.259115    Top5 87.305729    LR 0.000508    Time 0.182932    
2019-09-13 06:45:38,270 - Epoch: [5][ 1550/ 5005]    Overall Loss 1.294939    Objective Loss 1.294939    Top1 69.285030    Top5 87.321573    LR 0.000506    Time 0.183060    
2019-09-13 06:45:47,404 - Epoch: [5][ 1600/ 5005]    Overall Loss 1.295500    Objective Loss 1.295500    Top1 69.264893    Top5 87.310059    LR 0.000505    Time 0.183046    
2019-09-13 06:45:56,576 - Epoch: [5][ 1650/ 5005]    Overall Loss 1.295240    Objective Loss 1.295240    Top1 69.258049    Top5 87.313684    LR 0.000504    Time 0.183055    
2019-09-13 06:46:05,576 - Epoch: [5][ 1700/ 5005]    Overall Loss 1.295607    Objective Loss 1.295607    Top1 69.247472    Top5 87.306756    LR 0.000502    Time 0.182962    
2019-09-13 06:46:14,725 - Epoch: [5][ 1750/ 5005]    Overall Loss 1.295139    Objective Loss 1.295139    Top1 69.254688    Top5 87.318973    LR 0.000501    Time 0.182960    
2019-09-13 06:46:23,814 - Epoch: [5][ 1800/ 5005]    Overall Loss 1.295223    Objective Loss 1.295223    Top1 69.252604    Top5 87.321832    LR 0.000499    Time 0.182925    
2019-09-13 06:46:32,971 - Epoch: [5][ 1850/ 5005]    Overall Loss 1.294907    Objective Loss 1.294907    Top1 69.250633    Top5 87.330448    LR 0.000498    Time 0.182929    
2019-09-13 06:46:42,056 - Epoch: [5][ 1900/ 5005]    Overall Loss 1.294419    Objective Loss 1.294419    Top1 69.265831    Top5 87.336965    LR 0.000496    Time 0.182894    
2019-09-13 06:46:51,421 - Epoch: [5][ 1950/ 5005]    Overall Loss 1.294330    Objective Loss 1.294330    Top1 69.268029    Top5 87.338742    LR 0.000495    Time 0.183006    
2019-09-13 06:47:00,520 - Epoch: [5][ 2000/ 5005]    Overall Loss 1.294491    Objective Loss 1.294491    Top1 69.272656    Top5 87.335938    LR 0.000494    Time 0.182978    
2019-09-13 06:47:09,575 - Epoch: [5][ 2050/ 5005]    Overall Loss 1.294717    Objective Loss 1.294717    Top1 69.255145    Top5 87.336700    LR 0.000492    Time 0.182930    
2019-09-13 06:47:18,629 - Epoch: [5][ 2100/ 5005]    Overall Loss 1.294845    Objective Loss 1.294845    Top1 69.255394    Top5 87.332217    LR 0.000491    Time 0.182884    
2019-09-13 06:47:27,771 - Epoch: [5][ 2150/ 5005]    Overall Loss 1.294255    Objective Loss 1.294255    Top1 69.272347    Top5 87.337028    LR 0.000489    Time 0.182881    
2019-09-13 06:47:36,869 - Epoch: [5][ 2200/ 5005]    Overall Loss 1.293747    Objective Loss 1.293747    Top1 69.285156    Top5 87.343217    LR 0.000488    Time 0.182858    
2019-09-13 06:47:46,033 - Epoch: [5][ 2250/ 5005]    Overall Loss 1.294104    Objective Loss 1.294104    Top1 69.288542    Top5 87.344618    LR 0.000487    Time 0.182866    
2019-09-13 06:47:55,222 - Epoch: [5][ 2300/ 5005]    Overall Loss 1.294537    Objective Loss 1.294537    Top1 69.278533    Top5 87.328804    LR 0.000485    Time 0.182884    
2019-09-13 06:48:04,268 - Epoch: [5][ 2350/ 5005]    Overall Loss 1.294675    Objective Loss 1.294675    Top1 69.275598    Top5 87.324967    LR 0.000484    Time 0.182840    
2019-09-13 06:48:13,551 - Epoch: [5][ 2400/ 5005]    Overall Loss 1.295127    Objective Loss 1.295127    Top1 69.265462    Top5 87.317871    LR 0.000482    Time 0.182897    
2019-09-13 06:48:22,682 - Epoch: [5][ 2450/ 5005]    Overall Loss 1.294434    Objective Loss 1.294434    Top1 69.272640    Top5 87.331154    LR 0.000481    Time 0.182890    
2019-09-13 06:48:31,699 - Epoch: [5][ 2500/ 5005]    Overall Loss 1.294753    Objective Loss 1.294753    Top1 69.267344    Top5 87.333125    LR 0.000480    Time 0.182838    
2019-09-13 06:48:40,707 - Epoch: [5][ 2550/ 5005]    Overall Loss 1.295023    Objective Loss 1.295023    Top1 69.270833    Top5 87.325980    LR 0.000478    Time 0.182784    
2019-09-13 06:48:49,863 - Epoch: [5][ 2600/ 5005]    Overall Loss 1.295129    Objective Loss 1.295129    Top1 69.264273    Top5 87.330529    LR 0.000477    Time 0.182789    
2019-09-13 06:48:59,088 - Epoch: [5][ 2650/ 5005]    Overall Loss 1.295249    Objective Loss 1.295249    Top1 69.255012    Top5 87.327388    LR 0.000476    Time 0.182819    
2019-09-13 06:49:08,194 - Epoch: [5][ 2700/ 5005]    Overall Loss 1.295065    Objective Loss 1.295065    Top1 69.262442    Top5 87.325521    LR 0.000474    Time 0.182805    
2019-09-13 06:49:17,171 - Epoch: [5][ 2750/ 5005]    Overall Loss 1.295398    Objective Loss 1.295398    Top1 69.253693    Top5 87.319318    LR 0.000473    Time 0.182744    
2019-09-13 06:49:26,313 - Epoch: [5][ 2800/ 5005]    Overall Loss 1.295047    Objective Loss 1.295047    Top1 69.260045    Top5 87.323940    LR 0.000471    Time 0.182744    
2019-09-13 06:49:35,279 - Epoch: [5][ 2850/ 5005]    Overall Loss 1.294790    Objective Loss 1.294790    Top1 69.261513    Top5 87.329084    LR 0.000470    Time 0.182683    
2019-09-13 06:49:44,215 - Epoch: [5][ 2900/ 5005]    Overall Loss 1.295151    Objective Loss 1.295151    Top1 69.253098    Top5 87.324892    LR 0.000469    Time 0.182613    
2019-09-13 06:49:53,010 - Epoch: [5][ 2950/ 5005]    Overall Loss 1.294658    Objective Loss 1.294658    Top1 69.265360    Top5 87.325212    LR 0.000467    Time 0.182498    
2019-09-13 06:50:01,896 - Epoch: [5][ 3000/ 5005]    Overall Loss 1.295018    Objective Loss 1.295018    Top1 69.258984    Top5 87.317057    LR 0.000466    Time 0.182418    
2019-09-13 06:50:10,687 - Epoch: [5][ 3050/ 5005]    Overall Loss 1.295328    Objective Loss 1.295328    Top1 69.252690    Top5 87.310707    LR 0.000464    Time 0.182308    
2019-09-13 06:50:19,487 - Epoch: [5][ 3100/ 5005]    Overall Loss 1.295065    Objective Loss 1.295065    Top1 69.254914    Top5 87.315272    LR 0.000463    Time 0.182205    
2019-09-13 06:50:28,408 - Epoch: [5][ 3150/ 5005]    Overall Loss 1.295209    Objective Loss 1.295209    Top1 69.244792    Top5 87.312872    LR 0.000462    Time 0.182144    
2019-09-13 06:50:37,328 - Epoch: [5][ 3200/ 5005]    Overall Loss 1.295537    Objective Loss 1.295537    Top1 69.236816    Top5 87.307495    LR 0.000460    Time 0.182085    
2019-09-13 06:50:46,277 - Epoch: [5][ 3250/ 5005]    Overall Loss 1.295152    Objective Loss 1.295152    Top1 69.240264    Top5 87.313822    LR 0.000459    Time 0.182036    
2019-09-13 06:50:55,208 - Epoch: [5][ 3300/ 5005]    Overall Loss 1.295390    Objective Loss 1.295390    Top1 69.231061    Top5 87.311908    LR 0.000457    Time 0.181984    
2019-09-13 06:51:04,259 - Epoch: [5][ 3350/ 5005]    Overall Loss 1.295087    Objective Loss 1.295087    Top1 69.237290    Top5 87.315532    LR 0.000456    Time 0.181968    
2019-09-13 06:51:13,154 - Epoch: [5][ 3400/ 5005]    Overall Loss 1.294620    Objective Loss 1.294620    Top1 69.241728    Top5 87.323874    LR 0.000455    Time 0.181908    
2019-09-13 06:51:22,091 - Epoch: [5][ 3450/ 5005]    Overall Loss 1.294744    Objective Loss 1.294744    Top1 69.247622    Top5 87.320652    LR 0.000453    Time 0.181861    
2019-09-13 06:51:31,099 - Epoch: [5][ 3500/ 5005]    Overall Loss 1.295044    Objective Loss 1.295044    Top1 69.242522    Top5 87.317076    LR 0.000452    Time 0.181836    
2019-09-13 06:51:40,034 - Epoch: [5][ 3550/ 5005]    Overall Loss 1.295040    Objective Loss 1.295040    Top1 69.242518    Top5 87.317011    LR 0.000451    Time 0.181790    
2019-09-13 06:51:49,015 - Epoch: [5][ 3600/ 5005]    Overall Loss 1.295167    Objective Loss 1.295167    Top1 69.241536    Top5 87.317817    LR 0.000449    Time 0.181759    
2019-09-13 06:51:57,907 - Epoch: [5][ 3650/ 5005]    Overall Loss 1.295073    Objective Loss 1.295073    Top1 69.239084    Top5 87.319884    LR 0.000448    Time 0.181705    
2019-09-13 06:52:06,941 - Epoch: [5][ 3700/ 5005]    Overall Loss 1.294890    Objective Loss 1.294890    Top1 69.243771    Top5 87.323374    LR 0.000446    Time 0.181690    
2019-09-13 06:52:15,900 - Epoch: [5][ 3750/ 5005]    Overall Loss 1.294959    Objective Loss 1.294959    Top1 69.240729    Top5 87.318958    LR 0.000445    Time 0.181656    
2019-09-13 06:52:25,105 - Epoch: [5][ 3800/ 5005]    Overall Loss 1.295256    Objective Loss 1.295256    Top1 69.237664    Top5 87.312397    LR 0.000444    Time 0.181687    
2019-09-13 06:52:34,066 - Epoch: [5][ 3850/ 5005]    Overall Loss 1.295751    Objective Loss 1.295751    Top1 69.227577    Top5 87.306615    LR 0.000442    Time 0.181654    
2019-09-13 06:52:43,090 - Epoch: [5][ 3900/ 5005]    Overall Loss 1.295704    Objective Loss 1.295704    Top1 69.230469    Top5 87.308994    LR 0.000441    Time 0.181638    
2019-09-13 06:52:52,071 - Epoch: [5][ 3950/ 5005]    Overall Loss 1.295463    Objective Loss 1.295463    Top1 69.235759    Top5 87.312797    LR 0.000440    Time 0.181612    
2019-09-13 06:53:01,036 - Epoch: [5][ 4000/ 5005]    Overall Loss 1.295467    Objective Loss 1.295467    Top1 69.235254    Top5 87.312891    LR 0.000438    Time 0.181582    
2019-09-13 06:53:10,037 - Epoch: [5][ 4050/ 5005]    Overall Loss 1.295157    Objective Loss 1.295157    Top1 69.245370    Top5 87.315586    LR 0.000437    Time 0.181562    
2019-09-13 06:53:19,078 - Epoch: [5][ 4100/ 5005]    Overall Loss 1.295414    Objective Loss 1.295414    Top1 69.241902    Top5 87.310213    LR 0.000435    Time 0.181552    
2019-09-13 06:53:28,034 - Epoch: [5][ 4150/ 5005]    Overall Loss 1.295263    Objective Loss 1.295263    Top1 69.245953    Top5 87.314759    LR 0.000434    Time 0.181522    
2019-09-13 06:53:37,002 - Epoch: [5][ 4200/ 5005]    Overall Loss 1.295442    Objective Loss 1.295442    Top1 69.238746    Top5 87.312221    LR 0.000433    Time 0.181496    
2019-09-13 06:53:46,127 - Epoch: [5][ 4250/ 5005]    Overall Loss 1.295696    Objective Loss 1.295696    Top1 69.230055    Top5 87.308456    LR 0.000431    Time 0.181507    
2019-09-13 06:53:55,114 - Epoch: [5][ 4300/ 5005]    Overall Loss 1.295919    Objective Loss 1.295919    Top1 69.225654    Top5 87.306868    LR 0.000430    Time 0.181485    
2019-09-13 06:54:04,092 - Epoch: [5][ 4350/ 5005]    Overall Loss 1.295699    Objective Loss 1.295699    Top1 69.227820    Top5 87.309357    LR 0.000429    Time 0.181463    
2019-09-13 06:54:13,192 - Epoch: [5][ 4400/ 5005]    Overall Loss 1.295334    Objective Loss 1.295334    Top1 69.242188    Top5 87.315874    LR 0.000427    Time 0.181468    
2019-09-13 06:54:22,219 - Epoch: [5][ 4450/ 5005]    Overall Loss 1.295312    Objective Loss 1.295312    Top1 69.240256    Top5 87.319084    LR 0.000426    Time 0.181457    
2019-09-13 06:54:31,253 - Epoch: [5][ 4500/ 5005]    Overall Loss 1.295017    Objective Loss 1.295017    Top1 69.249913    Top5 87.322656    LR 0.000425    Time 0.181448    
2019-09-13 06:54:40,258 - Epoch: [5][ 4550/ 5005]    Overall Loss 1.295020    Objective Loss 1.295020    Top1 69.251459    Top5 87.322630    LR 0.000423    Time 0.181432    
2019-09-13 06:54:49,225 - Epoch: [5][ 4600/ 5005]    Overall Loss 1.294944    Objective Loss 1.294944    Top1 69.255180    Top5 87.322860    LR 0.000422    Time 0.181408    
2019-09-13 06:54:58,263 - Epoch: [5][ 4650/ 5005]    Overall Loss 1.294966    Objective Loss 1.294966    Top1 69.256720    Top5 87.325605    LR 0.000421    Time 0.181401    
2019-09-13 06:55:07,303 - Epoch: [5][ 4700/ 5005]    Overall Loss 1.294985    Objective Loss 1.294985    Top1 69.254072    Top5 87.324551    LR 0.000419    Time 0.181394    
2019-09-13 06:55:16,259 - Epoch: [5][ 4750/ 5005]    Overall Loss 1.295127    Objective Loss 1.295127    Top1 69.249507    Top5 87.322780    LR 0.000418    Time 0.181369    
2019-09-13 06:55:25,216 - Epoch: [5][ 4800/ 5005]    Overall Loss 1.294991    Objective Loss 1.294991    Top1 69.251790    Top5 87.326579    LR 0.000416    Time 0.181345    
2019-09-13 06:55:34,156 - Epoch: [5][ 4850/ 5005]    Overall Loss 1.294926    Objective Loss 1.294926    Top1 69.253302    Top5 87.328125    LR 0.000415    Time 0.181318    
2019-09-13 06:55:42,967 - Epoch: [5][ 4900/ 5005]    Overall Loss 1.294668    Objective Loss 1.294668    Top1 69.258211    Top5 87.333068    LR 0.000414    Time 0.181265    
2019-09-13 06:55:51,874 - Epoch: [5][ 4950/ 5005]    Overall Loss 1.294759    Objective Loss 1.294759    Top1 69.256866    Top5 87.330887    LR 0.000412    Time 0.181233    
2019-09-13 06:56:00,602 - Epoch: [5][ 5000/ 5005]    Overall Loss 1.294865    Objective Loss 1.294865    Top1 69.254063    Top5 87.328906    LR 0.000411    Time 0.181166    
2019-09-13 06:56:01,749 - 
Parameters:
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                      | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.float_weight                 | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12708 |  0.00003 |    0.07448 |
|  1 | module.conv1.weight                       | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16015 |  0.00016 |    0.09688 |
|  2 | module.layer1.0.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05233 | -0.00309 |    0.03097 |
|  3 | module.layer1.0.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08014 | -0.00441 |    0.04853 |
|  4 | module.layer1.0.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04428 | -0.00083 |    0.03135 |
|  5 | module.layer1.0.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10225 | -0.00191 |    0.07265 |
|  6 | module.layer1.1.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04981 | -0.00234 |    0.03357 |
|  7 | module.layer1.1.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08887 | -0.00418 |    0.06046 |
|  8 | module.layer1.1.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04308 | -0.00116 |    0.03086 |
|  9 | module.layer1.1.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12383 | -0.00335 |    0.08894 |
| 10 | module.layer2.0.conv1.float_weight        | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04073 | -0.00133 |    0.02880 |
| 11 | module.layer2.0.conv1.weight              | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13040 | -0.00428 |    0.09242 |
| 12 | module.layer2.0.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03331 | -0.00122 |    0.02344 |
| 13 | module.layer2.0.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08761 | -0.00322 |    0.06182 |
| 14 | module.layer2.0.downsample.0.float_weight | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06913 | -0.00256 |    0.04338 |
| 15 | module.layer2.0.downsample.0.weight       | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10519 | -0.00391 |    0.06708 |
| 16 | module.layer2.1.conv1.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03348 | -0.00144 |    0.02376 |
| 17 | module.layer2.1.conv1.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08581 | -0.00370 |    0.06107 |
| 18 | module.layer2.1.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02944 | -0.00123 |    0.02179 |
| 19 | module.layer2.1.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09356 | -0.00392 |    0.06934 |
| 20 | module.layer3.0.conv1.float_weight        | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02845 | -0.00132 |    0.02049 |
| 21 | module.layer3.0.conv1.weight              | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08217 | -0.00383 |    0.05933 |
| 22 | module.layer3.0.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02453 | -0.00075 |    0.01797 |
| 23 | module.layer3.0.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08518 | -0.00259 |    0.06250 |
| 24 | module.layer3.0.downsample.0.float_weight | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03225 | -0.00182 |    0.02326 |
| 25 | module.layer3.0.downsample.0.weight       | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12694 | -0.00720 |    0.09173 |
| 26 | module.layer3.1.conv1.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02191 | -0.00161 |    0.01631 |
| 27 | module.layer3.1.conv1.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08431 | -0.00619 |    0.06285 |
| 28 | module.layer3.1.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02026 | -0.00139 |    0.01521 |
| 29 | module.layer3.1.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07189 | -0.00494 |    0.05406 |
| 30 | module.layer4.0.conv1.float_weight        | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01947 | -0.00151 |    0.01490 |
| 31 | module.layer4.0.conv1.weight              | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06666 | -0.00517 |    0.05108 |
| 32 | module.layer4.0.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01698 | -0.00127 |    0.01312 |
| 33 | module.layer4.0.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06090 | -0.00456 |    0.04710 |
| 34 | module.layer4.0.downsample.0.float_weight | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03210 | -0.00083 |    0.02339 |
| 35 | module.layer4.0.downsample.0.weight       | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05285 | -0.00137 |    0.03867 |
| 36 | module.layer4.1.conv1.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01747 | -0.00219 |    0.01375 |
| 37 | module.layer4.1.conv1.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07848 | -0.00985 |    0.06183 |
| 38 | module.layer4.1.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01293 | -0.00008 |    0.00989 |
| 39 | module.layer4.1.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05542 | -0.00036 |    0.04247 |
| 40 | module.fc.float_weight                    | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06788 |  0.00000 |    0.04980 |
| 41 | module.fc.weight                          | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09181 | -0.00020 |    0.06780 |
| 42 | Total sparsity:                           | -                |      23357824 |       23357824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2019-09-13 06:56:01,749 - Total sparsity: 0.00

2019-09-13 06:56:01,749 - --- validate (epoch=5)-----------
2019-09-13 06:56:01,749 - 50000 samples (256 per mini-batch)
2019-09-13 06:56:13,091 - Epoch: [5][   50/  195]    Loss 0.925910    Top1 75.953125    Top5 93.265625    
2019-09-13 06:56:20,915 - Epoch: [5][  100/  195]    Loss 1.059528    Top1 73.593750    Top5 91.726562    
2019-09-13 06:56:29,523 - Epoch: [5][  150/  195]    Loss 1.201015    Top1 70.716146    Top5 89.726562    
2019-09-13 06:56:36,525 - ==> Top1: 69.724    Top5: 89.046    Loss: 1.260

2019-09-13 06:56:36,533 - ==> Best Top1: 69.774 on Epoch: 4
2019-09-13 06:56:36,533 - Saving checkpoint to: 8b_logs/res18___2019.09.13-052127/res18_checkpoint.pth.tar
2019-09-13 06:56:39,773 - Saving PACT param_value.......
2019-09-13 06:56:39,774 - The PACT Clip Parameter Value............
2019-09-13 06:56:39,779 - 

2019-09-13 06:56:39,779 - +--------------------------------+--------------+
| Layers                         |   PACT_alpha |
|--------------------------------+--------------|
| module.relu.clip_val           |      7.81525 |
| module.layer1.0.relu1.clip_val |      7.81527 |
| module.layer1.0.relu2.clip_val |      7.81527 |
| module.layer1.1.relu1.clip_val |      7.81527 |
| module.layer1.1.relu2.clip_val |      7.81527 |
| module.layer2.0.relu1.clip_val |      7.81527 |
| module.layer2.0.relu2.clip_val |      7.8153  |
| module.layer2.1.relu1.clip_val |      7.81527 |
| module.layer2.1.relu2.clip_val |      7.81534 |
| module.layer3.0.relu1.clip_val |      7.81527 |
| module.layer3.0.relu2.clip_val |      7.81527 |
| module.layer3.1.relu1.clip_val |      7.81527 |
| module.layer3.1.relu2.clip_val |      7.81532 |
| module.layer4.0.relu1.clip_val |      7.81527 |
| module.layer4.0.relu2.clip_val |      7.81538 |
| module.layer4.1.relu1.clip_val |      7.81527 |
| module.layer4.1.relu2.clip_val |      8.10833 |
+--------------------------------+--------------+
2019-09-13 06:56:39,782 - 

2019-09-13 06:56:39,782 - Training epoch: 1281167 samples (256 per mini-batch)
2019-09-13 06:56:52,243 - Epoch: [6][   50/ 5005]    Overall Loss 1.274289    Objective Loss 1.274289    Top1 69.367188    Top5 87.492188    LR 0.000410    Time 0.249125    
2019-09-13 06:57:01,149 - Epoch: [6][  100/ 5005]    Overall Loss 1.281086    Objective Loss 1.281086    Top1 69.562500    Top5 87.304688    LR 0.000408    Time 0.213586    
2019-09-13 06:57:10,143 - Epoch: [6][  150/ 5005]    Overall Loss 1.290370    Objective Loss 1.290370    Top1 69.424479    Top5 87.210938    LR 0.000407    Time 0.202326    
2019-09-13 06:57:19,076 - Epoch: [6][  200/ 5005]    Overall Loss 1.283335    Objective Loss 1.283335    Top1 69.552734    Top5 87.330078    LR 0.000406    Time 0.196396    
2019-09-13 06:57:27,985 - Epoch: [6][  250/ 5005]    Overall Loss 1.286248    Objective Loss 1.286248    Top1 69.342188    Top5 87.273438    LR 0.000404    Time 0.192743    
2019-09-13 06:57:36,848 - Epoch: [6][  300/ 5005]    Overall Loss 1.287199    Objective Loss 1.287199    Top1 69.394531    Top5 87.273438    LR 0.000403    Time 0.190152    
2019-09-13 06:57:45,831 - Epoch: [6][  350/ 5005]    Overall Loss 1.283490    Objective Loss 1.283490    Top1 69.498884    Top5 87.363839    LR 0.000402    Time 0.188643    
2019-09-13 06:57:54,922 - Epoch: [6][  400/ 5005]    Overall Loss 1.286683    Objective Loss 1.286683    Top1 69.515625    Top5 87.327148    LR 0.000400    Time 0.187781    
2019-09-13 06:58:03,832 - Epoch: [6][  450/ 5005]    Overall Loss 1.285109    Objective Loss 1.285109    Top1 69.520833    Top5 87.368924    LR 0.000399    Time 0.186710    
2019-09-13 06:58:12,857 - Epoch: [6][  500/ 5005]    Overall Loss 1.283963    Objective Loss 1.283963    Top1 69.508594    Top5 87.392969    LR 0.000398    Time 0.186083    
2019-09-13 06:58:21,867 - Epoch: [6][  550/ 5005]    Overall Loss 1.285454    Objective Loss 1.285454    Top1 69.507812    Top5 87.397017    LR 0.000396    Time 0.185542    
2019-09-13 06:58:30,796 - Epoch: [6][  600/ 5005]    Overall Loss 1.284947    Objective Loss 1.284947    Top1 69.545573    Top5 87.400391    LR 0.000395    Time 0.184958    
2019-09-13 06:58:39,670 - Epoch: [6][  650/ 5005]    Overall Loss 1.284486    Objective Loss 1.284486    Top1 69.500601    Top5 87.421274    LR 0.000394    Time 0.184375    
2019-09-13 06:58:48,543 - Epoch: [6][  700/ 5005]    Overall Loss 1.283652    Objective Loss 1.283652    Top1 69.544085    Top5 87.433036    LR 0.000392    Time 0.183877    
2019-09-13 06:58:57,433 - Epoch: [6][  750/ 5005]    Overall Loss 1.285233    Objective Loss 1.285233    Top1 69.547396    Top5 87.414583    LR 0.000391    Time 0.183468    
2019-09-13 06:59:06,418 - Epoch: [6][  800/ 5005]    Overall Loss 1.285522    Objective Loss 1.285522    Top1 69.519043    Top5 87.423828    LR 0.000390    Time 0.183228    
2019-09-13 06:59:15,561 - Epoch: [6][  850/ 5005]    Overall Loss 1.286153    Objective Loss 1.286153    Top1 69.500919    Top5 87.395680    LR 0.000388    Time 0.183203    
2019-09-13 06:59:24,600 - Epoch: [6][  900/ 5005]    Overall Loss 1.286281    Objective Loss 1.286281    Top1 69.493490    Top5 87.412760    LR 0.000387    Time 0.183064    
2019-09-13 06:59:33,478 - Epoch: [6][  950/ 5005]    Overall Loss 1.286094    Objective Loss 1.286094    Top1 69.491365    Top5 87.421053    LR 0.000386    Time 0.182771    
2019-09-13 06:59:42,665 - Epoch: [6][ 1000/ 5005]    Overall Loss 1.284987    Objective Loss 1.284987    Top1 69.502734    Top5 87.435938    LR 0.000384    Time 0.182816    
2019-09-13 06:59:52,263 - Epoch: [6][ 1050/ 5005]    Overall Loss 1.285543    Objective Loss 1.285543    Top1 69.488467    Top5 87.431920    LR 0.000383    Time 0.183246    
2019-09-13 07:00:01,936 - Epoch: [6][ 1100/ 5005]    Overall Loss 1.285081    Objective Loss 1.285081    Top1 69.509233    Top5 87.436080    LR 0.000382    Time 0.183707    
2019-09-13 07:00:11,172 - Epoch: [6][ 1150/ 5005]    Overall Loss 1.284587    Objective Loss 1.284587    Top1 69.506114    Top5 87.444293    LR 0.000380    Time 0.183748    
2019-09-13 07:00:20,281 - Epoch: [6][ 1200/ 5005]    Overall Loss 1.285395    Objective Loss 1.285395    Top1 69.511068    Top5 87.439779    LR 0.000379    Time 0.183679    
2019-09-13 07:00:36,460 - Epoch: [6][ 1250/ 5005]    Overall Loss 1.284344    Objective Loss 1.284344    Top1 69.549375    Top5 87.439062    LR 0.000378    Time 0.189274    
2019-09-13 07:00:45,791 - Epoch: [6][ 1300/ 5005]    Overall Loss 1.284845    Objective Loss 1.284845    Top1 69.537560    Top5 87.442608    LR 0.000377    Time 0.189168    
2019-09-13 07:00:54,747 - Epoch: [6][ 1350/ 5005]    Overall Loss 1.284863    Objective Loss 1.284863    Top1 69.532407    Top5 87.443576    LR 0.000375    Time 0.188794    
2019-09-13 07:01:03,647 - Epoch: [6][ 1400/ 5005]    Overall Loss 1.285498    Objective Loss 1.285498    Top1 69.520089    Top5 87.438895    LR 0.000374    Time 0.188405    
2019-09-13 07:01:12,542 - Epoch: [6][ 1450/ 5005]    Overall Loss 1.284610    Objective Loss 1.284610    Top1 69.540679    Top5 87.449892    LR 0.000373    Time 0.188041    
2019-09-13 07:01:21,576 - Epoch: [6][ 1500/ 5005]    Overall Loss 1.284199    Objective Loss 1.284199    Top1 69.555208    Top5 87.452865    LR 0.000371    Time 0.187793    
2019-09-13 07:01:30,591 - Epoch: [6][ 1550/ 5005]    Overall Loss 1.284354    Objective Loss 1.284354    Top1 69.551915    Top5 87.461946    LR 0.000370    Time 0.187548    
2019-09-13 07:01:39,588 - Epoch: [6][ 1600/ 5005]    Overall Loss 1.284745    Objective Loss 1.284745    Top1 69.536133    Top5 87.461914    LR 0.000369    Time 0.187308    
2019-09-13 07:01:48,605 - Epoch: [6][ 1650/ 5005]    Overall Loss 1.284816    Objective Loss 1.284816    Top1 69.548059    Top5 87.464015    LR 0.000367    Time 0.187094    
2019-09-13 07:01:57,588 - Epoch: [6][ 1700/ 5005]    Overall Loss 1.285495    Objective Loss 1.285495    Top1 69.523897    Top5 87.446232    LR 0.000366    Time 0.186874    
2019-09-13 07:02:06,683 - Epoch: [6][ 1750/ 5005]    Overall Loss 1.285746    Objective Loss 1.285746    Top1 69.525223    Top5 87.439062    LR 0.000365    Time 0.186730    
2019-09-13 07:02:15,630 - Epoch: [6][ 1800/ 5005]    Overall Loss 1.286090    Objective Loss 1.286090    Top1 69.508464    Top5 87.442057    LR 0.000364    Time 0.186512    
2019-09-13 07:02:24,603 - Epoch: [6][ 1850/ 5005]    Overall Loss 1.285737    Objective Loss 1.285737    Top1 69.509079    Top5 87.455025    LR 0.000362    Time 0.186320    
2019-09-13 07:02:33,498 - Epoch: [6][ 1900/ 5005]    Overall Loss 1.285725    Objective Loss 1.285725    Top1 69.507401    Top5 87.458470    LR 0.000361    Time 0.186097    
2019-09-13 07:02:42,462 - Epoch: [6][ 1950/ 5005]    Overall Loss 1.286031    Objective Loss 1.286031    Top1 69.501603    Top5 87.451923    LR 0.000360    Time 0.185920    
2019-09-13 07:02:51,407 - Epoch: [6][ 2000/ 5005]    Overall Loss 1.285441    Objective Loss 1.285441    Top1 69.505664    Top5 87.459961    LR 0.000358    Time 0.185743    
2019-09-13 07:03:00,366 - Epoch: [6][ 2050/ 5005]    Overall Loss 1.286295    Objective Loss 1.286295    Top1 69.489901    Top5 87.449695    LR 0.000357    Time 0.185581    
2019-09-13 07:03:09,251 - Epoch: [6][ 2100/ 5005]    Overall Loss 1.285773    Objective Loss 1.285773    Top1 69.492374    Top5 87.452381    LR 0.000356    Time 0.185392    
2019-09-13 07:03:18,127 - Epoch: [6][ 2150/ 5005]    Overall Loss 1.286479    Objective Loss 1.286479    Top1 69.488009    Top5 87.446766    LR 0.000355    Time 0.185208    
2019-09-13 07:03:27,093 - Epoch: [6][ 2200/ 5005]    Overall Loss 1.287138    Objective Loss 1.287138    Top1 69.470703    Top5 87.436967    LR 0.000353    Time 0.185073    
2019-09-13 07:03:36,127 - Epoch: [6][ 2250/ 5005]    Overall Loss 1.287153    Objective Loss 1.287153    Top1 69.467188    Top5 87.439410    LR 0.000352    Time 0.184974    
2019-09-13 07:03:45,215 - Epoch: [6][ 2300/ 5005]    Overall Loss 1.287405    Objective Loss 1.287405    Top1 69.461787    Top5 87.433254    LR 0.000351    Time 0.184903    
2019-09-13 07:03:54,140 - Epoch: [6][ 2350/ 5005]    Overall Loss 1.287501    Objective Loss 1.287501    Top1 69.462766    Top5 87.428191    LR 0.000350    Time 0.184764    
2019-09-13 07:04:03,056 - Epoch: [6][ 2400/ 5005]    Overall Loss 1.287247    Objective Loss 1.287247    Top1 69.468750    Top5 87.431641    LR 0.000348    Time 0.184629    
2019-09-13 07:04:11,964 - Epoch: [6][ 2450/ 5005]    Overall Loss 1.287563    Objective Loss 1.287563    Top1 69.458068    Top5 87.426818    LR 0.000347    Time 0.184495    
2019-09-13 07:04:20,877 - Epoch: [6][ 2500/ 5005]    Overall Loss 1.287261    Objective Loss 1.287261    Top1 69.462187    Top5 87.426250    LR 0.000346    Time 0.184369    
2019-09-13 07:04:29,804 - Epoch: [6][ 2550/ 5005]    Overall Loss 1.286229    Objective Loss 1.286229    Top1 69.477941    Top5 87.443168    LR 0.000345    Time 0.184253    
2019-09-13 07:04:38,767 - Epoch: [6][ 2600/ 5005]    Overall Loss 1.285909    Objective Loss 1.285909    Top1 69.485877    Top5 87.450721    LR 0.000343    Time 0.184156    
2019-09-13 07:04:47,664 - Epoch: [6][ 2650/ 5005]    Overall Loss 1.285649    Objective Loss 1.285649    Top1 69.481722    Top5 87.454599    LR 0.000342    Time 0.184038    
2019-09-13 07:04:56,670 - Epoch: [6][ 2700/ 5005]    Overall Loss 1.285609    Objective Loss 1.285609    Top1 69.479167    Top5 87.457465    LR 0.000341    Time 0.183964    
2019-09-13 07:05:05,614 - Epoch: [6][ 2750/ 5005]    Overall Loss 1.285358    Objective Loss 1.285358    Top1 69.478409    Top5 87.465909    LR 0.000340    Time 0.183870    
2019-09-13 07:05:14,552 - Epoch: [6][ 2800/ 5005]    Overall Loss 1.285965    Objective Loss 1.285965    Top1 69.468610    Top5 87.457031    LR 0.000338    Time 0.183778    
2019-09-13 07:05:23,455 - Epoch: [6][ 2850/ 5005]    Overall Loss 1.285625    Objective Loss 1.285625    Top1 69.468613    Top5 87.459704    LR 0.000337    Time 0.183677    
2019-09-13 07:05:32,323 - Epoch: [6][ 2900/ 5005]    Overall Loss 1.285929    Objective Loss 1.285929    Top1 69.457031    Top5 87.461342    LR 0.000336    Time 0.183567    
2019-09-13 07:05:41,114 - Epoch: [6][ 2950/ 5005]    Overall Loss 1.286237    Objective Loss 1.286237    Top1 69.451139    Top5 87.457230    LR 0.000335    Time 0.183434    
2019-09-13 07:05:49,873 - Epoch: [6][ 3000/ 5005]    Overall Loss 1.285839    Objective Loss 1.285839    Top1 69.461068    Top5 87.463542    LR 0.000333    Time 0.183296    
2019-09-13 07:05:58,689 - Epoch: [6][ 3050/ 5005]    Overall Loss 1.285606    Objective Loss 1.285606    Top1 69.465804    Top5 87.468110    LR 0.000332    Time 0.183180    
2019-09-13 07:06:07,509 - Epoch: [6][ 3100/ 5005]    Overall Loss 1.286108    Objective Loss 1.286108    Top1 69.446699    Top5 87.462198    LR 0.000331    Time 0.183070    
2019-09-13 07:06:16,469 - Epoch: [6][ 3150/ 5005]    Overall Loss 1.285903    Objective Loss 1.285903    Top1 69.442460    Top5 87.468502    LR 0.000330    Time 0.183008    
2019-09-13 07:06:25,286 - Epoch: [6][ 3200/ 5005]    Overall Loss 1.285204    Objective Loss 1.285204    Top1 69.459595    Top5 87.476196    LR 0.000328    Time 0.182903    
2019-09-13 07:06:34,105 - Epoch: [6][ 3250/ 5005]    Overall Loss 1.285275    Objective Loss 1.285275    Top1 69.457572    Top5 87.480048    LR 0.000327    Time 0.182801    
2019-09-13 07:06:43,062 - Epoch: [6][ 3300/ 5005]    Overall Loss 1.285558    Objective Loss 1.285558    Top1 69.455611    Top5 87.475379    LR 0.000326    Time 0.182745    
2019-09-13 07:06:51,984 - Epoch: [6][ 3350/ 5005]    Overall Loss 1.285022    Objective Loss 1.285022    Top1 69.463619    Top5 87.481810    LR 0.000325    Time 0.182680    
2019-09-13 07:07:00,902 - Epoch: [6][ 3400/ 5005]    Overall Loss 1.284588    Objective Loss 1.284588    Top1 69.464040    Top5 87.486673    LR 0.000323    Time 0.182615    
2019-09-13 07:07:09,810 - Epoch: [6][ 3450/ 5005]    Overall Loss 1.284630    Objective Loss 1.284630    Top1 69.457880    Top5 87.484715    LR 0.000322    Time 0.182550    
2019-09-13 07:07:18,752 - Epoch: [6][ 3500/ 5005]    Overall Loss 1.284793    Objective Loss 1.284793    Top1 69.449442    Top5 87.484933    LR 0.000321    Time 0.182496    
2019-09-13 07:07:27,663 - Epoch: [6][ 3550/ 5005]    Overall Loss 1.284843    Objective Loss 1.284843    Top1 69.448063    Top5 87.485695    LR 0.000320    Time 0.182434    
2019-09-13 07:07:36,730 - Epoch: [6][ 3600/ 5005]    Overall Loss 1.284548    Objective Loss 1.284548    Top1 69.449436    Top5 87.487522    LR 0.000319    Time 0.182418    
2019-09-13 07:07:45,825 - Epoch: [6][ 3650/ 5005]    Overall Loss 1.284595    Objective Loss 1.284595    Top1 69.447346    Top5 87.488121    LR 0.000317    Time 0.182411    
2019-09-13 07:07:54,825 - Epoch: [6][ 3700/ 5005]    Overall Loss 1.284331    Objective Loss 1.284331    Top1 69.451964    Top5 87.484903    LR 0.000316    Time 0.182377    
2019-09-13 07:08:03,798 - Epoch: [6][ 3750/ 5005]    Overall Loss 1.284252    Objective Loss 1.284252    Top1 69.453229    Top5 87.488958    LR 0.000315    Time 0.182337    
2019-09-13 07:08:12,827 - Epoch: [6][ 3800/ 5005]    Overall Loss 1.284303    Objective Loss 1.284303    Top1 69.446032    Top5 87.486431    LR 0.000314    Time 0.182313    
2019-09-13 07:08:21,810 - Epoch: [6][ 3850/ 5005]    Overall Loss 1.284594    Objective Loss 1.284594    Top1 69.439123    Top5 87.483157    LR 0.000313    Time 0.182278    
2019-09-13 07:08:30,819 - Epoch: [6][ 3900/ 5005]    Overall Loss 1.284356    Objective Loss 1.284356    Top1 69.444511    Top5 87.488982    LR 0.000311    Time 0.182250    
2019-09-13 07:08:39,799 - Epoch: [6][ 3950/ 5005]    Overall Loss 1.284314    Objective Loss 1.284314    Top1 69.443038    Top5 87.485067    LR 0.000310    Time 0.182216    
2019-09-13 07:08:48,787 - Epoch: [6][ 4000/ 5005]    Overall Loss 1.284264    Objective Loss 1.284264    Top1 69.440430    Top5 87.482129    LR 0.000309    Time 0.182184    
2019-09-13 07:08:57,883 - Epoch: [6][ 4050/ 5005]    Overall Loss 1.284248    Objective Loss 1.284248    Top1 69.442226    Top5 87.483218    LR 0.000308    Time 0.182180    
2019-09-13 07:09:06,849 - Epoch: [6][ 4100/ 5005]    Overall Loss 1.284384    Objective Loss 1.284384    Top1 69.436928    Top5 87.482470    LR 0.000307    Time 0.182144    
2019-09-13 07:09:15,907 - Epoch: [6][ 4150/ 5005]    Overall Loss 1.284352    Objective Loss 1.284352    Top1 69.432888    Top5 87.483622    LR 0.000305    Time 0.182132    
2019-09-13 07:09:25,063 - Epoch: [6][ 4200/ 5005]    Overall Loss 1.284022    Objective Loss 1.284022    Top1 69.431455    Top5 87.489676    LR 0.000304    Time 0.182133    
2019-09-13 07:09:34,152 - Epoch: [6][ 4250/ 5005]    Overall Loss 1.283988    Objective Loss 1.283988    Top1 69.434191    Top5 87.486857    LR 0.000303    Time 0.182128    
2019-09-13 07:09:43,209 - Epoch: [6][ 4300/ 5005]    Overall Loss 1.284321    Objective Loss 1.284321    Top1 69.428870    Top5 87.479651    LR 0.000302    Time 0.182116    
2019-09-13 07:09:52,236 - Epoch: [6][ 4350/ 5005]    Overall Loss 1.284632    Objective Loss 1.284632    Top1 69.426994    Top5 87.476114    LR 0.000301    Time 0.182097    
2019-09-13 07:10:01,311 - Epoch: [6][ 4400/ 5005]    Overall Loss 1.284498    Objective Loss 1.284498    Top1 69.430043    Top5 87.474609    LR 0.000300    Time 0.182089    
2019-09-13 07:10:10,342 - Epoch: [6][ 4450/ 5005]    Overall Loss 1.284563    Objective Loss 1.284563    Top1 69.432584    Top5 87.472261    LR 0.000298    Time 0.182072    
2019-09-13 07:10:19,460 - Epoch: [6][ 4500/ 5005]    Overall Loss 1.284768    Objective Loss 1.284768    Top1 69.431250    Top5 87.472309    LR 0.000297    Time 0.182075    
2019-09-13 07:10:28,376 - Epoch: [6][ 4550/ 5005]    Overall Loss 1.284564    Objective Loss 1.284564    Top1 69.431920    Top5 87.475532    LR 0.000296    Time 0.182032    
2019-09-13 07:10:37,178 - Epoch: [6][ 4600/ 5005]    Overall Loss 1.284892    Objective Loss 1.284892    Top1 69.426885    Top5 87.468920    LR 0.000295    Time 0.181967    
2019-09-13 07:10:45,986 - Epoch: [6][ 4650/ 5005]    Overall Loss 1.284955    Objective Loss 1.284955    Top1 69.427419    Top5 87.468666    LR 0.000294    Time 0.181903    
2019-09-13 07:10:54,864 - Epoch: [6][ 4700/ 5005]    Overall Loss 1.285129    Objective Loss 1.285129    Top1 69.426695    Top5 87.466423    LR 0.000293    Time 0.181856    
2019-09-13 07:11:03,766 - Epoch: [6][ 4750/ 5005]    Overall Loss 1.284987    Objective Loss 1.284987    Top1 69.431332    Top5 87.468257    LR 0.000291    Time 0.181816    
2019-09-13 07:11:12,695 - Epoch: [6][ 4800/ 5005]    Overall Loss 1.284747    Objective Loss 1.284747    Top1 69.437744    Top5 87.472249    LR 0.000290    Time 0.181781    
2019-09-13 07:11:21,614 - Epoch: [6][ 4850/ 5005]    Overall Loss 1.284806    Objective Loss 1.284806    Top1 69.439594    Top5 87.472777    LR 0.000289    Time 0.181746    
2019-09-13 07:11:30,529 - Epoch: [6][ 4900/ 5005]    Overall Loss 1.284812    Objective Loss 1.284812    Top1 69.441805    Top5 87.474171    LR 0.000288    Time 0.181710    
2019-09-13 07:11:39,662 - Epoch: [6][ 4950/ 5005]    Overall Loss 1.284536    Objective Loss 1.284536    Top1 69.443576    Top5 87.479561    LR 0.000287    Time 0.181719    
2019-09-13 07:11:48,478 - Epoch: [6][ 5000/ 5005]    Overall Loss 1.284451    Objective Loss 1.284451    Top1 69.447500    Top5 87.481719    LR 0.000286    Time 0.181664    
2019-09-13 07:11:49,623 - 
Parameters:
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                      | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.float_weight                 | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12687 |  0.00014 |    0.07434 |
|  1 | module.conv1.weight                       | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16010 |  0.00030 |    0.09682 |
|  2 | module.layer1.0.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05224 | -0.00311 |    0.03091 |
|  3 | module.layer1.0.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08021 | -0.00447 |    0.04856 |
|  4 | module.layer1.0.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04421 | -0.00084 |    0.03130 |
|  5 | module.layer1.0.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10239 | -0.00195 |    0.07275 |
|  6 | module.layer1.1.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04973 | -0.00231 |    0.03351 |
|  7 | module.layer1.1.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08889 | -0.00414 |    0.06045 |
|  8 | module.layer1.1.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04301 | -0.00117 |    0.03080 |
|  9 | module.layer1.1.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12407 | -0.00337 |    0.08911 |
| 10 | module.layer2.0.conv1.float_weight        | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04067 | -0.00134 |    0.02875 |
| 11 | module.layer2.0.conv1.weight              | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13050 | -0.00431 |    0.09249 |
| 12 | module.layer2.0.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03326 | -0.00122 |    0.02340 |
| 13 | module.layer2.0.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08776 | -0.00323 |    0.06191 |
| 14 | module.layer2.0.downsample.0.float_weight | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06902 | -0.00256 |    0.04330 |
| 15 | module.layer2.0.downsample.0.weight       | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10528 | -0.00392 |    0.06716 |
| 16 | module.layer2.1.conv1.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03342 | -0.00144 |    0.02372 |
| 17 | module.layer2.1.conv1.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08592 | -0.00373 |    0.06116 |
| 18 | module.layer2.1.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02939 | -0.00122 |    0.02175 |
| 19 | module.layer2.1.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09402 | -0.00392 |    0.06967 |
| 20 | module.layer3.0.conv1.float_weight        | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02840 | -0.00132 |    0.02046 |
| 21 | module.layer3.0.conv1.weight              | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08233 | -0.00384 |    0.05944 |
| 22 | module.layer3.0.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02449 | -0.00075 |    0.01794 |
| 23 | module.layer3.0.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08550 | -0.00261 |    0.06273 |
| 24 | module.layer3.0.downsample.0.float_weight | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03219 | -0.00183 |    0.02322 |
| 25 | module.layer3.0.downsample.0.weight       | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12667 | -0.00721 |    0.09152 |
| 26 | module.layer3.1.conv1.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02188 | -0.00160 |    0.01629 |
| 27 | module.layer3.1.conv1.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08464 | -0.00620 |    0.06309 |
| 28 | module.layer3.1.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02022 | -0.00139 |    0.01519 |
| 29 | module.layer3.1.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07225 | -0.00497 |    0.05433 |
| 30 | module.layer4.0.conv1.float_weight        | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01944 | -0.00150 |    0.01488 |
| 31 | module.layer4.0.conv1.weight              | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06726 | -0.00521 |    0.05153 |
| 32 | module.layer4.0.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01695 | -0.00127 |    0.01309 |
| 33 | module.layer4.0.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06145 | -0.00460 |    0.04753 |
| 34 | module.layer4.0.downsample.0.float_weight | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03205 | -0.00083 |    0.02335 |
| 35 | module.layer4.0.downsample.0.weight       | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05297 | -0.00138 |    0.03876 |
| 36 | module.layer4.1.conv1.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01744 | -0.00219 |    0.01373 |
| 37 | module.layer4.1.conv1.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07913 | -0.00992 |    0.06234 |
| 38 | module.layer4.1.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01291 | -0.00008 |    0.00988 |
| 39 | module.layer4.1.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05571 | -0.00037 |    0.04270 |
| 40 | module.fc.float_weight                    | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06776 |  0.00000 |    0.04972 |
| 41 | module.fc.weight                          | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09273 | -0.00020 |    0.06847 |
| 42 | Total sparsity:                           | -                |      23357824 |       23357824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2019-09-13 07:11:49,623 - Total sparsity: 0.00

2019-09-13 07:11:49,623 - --- validate (epoch=6)-----------
2019-09-13 07:11:49,624 - 50000 samples (256 per mini-batch)
2019-09-13 07:12:01,205 - Epoch: [6][   50/  195]    Loss 0.925451    Top1 75.914062    Top5 93.320312    
2019-09-13 07:12:09,184 - Epoch: [6][  100/  195]    Loss 1.059329    Top1 73.691406    Top5 91.726562    
2019-09-13 07:12:16,619 - Epoch: [6][  150/  195]    Loss 1.199774    Top1 70.929688    Top5 89.786458    
2019-09-13 07:12:24,039 - ==> Top1: 69.874    Top5: 89.140    Loss: 1.257

2019-09-13 07:12:24,044 - ==> Best Top1: 69.874 on Epoch: 6
2019-09-13 07:12:24,044 - Saving checkpoint to: 8b_logs/res18___2019.09.13-052127/res18_checkpoint.pth.tar
2019-09-13 07:12:30,426 - Saving PACT param_value.......
2019-09-13 07:12:30,427 - The PACT Clip Parameter Value............
2019-09-13 07:12:30,432 - 

2019-09-13 07:12:30,432 - +--------------------------------+--------------+
| Layers                         |   PACT_alpha |
|--------------------------------+--------------|
| module.relu.clip_val           |      7.80168 |
| module.layer1.0.relu1.clip_val |      7.8017  |
| module.layer1.0.relu2.clip_val |      7.80171 |
| module.layer1.1.relu1.clip_val |      7.8017  |
| module.layer1.1.relu2.clip_val |      7.80173 |
| module.layer2.0.relu1.clip_val |      7.8017  |
| module.layer2.0.relu2.clip_val |      7.80171 |
| module.layer2.1.relu1.clip_val |      7.8017  |
| module.layer2.1.relu2.clip_val |      7.8018  |
| module.layer3.0.relu1.clip_val |      7.8017  |
| module.layer3.0.relu2.clip_val |      7.8017  |
| module.layer3.1.relu1.clip_val |      7.8017  |
| module.layer3.1.relu2.clip_val |      7.80176 |
| module.layer4.0.relu1.clip_val |      7.8017  |
| module.layer4.0.relu2.clip_val |      7.80184 |
| module.layer4.1.relu1.clip_val |      7.8017  |
| module.layer4.1.relu2.clip_val |      8.11233 |
+--------------------------------+--------------+
2019-09-13 07:12:30,435 - 

2019-09-13 07:12:30,435 - Training epoch: 1281167 samples (256 per mini-batch)
2019-09-13 07:12:43,082 - Epoch: [7][   50/ 5005]    Overall Loss 1.267952    Objective Loss 1.267952    Top1 69.843750    Top5 87.796875    LR 0.000284    Time 0.252842    
2019-09-13 07:12:51,991 - Epoch: [7][  100/ 5005]    Overall Loss 1.280692    Objective Loss 1.280692    Top1 69.398438    Top5 87.535156    LR 0.000283    Time 0.215482    
2019-09-13 07:13:00,923 - Epoch: [7][  150/ 5005]    Overall Loss 1.279140    Objective Loss 1.279140    Top1 69.489583    Top5 87.473958    LR 0.000282    Time 0.203179    
2019-09-13 07:13:10,090 - Epoch: [7][  200/ 5005]    Overall Loss 1.274221    Objective Loss 1.274221    Top1 69.658203    Top5 87.462891    LR 0.000281    Time 0.198208    
2019-09-13 07:13:19,080 - Epoch: [7][  250/ 5005]    Overall Loss 1.274355    Objective Loss 1.274355    Top1 69.696875    Top5 87.443750    LR 0.000280    Time 0.194510    
2019-09-13 07:13:28,154 - Epoch: [7][  300/ 5005]    Overall Loss 1.275512    Objective Loss 1.275512    Top1 69.647135    Top5 87.420573    LR 0.000279    Time 0.192327    
2019-09-13 07:13:37,228 - Epoch: [7][  350/ 5005]    Overall Loss 1.278890    Objective Loss 1.278890    Top1 69.543527    Top5 87.406250    LR 0.000278    Time 0.190769    
2019-09-13 07:13:46,267 - Epoch: [7][  400/ 5005]    Overall Loss 1.281880    Objective Loss 1.281880    Top1 69.489258    Top5 87.380859    LR 0.000276    Time 0.189511    
2019-09-13 07:13:55,308 - Epoch: [7][  450/ 5005]    Overall Loss 1.280716    Objective Loss 1.280716    Top1 69.537326    Top5 87.404514    LR 0.000275    Time 0.188539    
2019-09-13 07:14:04,357 - Epoch: [7][  500/ 5005]    Overall Loss 1.278354    Objective Loss 1.278354    Top1 69.567969    Top5 87.439062    LR 0.000274    Time 0.187777    
2019-09-13 07:14:13,375 - Epoch: [7][  550/ 5005]    Overall Loss 1.278927    Objective Loss 1.278927    Top1 69.551847    Top5 87.421165    LR 0.000273    Time 0.187097    
2019-09-13 07:14:22,519 - Epoch: [7][  600/ 5005]    Overall Loss 1.278605    Objective Loss 1.278605    Top1 69.574870    Top5 87.448568    LR 0.000272    Time 0.186739    
2019-09-13 07:14:31,592 - Epoch: [7][  650/ 5005]    Overall Loss 1.278448    Objective Loss 1.278448    Top1 69.588942    Top5 87.468149    LR 0.000271    Time 0.186326    
2019-09-13 07:14:40,852 - Epoch: [7][  700/ 5005]    Overall Loss 1.278355    Objective Loss 1.278355    Top1 69.559152    Top5 87.496652    LR 0.000270    Time 0.186240    
2019-09-13 07:14:49,964 - Epoch: [7][  750/ 5005]    Overall Loss 1.277587    Objective Loss 1.277587    Top1 69.584375    Top5 87.498438    LR 0.000269    Time 0.185968    
2019-09-13 07:14:58,975 - Epoch: [7][  800/ 5005]    Overall Loss 1.279073    Objective Loss 1.279073    Top1 69.578125    Top5 87.469238    LR 0.000268    Time 0.185603    
2019-09-13 07:15:07,889 - Epoch: [7][  850/ 5005]    Overall Loss 1.279946    Objective Loss 1.279946    Top1 69.585938    Top5 87.462776    LR 0.000266    Time 0.185168    
2019-09-13 07:15:16,867 - Epoch: [7][  900/ 5005]    Overall Loss 1.278764    Objective Loss 1.278764    Top1 69.630208    Top5 87.483507    LR 0.000265    Time 0.184852    
2019-09-13 07:15:25,857 - Epoch: [7][  950/ 5005]    Overall Loss 1.279765    Objective Loss 1.279765    Top1 69.619655    Top5 87.479441    LR 0.000264    Time 0.184581    
2019-09-13 07:15:35,069 - Epoch: [7][ 1000/ 5005]    Overall Loss 1.280419    Objective Loss 1.280419    Top1 69.583594    Top5 87.474609    LR 0.000263    Time 0.184519    
2019-09-13 07:15:44,112 - Epoch: [7][ 1050/ 5005]    Overall Loss 1.278888    Objective Loss 1.278888    Top1 69.627604    Top5 87.513393    LR 0.000262    Time 0.184341    
2019-09-13 07:15:53,222 - Epoch: [7][ 1100/ 5005]    Overall Loss 1.279636    Objective Loss 1.279636    Top1 69.598366    Top5 87.503906    LR 0.000261    Time 0.184239    
2019-09-13 07:16:02,602 - Epoch: [7][ 1150/ 5005]    Overall Loss 1.279028    Objective Loss 1.279028    Top1 69.609035    Top5 87.513247    LR 0.000260    Time 0.184383    
2019-09-13 07:16:11,661 - Epoch: [7][ 1200/ 5005]    Overall Loss 1.278321    Objective Loss 1.278321    Top1 69.621094    Top5 87.531901    LR 0.000259    Time 0.184246    
2019-09-13 07:16:20,649 - Epoch: [7][ 1250/ 5005]    Overall Loss 1.278723    Objective Loss 1.278723    Top1 69.620312    Top5 87.526563    LR 0.000258    Time 0.184064    
2019-09-13 07:16:29,632 - Epoch: [7][ 1300/ 5005]    Overall Loss 1.279703    Objective Loss 1.279703    Top1 69.601262    Top5 87.520433    LR 0.000257    Time 0.183891    
2019-09-13 07:16:38,649 - Epoch: [7][ 1350/ 5005]    Overall Loss 1.279469    Objective Loss 1.279469    Top1 69.611979    Top5 87.524884    LR 0.000256    Time 0.183757    
2019-09-13 07:16:47,599 - Epoch: [7][ 1400/ 5005]    Overall Loss 1.278247    Objective Loss 1.278247    Top1 69.642578    Top5 87.541295    LR 0.000255    Time 0.183584    
2019-09-13 07:16:56,784 - Epoch: [7][ 1450/ 5005]    Overall Loss 1.278561    Objective Loss 1.278561    Top1 69.633890    Top5 87.537716    LR 0.000254    Time 0.183585    
2019-09-13 07:17:05,846 - Epoch: [7][ 1500/ 5005]    Overall Loss 1.277945    Objective Loss 1.277945    Top1 69.641146    Top5 87.546875    LR 0.000252    Time 0.183504    
2019-09-13 07:17:14,882 - Epoch: [7][ 1550/ 5005]    Overall Loss 1.278455    Objective Loss 1.278455    Top1 69.635081    Top5 87.533266    LR 0.000251    Time 0.183412    
2019-09-13 07:17:24,233 - Epoch: [7][ 1600/ 5005]    Overall Loss 1.277569    Objective Loss 1.277569    Top1 69.659668    Top5 87.539307    LR 0.000250    Time 0.183522    
2019-09-13 07:17:33,302 - Epoch: [7][ 1650/ 5005]    Overall Loss 1.277244    Objective Loss 1.277244    Top1 69.666193    Top5 87.542140    LR 0.000249    Time 0.183455    
2019-09-13 07:17:42,369 - Epoch: [7][ 1700/ 5005]    Overall Loss 1.277608    Objective Loss 1.277608    Top1 69.645221    Top5 87.538603    LR 0.000248    Time 0.183390    
2019-09-13 07:17:51,402 - Epoch: [7][ 1750/ 5005]    Overall Loss 1.276608    Objective Loss 1.276608    Top1 69.651786    Top5 87.555134    LR 0.000247    Time 0.183311    
2019-09-13 07:18:00,591 - Epoch: [7][ 1800/ 5005]    Overall Loss 1.276067    Objective Loss 1.276067    Top1 69.661024    Top5 87.559462    LR 0.000246    Time 0.183321    
2019-09-13 07:18:09,630 - Epoch: [7][ 1850/ 5005]    Overall Loss 1.276453    Objective Loss 1.276453    Top1 69.644637    Top5 87.553421    LR 0.000245    Time 0.183251    
2019-09-13 07:18:18,570 - Epoch: [7][ 1900/ 5005]    Overall Loss 1.276582    Objective Loss 1.276582    Top1 69.650082    Top5 87.551604    LR 0.000244    Time 0.183132    
2019-09-13 07:18:27,694 - Epoch: [7][ 1950/ 5005]    Overall Loss 1.276863    Objective Loss 1.276863    Top1 69.636018    Top5 87.558093    LR 0.000243    Time 0.183113    
2019-09-13 07:18:36,738 - Epoch: [7][ 2000/ 5005]    Overall Loss 1.277142    Objective Loss 1.277142    Top1 69.638477    Top5 87.556445    LR 0.000242    Time 0.183055    
2019-09-13 07:18:46,035 - Epoch: [7][ 2050/ 5005]    Overall Loss 1.276760    Objective Loss 1.276760    Top1 69.631669    Top5 87.563834    LR 0.000241    Time 0.183123    
2019-09-13 07:18:55,102 - Epoch: [7][ 2100/ 5005]    Overall Loss 1.277408    Objective Loss 1.277408    Top1 69.615513    Top5 87.552641    LR 0.000240    Time 0.183079    
2019-09-13 07:19:04,119 - Epoch: [7][ 2150/ 5005]    Overall Loss 1.277255    Objective Loss 1.277255    Top1 69.624455    Top5 87.552326    LR 0.000239    Time 0.183012    
2019-09-13 07:19:13,174 - Epoch: [7][ 2200/ 5005]    Overall Loss 1.277939    Objective Loss 1.277939    Top1 69.607777    Top5 87.551669    LR 0.000238    Time 0.182967    
2019-09-13 07:19:22,313 - Epoch: [7][ 2250/ 5005]    Overall Loss 1.277778    Objective Loss 1.277778    Top1 69.603646    Top5 87.554340    LR 0.000237    Time 0.182961    
2019-09-13 07:19:31,364 - Epoch: [7][ 2300/ 5005]    Overall Loss 1.277049    Objective Loss 1.277049    Top1 69.623471    Top5 87.569124    LR 0.000236    Time 0.182917    
2019-09-13 07:19:40,355 - Epoch: [7][ 2350/ 5005]    Overall Loss 1.276585    Objective Loss 1.276585    Top1 69.640791    Top5 87.580120    LR 0.000235    Time 0.182850    
2019-09-13 07:19:49,313 - Epoch: [7][ 2400/ 5005]    Overall Loss 1.276898    Objective Loss 1.276898    Top1 69.632812    Top5 87.577962    LR 0.000234    Time 0.182771    
2019-09-13 07:19:58,358 - Epoch: [7][ 2450/ 5005]    Overall Loss 1.276635    Objective Loss 1.276635    Top1 69.640306    Top5 87.582270    LR 0.000233    Time 0.182731    
2019-09-13 07:20:07,694 - Epoch: [7][ 2500/ 5005]    Overall Loss 1.276018    Objective Loss 1.276018    Top1 69.649219    Top5 87.590781    LR 0.000232    Time 0.182809    
2019-09-13 07:20:16,725 - Epoch: [7][ 2550/ 5005]    Overall Loss 1.276145    Objective Loss 1.276145    Top1 69.652880    Top5 87.590380    LR 0.000231    Time 0.182765    
2019-09-13 07:20:25,705 - Epoch: [7][ 2600/ 5005]    Overall Loss 1.276290    Objective Loss 1.276290    Top1 69.648588    Top5 87.588642    LR 0.000230    Time 0.182702    
2019-09-13 07:20:34,717 - Epoch: [7][ 2650/ 5005]    Overall Loss 1.276714    Objective Loss 1.276714    Top1 69.639004    Top5 87.580631    LR 0.000229    Time 0.182654    
2019-09-13 07:20:43,846 - Epoch: [7][ 2700/ 5005]    Overall Loss 1.276751    Objective Loss 1.276751    Top1 69.638455    Top5 87.576389    LR 0.000228    Time 0.182652    
2019-09-13 07:20:52,892 - Epoch: [7][ 2750/ 5005]    Overall Loss 1.276196    Objective Loss 1.276196    Top1 69.655114    Top5 87.582812    LR 0.000227    Time 0.182618    
2019-09-13 07:21:01,906 - Epoch: [7][ 2800/ 5005]    Overall Loss 1.276646    Objective Loss 1.276646    Top1 69.639369    Top5 87.577288    LR 0.000226    Time 0.182575    
2019-09-13 07:21:10,826 - Epoch: [7][ 2850/ 5005]    Overall Loss 1.276291    Objective Loss 1.276291    Top1 69.650493    Top5 87.584704    LR 0.000225    Time 0.182500    
2019-09-13 07:21:19,922 - Epoch: [7][ 2900/ 5005]    Overall Loss 1.275806    Objective Loss 1.275806    Top1 69.657193    Top5 87.591191    LR 0.000224    Time 0.182489    
2019-09-13 07:21:29,374 - Epoch: [7][ 2950/ 5005]    Overall Loss 1.276250    Objective Loss 1.276250    Top1 69.652675    Top5 87.586732    LR 0.000223    Time 0.182599    
2019-09-13 07:21:38,558 - Epoch: [7][ 3000/ 5005]    Overall Loss 1.276823    Objective Loss 1.276823    Top1 69.642839    Top5 87.578646    LR 0.000222    Time 0.182615    
2019-09-13 07:21:47,658 - Epoch: [7][ 3050/ 5005]    Overall Loss 1.276634    Objective Loss 1.276634    Top1 69.643443    Top5 87.579662    LR 0.000221    Time 0.182604    
2019-09-13 07:21:56,696 - Epoch: [7][ 3100/ 5005]    Overall Loss 1.276603    Objective Loss 1.276603    Top1 69.646673    Top5 87.582787    LR 0.000220    Time 0.182573    
2019-09-13 07:22:05,664 - Epoch: [7][ 3150/ 5005]    Overall Loss 1.277534    Objective Loss 1.277534    Top1 69.623884    Top5 87.572917    LR 0.000219    Time 0.182520    
2019-09-13 07:22:14,657 - Epoch: [7][ 3200/ 5005]    Overall Loss 1.277402    Objective Loss 1.277402    Top1 69.633911    Top5 87.574341    LR 0.000218    Time 0.182478    
2019-09-13 07:22:23,637 - Epoch: [7][ 3250/ 5005]    Overall Loss 1.277500    Objective Loss 1.277500    Top1 69.633774    Top5 87.571995    LR 0.000217    Time 0.182432    
2019-09-13 07:22:32,659 - Epoch: [7][ 3300/ 5005]    Overall Loss 1.277810    Objective Loss 1.277810    Top1 69.631747    Top5 87.563565    LR 0.000216    Time 0.182401    
2019-09-13 07:22:41,651 - Epoch: [7][ 3350/ 5005]    Overall Loss 1.277523    Objective Loss 1.277523    Top1 69.633862    Top5 87.567048    LR 0.000215    Time 0.182361    
2019-09-13 07:22:50,975 - Epoch: [7][ 3400/ 5005]    Overall Loss 1.277357    Objective Loss 1.277357    Top1 69.638787    Top5 87.568130    LR 0.000214    Time 0.182421    
2019-09-13 07:22:59,962 - Epoch: [7][ 3450/ 5005]    Overall Loss 1.277859    Objective Loss 1.277859    Top1 69.626359    Top5 87.559783    LR 0.000213    Time 0.182381    
2019-09-13 07:23:08,965 - Epoch: [7][ 3500/ 5005]    Overall Loss 1.278193    Objective Loss 1.278193    Top1 69.619308    Top5 87.555246    LR 0.000213    Time 0.182346    
2019-09-13 07:23:18,073 - Epoch: [7][ 3550/ 5005]    Overall Loss 1.278117    Objective Loss 1.278117    Top1 69.616087    Top5 87.556558    LR 0.000212    Time 0.182343    
2019-09-13 07:23:27,255 - Epoch: [7][ 3600/ 5005]    Overall Loss 1.278175    Objective Loss 1.278175    Top1 69.610677    Top5 87.558811    LR 0.000211    Time 0.182360    
2019-09-13 07:23:36,341 - Epoch: [7][ 3650/ 5005]    Overall Loss 1.277697    Objective Loss 1.277697    Top1 69.618579    Top5 87.564640    LR 0.000210    Time 0.182350    
2019-09-13 07:23:45,528 - Epoch: [7][ 3700/ 5005]    Overall Loss 1.277895    Objective Loss 1.277895    Top1 69.613387    Top5 87.563767    LR 0.000209    Time 0.182367    
2019-09-13 07:23:54,595 - Epoch: [7][ 3750/ 5005]    Overall Loss 1.277953    Objective Loss 1.277953    Top1 69.605625    Top5 87.563021    LR 0.000208    Time 0.182353    
2019-09-13 07:24:03,718 - Epoch: [7][ 3800/ 5005]    Overall Loss 1.277735    Objective Loss 1.277735    Top1 69.605572    Top5 87.567331    LR 0.000207    Time 0.182353    
2019-09-13 07:24:12,682 - Epoch: [7][ 3850/ 5005]    Overall Loss 1.277398    Objective Loss 1.277398    Top1 69.609984    Top5 87.570617    LR 0.000206    Time 0.182312    
2019-09-13 07:24:21,814 - Epoch: [7][ 3900/ 5005]    Overall Loss 1.277264    Objective Loss 1.277264    Top1 69.605669    Top5 87.574419    LR 0.000205    Time 0.182315    
2019-09-13 07:24:30,747 - Epoch: [7][ 3950/ 5005]    Overall Loss 1.277438    Objective Loss 1.277438    Top1 69.602749    Top5 87.573081    LR 0.000204    Time 0.182268    
2019-09-13 07:24:39,725 - Epoch: [7][ 4000/ 5005]    Overall Loss 1.277476    Objective Loss 1.277476    Top1 69.599121    Top5 87.576562    LR 0.000203    Time 0.182233    
2019-09-13 07:24:48,760 - Epoch: [7][ 4050/ 5005]    Overall Loss 1.277701    Objective Loss 1.277701    Top1 69.594715    Top5 87.575424    LR 0.000202    Time 0.182213    
2019-09-13 07:24:57,845 - Epoch: [7][ 4100/ 5005]    Overall Loss 1.277714    Objective Loss 1.277714    Top1 69.599085    Top5 87.575362    LR 0.000202    Time 0.182205    
2019-09-13 07:25:06,910 - Epoch: [7][ 4150/ 5005]    Overall Loss 1.277863    Objective Loss 1.277863    Top1 69.595727    Top5 87.570030    LR 0.000201    Time 0.182193    
2019-09-13 07:25:15,838 - Epoch: [7][ 4200/ 5005]    Overall Loss 1.277560    Objective Loss 1.277560    Top1 69.604911    Top5 87.576172    LR 0.000200    Time 0.182149    
2019-09-13 07:25:24,819 - Epoch: [7][ 4250/ 5005]    Overall Loss 1.277582    Objective Loss 1.277582    Top1 69.608548    Top5 87.573162    LR 0.000199    Time 0.182118    
2019-09-13 07:25:33,885 - Epoch: [7][ 4300/ 5005]    Overall Loss 1.277542    Objective Loss 1.277542    Top1 69.612282    Top5 87.570767    LR 0.000198    Time 0.182108    
2019-09-13 07:25:43,188 - Epoch: [7][ 4350/ 5005]    Overall Loss 1.277633    Objective Loss 1.277633    Top1 69.607310    Top5 87.570492    LR 0.000197    Time 0.182153    
2019-09-13 07:25:52,227 - Epoch: [7][ 4400/ 5005]    Overall Loss 1.277755    Objective Loss 1.277755    Top1 69.604048    Top5 87.568004    LR 0.000196    Time 0.182136    
2019-09-13 07:26:01,215 - Epoch: [7][ 4450/ 5005]    Overall Loss 1.277842    Objective Loss 1.277842    Top1 69.600070    Top5 87.569347    LR 0.000195    Time 0.182109    
2019-09-13 07:26:10,237 - Epoch: [7][ 4500/ 5005]    Overall Loss 1.278070    Objective Loss 1.278070    Top1 69.599219    Top5 87.567708    LR 0.000195    Time 0.182089    
2019-09-13 07:26:19,229 - Epoch: [7][ 4550/ 5005]    Overall Loss 1.278043    Objective Loss 1.278043    Top1 69.601562    Top5 87.566621    LR 0.000194    Time 0.182064    
2019-09-13 07:26:28,335 - Epoch: [7][ 4600/ 5005]    Overall Loss 1.277812    Objective Loss 1.277812    Top1 69.606743    Top5 87.565812    LR 0.000193    Time 0.182063    
2019-09-13 07:26:37,422 - Epoch: [7][ 4650/ 5005]    Overall Loss 1.277709    Objective Loss 1.277709    Top1 69.609207    Top5 87.566364    LR 0.000192    Time 0.182059    
2019-09-13 07:26:46,398 - Epoch: [7][ 4700/ 5005]    Overall Loss 1.277606    Objective Loss 1.277606    Top1 69.614611    Top5 87.566240    LR 0.000191    Time 0.182031    
2019-09-13 07:26:55,308 - Epoch: [7][ 4750/ 5005]    Overall Loss 1.277731    Objective Loss 1.277731    Top1 69.613076    Top5 87.564062    LR 0.000190    Time 0.181990    
2019-09-13 07:27:04,505 - Epoch: [7][ 4800/ 5005]    Overall Loss 1.277812    Objective Loss 1.277812    Top1 69.610840    Top5 87.564941    LR 0.000189    Time 0.182010    
2019-09-13 07:27:13,524 - Epoch: [7][ 4850/ 5005]    Overall Loss 1.278266    Objective Loss 1.278266    Top1 69.607523    Top5 87.560325    LR 0.000189    Time 0.181992    
2019-09-13 07:27:22,547 - Epoch: [7][ 4900/ 5005]    Overall Loss 1.278121    Objective Loss 1.278121    Top1 69.613520    Top5 87.561543    LR 0.000188    Time 0.181976    
2019-09-13 07:27:31,610 - Epoch: [7][ 4950/ 5005]    Overall Loss 1.277882    Objective Loss 1.277882    Top1 69.616951    Top5 87.564078    LR 0.000187    Time 0.181967    
2019-09-13 07:27:40,489 - Epoch: [7][ 5000/ 5005]    Overall Loss 1.278011    Objective Loss 1.278011    Top1 69.618438    Top5 87.566719    LR 0.000186    Time 0.181923    
2019-09-13 07:27:41,664 - 
Parameters:
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                      | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.float_weight                 | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12673 |  0.00010 |    0.07425 |
|  1 | module.conv1.weight                       | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16004 |  0.00024 |    0.09678 |
|  2 | module.layer1.0.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05219 | -0.00311 |    0.03088 |
|  3 | module.layer1.0.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08024 | -0.00446 |    0.04858 |
|  4 | module.layer1.0.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04416 | -0.00084 |    0.03127 |
|  5 | module.layer1.0.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10250 | -0.00195 |    0.07283 |
|  6 | module.layer1.1.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04967 | -0.00230 |    0.03347 |
|  7 | module.layer1.1.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08888 | -0.00413 |    0.06045 |
|  8 | module.layer1.1.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04296 | -0.00116 |    0.03077 |
|  9 | module.layer1.1.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12404 | -0.00335 |    0.08909 |
| 10 | module.layer2.0.conv1.float_weight        | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04062 | -0.00133 |    0.02872 |
| 11 | module.layer2.0.conv1.weight              | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13069 | -0.00430 |    0.09263 |
| 12 | module.layer2.0.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03322 | -0.00121 |    0.02337 |
| 13 | module.layer2.0.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08786 | -0.00322 |    0.06198 |
| 14 | module.layer2.0.downsample.0.float_weight | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06894 | -0.00255 |    0.04324 |
| 15 | module.layer2.0.downsample.0.weight       | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10520 | -0.00391 |    0.06708 |
| 16 | module.layer2.1.conv1.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03339 | -0.00144 |    0.02370 |
| 17 | module.layer2.1.conv1.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08605 | -0.00374 |    0.06125 |
| 18 | module.layer2.1.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02936 | -0.00122 |    0.02173 |
| 19 | module.layer2.1.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09424 | -0.00394 |    0.06984 |
| 20 | module.layer3.0.conv1.float_weight        | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02837 | -0.00132 |    0.02043 |
| 21 | module.layer3.0.conv1.weight              | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08242 | -0.00384 |    0.05950 |
| 22 | module.layer3.0.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02446 | -0.00075 |    0.01792 |
| 23 | module.layer3.0.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08576 | -0.00262 |    0.06292 |
| 24 | module.layer3.0.downsample.0.float_weight | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03216 | -0.00183 |    0.02320 |
| 25 | module.layer3.0.downsample.0.weight       | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12667 | -0.00721 |    0.09152 |
| 26 | module.layer3.1.conv1.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02185 | -0.00160 |    0.01627 |
| 27 | module.layer3.1.conv1.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08484 | -0.00621 |    0.06324 |
| 28 | module.layer3.1.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02020 | -0.00139 |    0.01517 |
| 29 | module.layer3.1.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07244 | -0.00497 |    0.05447 |
| 30 | module.layer4.0.conv1.float_weight        | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01942 | -0.00150 |    0.01486 |
| 31 | module.layer4.0.conv1.weight              | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06758 | -0.00523 |    0.05178 |
| 32 | module.layer4.0.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01693 | -0.00127 |    0.01308 |
| 33 | module.layer4.0.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06196 | -0.00463 |    0.04793 |
| 34 | module.layer4.0.downsample.0.float_weight | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03202 | -0.00083 |    0.02333 |
| 35 | module.layer4.0.downsample.0.weight       | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05304 | -0.00138 |    0.03881 |
| 36 | module.layer4.1.conv1.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01742 | -0.00218 |    0.01372 |
| 37 | module.layer4.1.conv1.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07967 | -0.00997 |    0.06277 |
| 38 | module.layer4.1.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01289 | -0.00009 |    0.00987 |
| 39 | module.layer4.1.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05584 | -0.00037 |    0.04280 |
| 40 | module.fc.float_weight                    | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06768 |  0.00000 |    0.04966 |
| 41 | module.fc.weight                          | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09297 | -0.00020 |    0.06865 |
| 42 | Total sparsity:                           | -                |      23357824 |       23357824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2019-09-13 07:27:41,664 - Total sparsity: 0.00

2019-09-13 07:27:41,664 - --- validate (epoch=7)-----------
2019-09-13 07:27:41,664 - 50000 samples (256 per mini-batch)
2019-09-13 07:27:53,600 - Epoch: [7][   50/  195]    Loss 0.920250    Top1 76.414062    Top5 93.523438    
2019-09-13 07:28:01,651 - Epoch: [7][  100/  195]    Loss 1.053402    Top1 74.031250    Top5 91.957031    
2019-09-13 07:28:09,541 - Epoch: [7][  150/  195]    Loss 1.196001    Top1 71.119792    Top5 89.960938    
2019-09-13 07:28:17,306 - ==> Top1: 70.106    Top5: 89.274    Loss: 1.253

2019-09-13 07:28:17,314 - ==> Best Top1: 70.106 on Epoch: 7
2019-09-13 07:28:17,314 - Saving checkpoint to: 8b_logs/res18___2019.09.13-052127/res18_checkpoint.pth.tar
2019-09-13 07:28:23,517 - Saving PACT param_value.......
2019-09-13 07:28:23,518 - The PACT Clip Parameter Value............
2019-09-13 07:28:23,525 - 

2019-09-13 07:28:23,525 - +--------------------------------+--------------+
| Layers                         |   PACT_alpha |
|--------------------------------+--------------|
| module.relu.clip_val           |      7.79267 |
| module.layer1.0.relu1.clip_val |      7.79269 |
| module.layer1.0.relu2.clip_val |      7.7927  |
| module.layer1.1.relu1.clip_val |      7.79269 |
| module.layer1.1.relu2.clip_val |      7.79272 |
| module.layer2.0.relu1.clip_val |      7.79269 |
| module.layer2.0.relu2.clip_val |      7.79269 |
| module.layer2.1.relu1.clip_val |      7.79269 |
| module.layer2.1.relu2.clip_val |      7.79278 |
| module.layer3.0.relu1.clip_val |      7.79269 |
| module.layer3.0.relu2.clip_val |      7.79269 |
| module.layer3.1.relu1.clip_val |      7.79269 |
| module.layer3.1.relu2.clip_val |      7.79274 |
| module.layer4.0.relu1.clip_val |      7.79269 |
| module.layer4.0.relu2.clip_val |      7.79283 |
| module.layer4.1.relu1.clip_val |      7.79269 |
| module.layer4.1.relu2.clip_val |      8.11448 |
+--------------------------------+--------------+
2019-09-13 07:28:23,529 - 

2019-09-13 07:28:23,529 - Training epoch: 1281167 samples (256 per mini-batch)
2019-09-13 07:28:35,826 - Epoch: [8][   50/ 5005]    Overall Loss 1.282846    Objective Loss 1.282846    Top1 69.789062    Top5 87.195312    LR 0.000185    Time 0.245843    
2019-09-13 07:28:44,755 - Epoch: [8][  100/ 5005]    Overall Loss 1.280857    Objective Loss 1.280857    Top1 69.753906    Top5 87.335938    LR 0.000184    Time 0.212182    
2019-09-13 07:28:53,703 - Epoch: [8][  150/ 5005]    Overall Loss 1.269819    Objective Loss 1.269819    Top1 69.864583    Top5 87.507812    LR 0.000183    Time 0.201081    
2019-09-13 07:29:02,639 - Epoch: [8][  200/ 5005]    Overall Loss 1.270018    Objective Loss 1.270018    Top1 69.896484    Top5 87.566406    LR 0.000183    Time 0.195473    
2019-09-13 07:29:11,597 - Epoch: [8][  250/ 5005]    Overall Loss 1.270044    Objective Loss 1.270044    Top1 69.868750    Top5 87.601562    LR 0.000182    Time 0.192199    
2019-09-13 07:29:20,587 - Epoch: [8][  300/ 5005]    Overall Loss 1.272487    Objective Loss 1.272487    Top1 69.852865    Top5 87.545573    LR 0.000181    Time 0.190121    
2019-09-13 07:29:29,544 - Epoch: [8][  350/ 5005]    Overall Loss 1.274307    Objective Loss 1.274307    Top1 69.852679    Top5 87.555804    LR 0.000180    Time 0.188543    
2019-09-13 07:29:38,450 - Epoch: [8][  400/ 5005]    Overall Loss 1.273533    Objective Loss 1.273533    Top1 69.839844    Top5 87.566406    LR 0.000179    Time 0.187234    
2019-09-13 07:29:47,416 - Epoch: [8][  450/ 5005]    Overall Loss 1.272719    Objective Loss 1.272719    Top1 69.892361    Top5 87.598958    LR 0.000179    Time 0.186348    
2019-09-13 07:29:56,519 - Epoch: [8][  500/ 5005]    Overall Loss 1.272473    Objective Loss 1.272473    Top1 69.938281    Top5 87.575781    LR 0.000178    Time 0.185913    
2019-09-13 07:30:05,350 - Epoch: [8][  550/ 5005]    Overall Loss 1.273377    Objective Loss 1.273377    Top1 69.892045    Top5 87.580256    LR 0.000177    Time 0.185062    
2019-09-13 07:30:14,325 - Epoch: [8][  600/ 5005]    Overall Loss 1.272428    Objective Loss 1.272428    Top1 69.899089    Top5 87.631510    LR 0.000176    Time 0.184592    
2019-09-13 07:30:23,317 - Epoch: [8][  650/ 5005]    Overall Loss 1.272797    Objective Loss 1.272797    Top1 69.883413    Top5 87.615385    LR 0.000175    Time 0.184221    
2019-09-13 07:30:32,312 - Epoch: [8][  700/ 5005]    Overall Loss 1.272945    Objective Loss 1.272945    Top1 69.902344    Top5 87.593750    LR 0.000175    Time 0.183909    
2019-09-13 07:30:41,262 - Epoch: [8][  750/ 5005]    Overall Loss 1.273658    Objective Loss 1.273658    Top1 69.898438    Top5 87.590625    LR 0.000174    Time 0.183576    
2019-09-13 07:30:50,390 - Epoch: [8][  800/ 5005]    Overall Loss 1.273575    Objective Loss 1.273575    Top1 69.860840    Top5 87.579102    LR 0.000173    Time 0.183509    
2019-09-13 07:30:59,412 - Epoch: [8][  850/ 5005]    Overall Loss 1.274878    Objective Loss 1.274878    Top1 69.826287    Top5 87.564338    LR 0.000172    Time 0.183324    
2019-09-13 07:31:08,353 - Epoch: [8][  900/ 5005]    Overall Loss 1.275143    Objective Loss 1.275143    Top1 69.796875    Top5 87.550781    LR 0.000172    Time 0.183070    
2019-09-13 07:31:17,443 - Epoch: [8][  950/ 5005]    Overall Loss 1.275713    Objective Loss 1.275713    Top1 69.813734    Top5 87.537418    LR 0.000171    Time 0.183001    
2019-09-13 07:31:26,387 - Epoch: [8][ 1000/ 5005]    Overall Loss 1.274388    Objective Loss 1.274388    Top1 69.827734    Top5 87.558594    LR 0.000170    Time 0.182790    
2019-09-13 07:31:35,373 - Epoch: [8][ 1050/ 5005]    Overall Loss 1.273058    Objective Loss 1.273058    Top1 69.834077    Top5 87.585193    LR 0.000169    Time 0.182640    
2019-09-13 07:31:44,288 - Epoch: [8][ 1100/ 5005]    Overall Loss 1.272986    Objective Loss 1.272986    Top1 69.839844    Top5 87.580966    LR 0.000169    Time 0.182440    
2019-09-13 07:31:53,248 - Epoch: [8][ 1150/ 5005]    Overall Loss 1.272378    Objective Loss 1.272378    Top1 69.834579    Top5 87.585258    LR 0.000168    Time 0.182297    
2019-09-13 07:32:02,232 - Epoch: [8][ 1200/ 5005]    Overall Loss 1.271617    Objective Loss 1.271617    Top1 69.848633    Top5 87.596680    LR 0.000167    Time 0.182185    
2019-09-13 07:32:11,146 - Epoch: [8][ 1250/ 5005]    Overall Loss 1.271652    Objective Loss 1.271652    Top1 69.846250    Top5 87.601562    LR 0.000166    Time 0.182026    
2019-09-13 07:32:20,074 - Epoch: [8][ 1300/ 5005]    Overall Loss 1.271940    Objective Loss 1.271940    Top1 69.819411    Top5 87.601562    LR 0.000166    Time 0.181891    
2019-09-13 07:32:28,945 - Epoch: [8][ 1350/ 5005]    Overall Loss 1.271858    Objective Loss 1.271858    Top1 69.825521    Top5 87.602141    LR 0.000165    Time 0.181722    
2019-09-13 07:32:38,000 - Epoch: [8][ 1400/ 5005]    Overall Loss 1.272683    Objective Loss 1.272683    Top1 69.803850    Top5 87.590402    LR 0.000164    Time 0.181697    
2019-09-13 07:32:47,023 - Epoch: [8][ 1450/ 5005]    Overall Loss 1.273680    Objective Loss 1.273680    Top1 69.784752    Top5 87.581627    LR 0.000163    Time 0.181652    
2019-09-13 07:32:56,189 - Epoch: [8][ 1500/ 5005]    Overall Loss 1.273448    Objective Loss 1.273448    Top1 69.786719    Top5 87.584375    LR 0.000163    Time 0.181706    
2019-09-13 07:33:05,384 - Epoch: [8][ 1550/ 5005]    Overall Loss 1.273122    Objective Loss 1.273122    Top1 69.780746    Top5 87.596270    LR 0.000162    Time 0.181774    
2019-09-13 07:33:14,398 - Epoch: [8][ 1600/ 5005]    Overall Loss 1.272894    Objective Loss 1.272894    Top1 69.798828    Top5 87.603271    LR 0.000161    Time 0.181725    
2019-09-13 07:33:23,448 - Epoch: [8][ 1650/ 5005]    Overall Loss 1.272477    Objective Loss 1.272477    Top1 69.803977    Top5 87.610795    LR 0.000161    Time 0.181700    
2019-09-13 07:33:32,494 - Epoch: [8][ 1700/ 5005]    Overall Loss 1.273229    Objective Loss 1.273229    Top1 69.799403    Top5 87.588695    LR 0.000160    Time 0.181675    
2019-09-13 07:33:41,530 - Epoch: [8][ 1750/ 5005]    Overall Loss 1.272718    Objective Loss 1.272718    Top1 69.809375    Top5 87.604018    LR 0.000159    Time 0.181646    
2019-09-13 07:33:50,576 - Epoch: [8][ 1800/ 5005]    Overall Loss 1.272289    Objective Loss 1.272289    Top1 69.812717    Top5 87.608507    LR 0.000158    Time 0.181623    
2019-09-13 07:33:59,807 - Epoch: [8][ 1850/ 5005]    Overall Loss 1.272455    Objective Loss 1.272455    Top1 69.808066    Top5 87.609797    LR 0.000158    Time 0.181702    
2019-09-13 07:34:08,880 - Epoch: [8][ 1900/ 5005]    Overall Loss 1.273080    Objective Loss 1.273080    Top1 69.809005    Top5 87.597656    LR 0.000157    Time 0.181694    
2019-09-13 07:34:17,945 - Epoch: [8][ 1950/ 5005]    Overall Loss 1.273166    Objective Loss 1.273166    Top1 69.805689    Top5 87.593750    LR 0.000156    Time 0.181682    
2019-09-13 07:34:26,966 - Epoch: [8][ 2000/ 5005]    Overall Loss 1.272728    Objective Loss 1.272728    Top1 69.808984    Top5 87.604492    LR 0.000156    Time 0.181648    
2019-09-13 07:34:36,075 - Epoch: [8][ 2050/ 5005]    Overall Loss 1.272579    Objective Loss 1.272579    Top1 69.817454    Top5 87.614710    LR 0.000155    Time 0.181658    
2019-09-13 07:34:45,183 - Epoch: [8][ 2100/ 5005]    Overall Loss 1.272842    Objective Loss 1.272842    Top1 69.809524    Top5 87.614583    LR 0.000154    Time 0.181668    
2019-09-13 07:34:54,222 - Epoch: [8][ 2150/ 5005]    Overall Loss 1.272810    Objective Loss 1.272810    Top1 69.807049    Top5 87.612827    LR 0.000154    Time 0.181646    
2019-09-13 07:35:03,184 - Epoch: [8][ 2200/ 5005]    Overall Loss 1.273231    Objective Loss 1.273231    Top1 69.807173    Top5 87.605824    LR 0.000153    Time 0.181590    
2019-09-13 07:35:12,145 - Epoch: [8][ 2250/ 5005]    Overall Loss 1.273215    Objective Loss 1.273215    Top1 69.805208    Top5 87.607292    LR 0.000152    Time 0.181535    
2019-09-13 07:35:21,029 - Epoch: [8][ 2300/ 5005]    Overall Loss 1.272721    Objective Loss 1.272721    Top1 69.813010    Top5 87.612602    LR 0.000152    Time 0.181450    
2019-09-13 07:35:30,221 - Epoch: [8][ 2350/ 5005]    Overall Loss 1.272226    Objective Loss 1.272226    Top1 69.826463    Top5 87.620013    LR 0.000151    Time 0.181499    
2019-09-13 07:35:39,031 - Epoch: [8][ 2400/ 5005]    Overall Loss 1.271980    Objective Loss 1.271980    Top1 69.829915    Top5 87.621908    LR 0.000150    Time 0.181387    
2019-09-13 07:35:47,814 - Epoch: [8][ 2450/ 5005]    Overall Loss 1.272296    Objective Loss 1.272296    Top1 69.821907    Top5 87.613361    LR 0.000150    Time 0.181269    
2019-09-13 07:35:56,607 - Epoch: [8][ 2500/ 5005]    Overall Loss 1.272406    Objective Loss 1.272406    Top1 69.818438    Top5 87.616875    LR 0.000149    Time 0.181160    
2019-09-13 07:36:05,402 - Epoch: [8][ 2550/ 5005]    Overall Loss 1.272141    Objective Loss 1.272141    Top1 69.822763    Top5 87.617647    LR 0.000148    Time 0.181055    
2019-09-13 07:36:14,236 - Epoch: [8][ 2600/ 5005]    Overall Loss 1.271892    Objective Loss 1.271892    Top1 69.823468    Top5 87.619141    LR 0.000148    Time 0.180970    
2019-09-13 07:36:23,235 - Epoch: [8][ 2650/ 5005]    Overall Loss 1.272096    Objective Loss 1.272096    Top1 69.817659    Top5 87.616745    LR 0.000147    Time 0.180950    
2019-09-13 07:36:32,136 - Epoch: [8][ 2700/ 5005]    Overall Loss 1.272074    Objective Loss 1.272074    Top1 69.814091    Top5 87.613137    LR 0.000147    Time 0.180894    
2019-09-13 07:36:41,167 - Epoch: [8][ 2750/ 5005]    Overall Loss 1.271959    Objective Loss 1.271959    Top1 69.817614    Top5 87.614773    LR 0.000146    Time 0.180888    
2019-09-13 07:36:50,302 - Epoch: [8][ 2800/ 5005]    Overall Loss 1.271902    Objective Loss 1.271902    Top1 69.822405    Top5 87.613839    LR 0.000145    Time 0.180919    
2019-09-13 07:36:59,422 - Epoch: [8][ 2850/ 5005]    Overall Loss 1.272282    Objective Loss 1.272282    Top1 69.821272    Top5 87.604989    LR 0.000145    Time 0.180944    
2019-09-13 07:37:08,474 - Epoch: [8][ 2900/ 5005]    Overall Loss 1.272424    Objective Loss 1.272424    Top1 69.808324    Top5 87.600889    LR 0.000144    Time 0.180944    
2019-09-13 07:37:17,440 - Epoch: [8][ 2950/ 5005]    Overall Loss 1.271760    Objective Loss 1.271760    Top1 69.821504    Top5 87.614010    LR 0.000143    Time 0.180915    
2019-09-13 07:37:26,485 - Epoch: [8][ 3000/ 5005]    Overall Loss 1.272306    Objective Loss 1.272306    Top1 69.814714    Top5 87.608594    LR 0.000143    Time 0.180914    
2019-09-13 07:37:35,554 - Epoch: [8][ 3050/ 5005]    Overall Loss 1.272121    Objective Loss 1.272121    Top1 69.815190    Top5 87.610656    LR 0.000142    Time 0.180920    
2019-09-13 07:37:44,639 - Epoch: [8][ 3100/ 5005]    Overall Loss 1.272286    Objective Loss 1.272286    Top1 69.800403    Top5 87.609123    LR 0.000142    Time 0.180931    
2019-09-13 07:37:53,670 - Epoch: [8][ 3150/ 5005]    Overall Loss 1.272577    Objective Loss 1.272577    Top1 69.789559    Top5 87.611235    LR 0.000141    Time 0.180925    
2019-09-13 07:38:02,632 - Epoch: [8][ 3200/ 5005]    Overall Loss 1.272383    Objective Loss 1.272383    Top1 69.795044    Top5 87.611572    LR 0.000141    Time 0.180898    
2019-09-13 07:38:11,867 - Epoch: [8][ 3250/ 5005]    Overall Loss 1.272329    Objective Loss 1.272329    Top1 69.786298    Top5 87.615865    LR 0.000140    Time 0.180955    
2019-09-13 07:38:20,864 - Epoch: [8][ 3300/ 5005]    Overall Loss 1.272179    Objective Loss 1.272179    Top1 69.788826    Top5 87.619792    LR 0.000139    Time 0.180938    
2019-09-13 07:38:30,000 - Epoch: [8][ 3350/ 5005]    Overall Loss 1.272251    Objective Loss 1.272251    Top1 69.786964    Top5 87.621618    LR 0.000139    Time 0.180964    
2019-09-13 07:38:39,099 - Epoch: [8][ 3400/ 5005]    Overall Loss 1.272295    Objective Loss 1.272295    Top1 69.789292    Top5 87.618796    LR 0.000138    Time 0.180978    
2019-09-13 07:38:48,127 - Epoch: [8][ 3450/ 5005]    Overall Loss 1.272119    Objective Loss 1.272119    Top1 69.787251    Top5 87.624774    LR 0.000138    Time 0.180970    
2019-09-13 07:38:57,115 - Epoch: [8][ 3500/ 5005]    Overall Loss 1.272357    Objective Loss 1.272357    Top1 69.779353    Top5 87.619978    LR 0.000137    Time 0.180952    
2019-09-13 07:39:06,121 - Epoch: [8][ 3550/ 5005]    Overall Loss 1.272371    Objective Loss 1.272371    Top1 69.777729    Top5 87.618728    LR 0.000137    Time 0.180939    
2019-09-13 07:39:15,284 - Epoch: [8][ 3600/ 5005]    Overall Loss 1.272224    Objective Loss 1.272224    Top1 69.778429    Top5 87.619358    LR 0.000136    Time 0.180971    
2019-09-13 07:39:24,235 - Epoch: [8][ 3650/ 5005]    Overall Loss 1.272143    Objective Loss 1.272143    Top1 69.785531    Top5 87.620826    LR 0.000135    Time 0.180943    
2019-09-13 07:39:33,324 - Epoch: [8][ 3700/ 5005]    Overall Loss 1.271681    Objective Loss 1.271681    Top1 69.793813    Top5 87.628590    LR 0.000135    Time 0.180954    
2019-09-13 07:39:42,312 - Epoch: [8][ 3750/ 5005]    Overall Loss 1.271600    Objective Loss 1.271600    Top1 69.789896    Top5 87.629583    LR 0.000134    Time 0.180937    
2019-09-13 07:39:51,356 - Epoch: [8][ 3800/ 5005]    Overall Loss 1.271612    Objective Loss 1.271612    Top1 69.785773    Top5 87.629729    LR 0.000134    Time 0.180935    
2019-09-13 07:40:00,359 - Epoch: [8][ 3850/ 5005]    Overall Loss 1.271281    Objective Loss 1.271281    Top1 69.789468    Top5 87.633624    LR 0.000133    Time 0.180922    
2019-09-13 07:40:09,335 - Epoch: [8][ 3900/ 5005]    Overall Loss 1.271293    Objective Loss 1.271293    Top1 69.786058    Top5 87.630108    LR 0.000133    Time 0.180903    
2019-09-13 07:40:18,322 - Epoch: [8][ 3950/ 5005]    Overall Loss 1.271154    Objective Loss 1.271154    Top1 69.792722    Top5 87.631824    LR 0.000132    Time 0.180888    
2019-09-13 07:40:27,285 - Epoch: [8][ 4000/ 5005]    Overall Loss 1.271555    Objective Loss 1.271555    Top1 69.792480    Top5 87.625977    LR 0.000132    Time 0.180867    
2019-09-13 07:40:36,247 - Epoch: [8][ 4050/ 5005]    Overall Loss 1.271976    Objective Loss 1.271976    Top1 69.786651    Top5 87.618248    LR 0.000131    Time 0.180846    
2019-09-13 07:40:45,236 - Epoch: [8][ 4100/ 5005]    Overall Loss 1.272039    Objective Loss 1.272039    Top1 69.788872    Top5 87.616616    LR 0.000131    Time 0.180832    
2019-09-13 07:40:54,315 - Epoch: [8][ 4150/ 5005]    Overall Loss 1.271878    Objective Loss 1.271878    Top1 69.789062    Top5 87.620482    LR 0.000130    Time 0.180840    
2019-09-13 07:41:03,360 - Epoch: [8][ 4200/ 5005]    Overall Loss 1.271592    Objective Loss 1.271592    Top1 69.792411    Top5 87.626023    LR 0.000130    Time 0.180840    
2019-09-13 07:41:12,365 - Epoch: [8][ 4250/ 5005]    Overall Loss 1.271420    Objective Loss 1.271420    Top1 69.794301    Top5 87.626287    LR 0.000129    Time 0.180831    
2019-09-13 07:41:21,335 - Epoch: [8][ 4300/ 5005]    Overall Loss 1.271316    Objective Loss 1.271316    Top1 69.796966    Top5 87.631904    LR 0.000129    Time 0.180813    
2019-09-13 07:41:30,293 - Epoch: [8][ 4350/ 5005]    Overall Loss 1.271458    Objective Loss 1.271458    Top1 69.793822    Top5 87.630568    LR 0.000128    Time 0.180794    
2019-09-13 07:41:39,260 - Epoch: [8][ 4400/ 5005]    Overall Loss 1.271556    Objective Loss 1.271556    Top1 69.792170    Top5 87.629528    LR 0.000128    Time 0.180776    
2019-09-13 07:41:48,249 - Epoch: [8][ 4450/ 5005]    Overall Loss 1.271444    Objective Loss 1.271444    Top1 69.789853    Top5 87.631408    LR 0.000127    Time 0.180764    
2019-09-13 07:41:57,321 - Epoch: [8][ 4500/ 5005]    Overall Loss 1.271559    Objective Loss 1.271559    Top1 69.791146    Top5 87.630642    LR 0.000127    Time 0.180771    
2019-09-13 07:42:06,318 - Epoch: [8][ 4550/ 5005]    Overall Loss 1.271594    Objective Loss 1.271594    Top1 69.791037    Top5 87.631353    LR 0.000126    Time 0.180761    
2019-09-13 07:42:15,360 - Epoch: [8][ 4600/ 5005]    Overall Loss 1.271411    Objective Loss 1.271411    Top1 69.796875    Top5 87.634935    LR 0.000126    Time 0.180761    
2019-09-13 07:42:24,334 - Epoch: [8][ 4650/ 5005]    Overall Loss 1.271444    Objective Loss 1.271444    Top1 69.795363    Top5 87.634745    LR 0.000125    Time 0.180747    
2019-09-13 07:42:33,297 - Epoch: [8][ 4700/ 5005]    Overall Loss 1.271331    Objective Loss 1.271331    Top1 69.796459    Top5 87.637799    LR 0.000125    Time 0.180730    
2019-09-13 07:42:42,299 - Epoch: [8][ 4750/ 5005]    Overall Loss 1.271398    Objective Loss 1.271398    Top1 69.796135    Top5 87.637911    LR 0.000124    Time 0.180722    
2019-09-13 07:42:51,289 - Epoch: [8][ 4800/ 5005]    Overall Loss 1.271516    Objective Loss 1.271516    Top1 69.791829    Top5 87.634196    LR 0.000124    Time 0.180712    
2019-09-13 07:43:00,350 - Epoch: [8][ 4850/ 5005]    Overall Loss 1.271221    Objective Loss 1.271221    Top1 69.792204    Top5 87.639014    LR 0.000123    Time 0.180717    
2019-09-13 07:43:09,345 - Epoch: [8][ 4900/ 5005]    Overall Loss 1.271175    Objective Loss 1.271175    Top1 69.793208    Top5 87.641582    LR 0.000123    Time 0.180708    
2019-09-13 07:43:18,333 - Epoch: [8][ 4950/ 5005]    Overall Loss 1.271689    Objective Loss 1.271689    Top1 69.783381    Top5 87.632181    LR 0.000123    Time 0.180697    
2019-09-13 07:43:27,116 - Epoch: [8][ 5000/ 5005]    Overall Loss 1.271793    Objective Loss 1.271793    Top1 69.783750    Top5 87.628047    LR 0.000122    Time 0.180646    
2019-09-13 07:43:28,271 - 
Parameters:
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                      | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.float_weight                 | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12664 |  0.00014 |    0.07420 |
|  1 | module.conv1.weight                       | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16003 |  0.00032 |    0.09676 |
|  2 | module.layer1.0.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05215 | -0.00310 |    0.03085 |
|  3 | module.layer1.0.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08025 | -0.00445 |    0.04859 |
|  4 | module.layer1.0.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04412 | -0.00084 |    0.03124 |
|  5 | module.layer1.0.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10255 | -0.00195 |    0.07286 |
|  6 | module.layer1.1.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04963 | -0.00229 |    0.03345 |
|  7 | module.layer1.1.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08894 | -0.00412 |    0.06050 |
|  8 | module.layer1.1.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04293 | -0.00116 |    0.03074 |
|  9 | module.layer1.1.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12415 | -0.00335 |    0.08917 |
| 10 | module.layer2.0.conv1.float_weight        | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04059 | -0.00133 |    0.02869 |
| 11 | module.layer2.0.conv1.weight              | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13087 | -0.00430 |    0.09275 |
| 12 | module.layer2.0.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03319 | -0.00122 |    0.02335 |
| 13 | module.layer2.0.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08792 | -0.00324 |    0.06203 |
| 14 | module.layer2.0.downsample.0.float_weight | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06889 | -0.00255 |    0.04321 |
| 15 | module.layer2.0.downsample.0.weight       | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10516 | -0.00387 |    0.06704 |
| 16 | module.layer2.1.conv1.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03336 | -0.00144 |    0.02368 |
| 17 | module.layer2.1.conv1.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08614 | -0.00372 |    0.06131 |
| 18 | module.layer2.1.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02934 | -0.00122 |    0.02171 |
| 19 | module.layer2.1.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09442 | -0.00394 |    0.06997 |
| 20 | module.layer3.0.conv1.float_weight        | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02835 | -0.00132 |    0.02042 |
| 21 | module.layer3.0.conv1.weight              | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08250 | -0.00384 |    0.05956 |
| 22 | module.layer3.0.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02445 | -0.00075 |    0.01791 |
| 23 | module.layer3.0.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08600 | -0.00263 |    0.06310 |
| 24 | module.layer3.0.downsample.0.float_weight | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03213 | -0.00182 |    0.02318 |
| 25 | module.layer3.0.downsample.0.weight       | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12683 | -0.00720 |    0.09164 |
| 26 | module.layer3.1.conv1.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02184 | -0.00159 |    0.01626 |
| 27 | module.layer3.1.conv1.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08493 | -0.00621 |    0.06331 |
| 28 | module.layer3.1.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02019 | -0.00139 |    0.01516 |
| 29 | module.layer3.1.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07258 | -0.00499 |    0.05457 |
| 30 | module.layer4.0.conv1.float_weight        | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01940 | -0.00150 |    0.01485 |
| 31 | module.layer4.0.conv1.weight              | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06777 | -0.00525 |    0.05193 |
| 32 | module.layer4.0.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01692 | -0.00126 |    0.01307 |
| 33 | module.layer4.0.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06223 | -0.00465 |    0.04813 |
| 34 | module.layer4.0.downsample.0.float_weight | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03199 | -0.00083 |    0.02331 |
| 35 | module.layer4.0.downsample.0.weight       | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05306 | -0.00138 |    0.03883 |
| 36 | module.layer4.1.conv1.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01741 | -0.00218 |    0.01371 |
| 37 | module.layer4.1.conv1.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07998 | -0.01001 |    0.06301 |
| 38 | module.layer4.1.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01288 | -0.00008 |    0.00986 |
| 39 | module.layer4.1.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05595 | -0.00037 |    0.04288 |
| 40 | module.fc.float_weight                    | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06763 |  0.00000 |    0.04963 |
| 41 | module.fc.weight                          | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09351 | -0.00020 |    0.06905 |
| 42 | Total sparsity:                           | -                |      23357824 |       23357824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2019-09-13 07:43:28,271 - Total sparsity: 0.00

2019-09-13 07:43:28,272 - --- validate (epoch=8)-----------
2019-09-13 07:43:28,272 - 50000 samples (256 per mini-batch)
2019-09-13 07:43:39,473 - Epoch: [8][   50/  195]    Loss 0.922516    Top1 76.078125    Top5 93.320312    
2019-09-13 07:43:47,518 - Epoch: [8][  100/  195]    Loss 1.054933    Top1 73.816406    Top5 91.828125    
2019-09-13 07:43:55,096 - Epoch: [8][  150/  195]    Loss 1.196307    Top1 70.981771    Top5 89.880208    
2019-09-13 07:44:02,540 - ==> Top1: 70.008    Top5: 89.238    Loss: 1.253

2019-09-13 07:44:02,548 - ==> Best Top1: 70.106 on Epoch: 7
2019-09-13 07:44:02,549 - Saving checkpoint to: 8b_logs/res18___2019.09.13-052127/res18_checkpoint.pth.tar
2019-09-13 07:44:05,658 - Saving PACT param_value.......
2019-09-13 07:44:05,659 - The PACT Clip Parameter Value............
2019-09-13 07:44:05,664 - 

2019-09-13 07:44:05,664 - +--------------------------------+--------------+
| Layers                         |   PACT_alpha |
|--------------------------------+--------------|
| module.relu.clip_val           |      7.78686 |
| module.layer1.0.relu1.clip_val |      7.78687 |
| module.layer1.0.relu2.clip_val |      7.78688 |
| module.layer1.1.relu1.clip_val |      7.78687 |
| module.layer1.1.relu2.clip_val |      7.7869  |
| module.layer2.0.relu1.clip_val |      7.78687 |
| module.layer2.0.relu2.clip_val |      7.78688 |
| module.layer2.1.relu1.clip_val |      7.78687 |
| module.layer2.1.relu2.clip_val |      7.78694 |
| module.layer3.0.relu1.clip_val |      7.78687 |
| module.layer3.0.relu2.clip_val |      7.78687 |
| module.layer3.1.relu1.clip_val |      7.78687 |
| module.layer3.1.relu2.clip_val |      7.78694 |
| module.layer4.0.relu1.clip_val |      7.78687 |
| module.layer4.0.relu2.clip_val |      7.78698 |
| module.layer4.1.relu1.clip_val |      7.78687 |
| module.layer4.1.relu2.clip_val |      8.11565 |
+--------------------------------+--------------+
2019-09-13 07:44:05,667 - 

2019-09-13 07:44:05,667 - Training epoch: 1281167 samples (256 per mini-batch)
2019-09-13 07:44:18,098 - Epoch: [9][   50/ 5005]    Overall Loss 1.273607    Objective Loss 1.273607    Top1 69.828125    Top5 87.890625    LR 0.000122    Time 0.248526    
2019-09-13 07:44:27,096 - Epoch: [9][  100/ 5005]    Overall Loss 1.258867    Objective Loss 1.258867    Top1 69.929688    Top5 87.781250    LR 0.000121    Time 0.214210    
2019-09-13 07:44:36,164 - Epoch: [9][  150/ 5005]    Overall Loss 1.267738    Objective Loss 1.267738    Top1 69.695312    Top5 87.549479    LR 0.000121    Time 0.203241    
2019-09-13 07:44:45,102 - Epoch: [9][  200/ 5005]    Overall Loss 1.270279    Objective Loss 1.270279    Top1 69.759766    Top5 87.529297    LR 0.000120    Time 0.197106    
2019-09-13 07:44:54,120 - Epoch: [9][  250/ 5005]    Overall Loss 1.273590    Objective Loss 1.273590    Top1 69.657813    Top5 87.517188    LR 0.000120    Time 0.193745    
2019-09-13 07:45:03,324 - Epoch: [9][  300/ 5005]    Overall Loss 1.280128    Objective Loss 1.280128    Top1 69.523438    Top5 87.455729    LR 0.000119    Time 0.192121    
2019-09-13 07:45:12,345 - Epoch: [9][  350/ 5005]    Overall Loss 1.282119    Objective Loss 1.282119    Top1 69.502232    Top5 87.405134    LR 0.000119    Time 0.190442    
2019-09-13 07:45:21,344 - Epoch: [9][  400/ 5005]    Overall Loss 1.281166    Objective Loss 1.281166    Top1 69.480469    Top5 87.438477    LR 0.000119    Time 0.189124    
2019-09-13 07:45:30,384 - Epoch: [9][  450/ 5005]    Overall Loss 1.281399    Objective Loss 1.281399    Top1 69.479167    Top5 87.393229    LR 0.000118    Time 0.188191    
2019-09-13 07:45:39,501 - Epoch: [9][  500/ 5005]    Overall Loss 1.279219    Objective Loss 1.279219    Top1 69.546094    Top5 87.428125    LR 0.000118    Time 0.187599    
2019-09-13 07:45:48,581 - Epoch: [9][  550/ 5005]    Overall Loss 1.279109    Objective Loss 1.279109    Top1 69.566761    Top5 87.455966    LR 0.000117    Time 0.187049    
2019-09-13 07:45:57,608 - Epoch: [9][  600/ 5005]    Overall Loss 1.278459    Objective Loss 1.278459    Top1 69.565104    Top5 87.503906    LR 0.000117    Time 0.186501    
2019-09-13 07:46:06,657 - Epoch: [9][  650/ 5005]    Overall Loss 1.278674    Objective Loss 1.278674    Top1 69.572716    Top5 87.503005    LR 0.000117    Time 0.186069    
2019-09-13 07:46:15,836 - Epoch: [9][  700/ 5005]    Overall Loss 1.277121    Objective Loss 1.277121    Top1 69.621094    Top5 87.527902    LR 0.000116    Time 0.185886    
2019-09-13 07:46:24,909 - Epoch: [9][  750/ 5005]    Overall Loss 1.277461    Objective Loss 1.277461    Top1 69.607812    Top5 87.515625    LR 0.000116    Time 0.185586    
2019-09-13 07:46:34,062 - Epoch: [9][  800/ 5005]    Overall Loss 1.275494    Objective Loss 1.275494    Top1 69.636719    Top5 87.564941    LR 0.000116    Time 0.185424    
2019-09-13 07:46:43,051 - Epoch: [9][  850/ 5005]    Overall Loss 1.276824    Objective Loss 1.276824    Top1 69.643842    Top5 87.523897    LR 0.000115    Time 0.185088    
2019-09-13 07:46:52,104 - Epoch: [9][  900/ 5005]    Overall Loss 1.277861    Objective Loss 1.277861    Top1 69.636285    Top5 87.513455    LR 0.000115    Time 0.184860    
2019-09-13 07:47:01,003 - Epoch: [9][  950/ 5005]    Overall Loss 1.276848    Objective Loss 1.276848    Top1 69.659128    Top5 87.545641    LR 0.000115    Time 0.184495    
2019-09-13 07:47:10,014 - Epoch: [9][ 1000/ 5005]    Overall Loss 1.276742    Objective Loss 1.276742    Top1 69.658203    Top5 87.539453    LR 0.000114    Time 0.184278    
2019-09-13 07:47:19,105 - Epoch: [9][ 1050/ 5005]    Overall Loss 1.275724    Objective Loss 1.275724    Top1 69.686012    Top5 87.550967    LR 0.000114    Time 0.184158    
2019-09-13 07:47:28,201 - Epoch: [9][ 1100/ 5005]    Overall Loss 1.273778    Objective Loss 1.273778    Top1 69.721946    Top5 87.581321    LR 0.000113    Time 0.184053    
2019-09-13 07:47:37,229 - Epoch: [9][ 1150/ 5005]    Overall Loss 1.273976    Objective Loss 1.273976    Top1 69.700408    Top5 87.589674    LR 0.000113    Time 0.183899    
2019-09-13 07:47:46,309 - Epoch: [9][ 1200/ 5005]    Overall Loss 1.274159    Objective Loss 1.274159    Top1 69.694661    Top5 87.591797    LR 0.000113    Time 0.183800    
2019-09-13 07:47:55,399 - Epoch: [9][ 1250/ 5005]    Overall Loss 1.273147    Objective Loss 1.273147    Top1 69.708750    Top5 87.603437    LR 0.000112    Time 0.183718    
2019-09-13 07:48:04,388 - Epoch: [9][ 1300/ 5005]    Overall Loss 1.272915    Objective Loss 1.272915    Top1 69.715445    Top5 87.595853    LR 0.000112    Time 0.183564    
2019-09-13 07:48:13,366 - Epoch: [9][ 1350/ 5005]    Overall Loss 1.272414    Objective Loss 1.272414    Top1 69.738715    Top5 87.605035    LR 0.000112    Time 0.183413    
2019-09-13 07:48:22,333 - Epoch: [9][ 1400/ 5005]    Overall Loss 1.271555    Objective Loss 1.271555    Top1 69.751953    Top5 87.614397    LR 0.000111    Time 0.183265    
2019-09-13 07:48:31,340 - Epoch: [9][ 1450/ 5005]    Overall Loss 1.271406    Objective Loss 1.271406    Top1 69.760237    Top5 87.610183    LR 0.000111    Time 0.183155    
2019-09-13 07:48:40,413 - Epoch: [9][ 1500/ 5005]    Overall Loss 1.269747    Objective Loss 1.269747    Top1 69.790365    Top5 87.630469    LR 0.000111    Time 0.183097    
2019-09-13 07:48:49,734 - Epoch: [9][ 1550/ 5005]    Overall Loss 1.269540    Objective Loss 1.269540    Top1 69.795363    Top5 87.638105    LR 0.000111    Time 0.183202    
2019-09-13 07:48:59,255 - Epoch: [9][ 1600/ 5005]    Overall Loss 1.269591    Objective Loss 1.269591    Top1 69.788086    Top5 87.634766    LR 0.000110    Time 0.183425    
2019-09-13 07:49:08,825 - Epoch: [9][ 1650/ 5005]    Overall Loss 1.269572    Objective Loss 1.269572    Top1 69.795218    Top5 87.633523    LR 0.000110    Time 0.183664    
2019-09-13 07:49:18,275 - Epoch: [9][ 1700/ 5005]    Overall Loss 1.268556    Objective Loss 1.268556    Top1 69.802390    Top5 87.653493    LR 0.000110    Time 0.183819    
2019-09-13 07:49:29,599 - Epoch: [9][ 1750/ 5005]    Overall Loss 1.269413    Objective Loss 1.269413    Top1 69.780804    Top5 87.638839    LR 0.000109    Time 0.185036    
2019-09-13 07:49:39,074 - Epoch: [9][ 1800/ 5005]    Overall Loss 1.269120    Objective Loss 1.269120    Top1 69.796658    Top5 87.644965    LR 0.000109    Time 0.185158    
2019-09-13 07:49:48,118 - Epoch: [9][ 1850/ 5005]    Overall Loss 1.268980    Objective Loss 1.268980    Top1 69.806588    Top5 87.647382    LR 0.000109    Time 0.185041    
2019-09-13 07:49:57,128 - Epoch: [9][ 1900/ 5005]    Overall Loss 1.268306    Objective Loss 1.268306    Top1 69.810444    Top5 87.650905    LR 0.000109    Time 0.184912    
2019-09-13 07:50:06,154 - Epoch: [9][ 1950/ 5005]    Overall Loss 1.267583    Objective Loss 1.267583    Top1 69.825321    Top5 87.661458    LR 0.000108    Time 0.184797    
2019-09-13 07:50:15,147 - Epoch: [9][ 2000/ 5005]    Overall Loss 1.268007    Objective Loss 1.268007    Top1 69.825000    Top5 87.648438    LR 0.000108    Time 0.184672    
2019-09-13 07:50:24,096 - Epoch: [9][ 2050/ 5005]    Overall Loss 1.267536    Objective Loss 1.267536    Top1 69.827934    Top5 87.651105    LR 0.000108    Time 0.184531    
2019-09-13 07:50:33,182 - Epoch: [9][ 2100/ 5005]    Overall Loss 1.266468    Objective Loss 1.266468    Top1 69.849702    Top5 87.665179    LR 0.000107    Time 0.184462    
2019-09-13 07:50:42,375 - Epoch: [9][ 2150/ 5005]    Overall Loss 1.266954    Objective Loss 1.266954    Top1 69.842115    Top5 87.660429    LR 0.000107    Time 0.184446    
2019-09-13 07:50:51,514 - Epoch: [9][ 2200/ 5005]    Overall Loss 1.267031    Objective Loss 1.267031    Top1 69.842152    Top5 87.662464    LR 0.000107    Time 0.184407    
2019-09-13 07:51:00,642 - Epoch: [9][ 2250/ 5005]    Overall Loss 1.267119    Objective Loss 1.267119    Top1 69.843403    Top5 87.664757    LR 0.000107    Time 0.184364    
2019-09-13 07:51:09,741 - Epoch: [9][ 2300/ 5005]    Overall Loss 1.266602    Objective Loss 1.266602    Top1 69.859885    Top5 87.669158    LR 0.000106    Time 0.184310    
2019-09-13 07:51:18,842 - Epoch: [9][ 2350/ 5005]    Overall Loss 1.266491    Objective Loss 1.266491    Top1 69.853890    Top5 87.668052    LR 0.000106    Time 0.184260    
2019-09-13 07:51:27,845 - Epoch: [9][ 2400/ 5005]    Overall Loss 1.266225    Objective Loss 1.266225    Top1 69.847493    Top5 87.666829    LR 0.000106    Time 0.184171    
2019-09-13 07:51:36,761 - Epoch: [9][ 2450/ 5005]    Overall Loss 1.267013    Objective Loss 1.267013    Top1 69.847736    Top5 87.657366    LR 0.000106    Time 0.184051    
2019-09-13 07:51:45,793 - Epoch: [9][ 2500/ 5005]    Overall Loss 1.266921    Objective Loss 1.266921    Top1 69.847969    Top5 87.657969    LR 0.000106    Time 0.183981    
2019-09-13 07:51:54,908 - Epoch: [9][ 2550/ 5005]    Overall Loss 1.266962    Objective Loss 1.266962    Top1 69.844669    Top5 87.660539    LR 0.000105    Time 0.183947    
2019-09-13 07:52:04,012 - Epoch: [9][ 2600/ 5005]    Overall Loss 1.267881    Objective Loss 1.267881    Top1 69.831130    Top5 87.652945    LR 0.000105    Time 0.183909    
2019-09-13 07:52:12,969 - Epoch: [9][ 2650/ 5005]    Overall Loss 1.267959    Objective Loss 1.267959    Top1 69.833432    Top5 87.650943    LR 0.000105    Time 0.183818    
2019-09-13 07:52:22,006 - Epoch: [9][ 2700/ 5005]    Overall Loss 1.268211    Objective Loss 1.268211    Top1 69.828270    Top5 87.645399    LR 0.000105    Time 0.183760    
2019-09-13 07:52:31,061 - Epoch: [9][ 2750/ 5005]    Overall Loss 1.267762    Objective Loss 1.267762    Top1 69.835369    Top5 87.649858    LR 0.000105    Time 0.183711    
2019-09-13 07:52:40,088 - Epoch: [9][ 2800/ 5005]    Overall Loss 1.267792    Objective Loss 1.267792    Top1 69.833287    Top5 87.648298    LR 0.000104    Time 0.183653    
2019-09-13 07:52:49,214 - Epoch: [9][ 2850/ 5005]    Overall Loss 1.268199    Objective Loss 1.268199    Top1 69.816749    Top5 87.646245    LR 0.000104    Time 0.183632    
2019-09-13 07:52:58,370 - Epoch: [9][ 2900/ 5005]    Overall Loss 1.268145    Objective Loss 1.268145    Top1 69.815733    Top5 87.647360    LR 0.000104    Time 0.183622    
2019-09-13 07:53:07,351 - Epoch: [9][ 2950/ 5005]    Overall Loss 1.268533    Objective Loss 1.268533    Top1 69.802304    Top5 87.647378    LR 0.000104    Time 0.183553    
2019-09-13 07:53:16,276 - Epoch: [9][ 3000/ 5005]    Overall Loss 1.268620    Objective Loss 1.268620    Top1 69.810417    Top5 87.645052    LR 0.000104    Time 0.183467    
2019-09-13 07:53:25,459 - Epoch: [9][ 3050/ 5005]    Overall Loss 1.268523    Objective Loss 1.268523    Top1 69.811347    Top5 87.649718    LR 0.000103    Time 0.183470    
2019-09-13 07:53:34,483 - Epoch: [9][ 3100/ 5005]    Overall Loss 1.268721    Objective Loss 1.268721    Top1 69.812626    Top5 87.639239    LR 0.000103    Time 0.183420    
2019-09-13 07:53:43,539 - Epoch: [9][ 3150/ 5005]    Overall Loss 1.268716    Objective Loss 1.268716    Top1 69.811136    Top5 87.639509    LR 0.000103    Time 0.183383    
2019-09-13 07:53:52,545 - Epoch: [9][ 3200/ 5005]    Overall Loss 1.269170    Objective Loss 1.269170    Top1 69.804443    Top5 87.633667    LR 0.000103    Time 0.183331    
2019-09-13 07:54:01,607 - Epoch: [9][ 3250/ 5005]    Overall Loss 1.269006    Objective Loss 1.269006    Top1 69.809736    Top5 87.637260    LR 0.000103    Time 0.183298    
2019-09-13 07:54:10,551 - Epoch: [9][ 3300/ 5005]    Overall Loss 1.268760    Objective Loss 1.268760    Top1 69.821259    Top5 87.639323    LR 0.000103    Time 0.183230    
2019-09-13 07:54:19,637 - Epoch: [9][ 3350/ 5005]    Overall Loss 1.268745    Objective Loss 1.268745    Top1 69.813433    Top5 87.646105    LR 0.000102    Time 0.183206    
2019-09-13 07:54:28,498 - Epoch: [9][ 3400/ 5005]    Overall Loss 1.268552    Objective Loss 1.268552    Top1 69.813419    Top5 87.650161    LR 0.000102    Time 0.183117    
2019-09-13 07:54:37,517 - Epoch: [9][ 3450/ 5005]    Overall Loss 1.268269    Objective Loss 1.268269    Top1 69.815897    Top5 87.656476    LR 0.000102    Time 0.183076    
2019-09-13 07:54:46,564 - Epoch: [9][ 3500/ 5005]    Overall Loss 1.268078    Objective Loss 1.268078    Top1 69.818750    Top5 87.659040    LR 0.000102    Time 0.183045    
2019-09-13 07:54:55,601 - Epoch: [9][ 3550/ 5005]    Overall Loss 1.267852    Objective Loss 1.267852    Top1 69.821743    Top5 87.663512    LR 0.000102    Time 0.183011    
2019-09-13 07:55:04,571 - Epoch: [9][ 3600/ 5005]    Overall Loss 1.267997    Objective Loss 1.267997    Top1 69.819661    Top5 87.660156    LR 0.000102    Time 0.182960    
2019-09-13 07:55:13,602 - Epoch: [9][ 3650/ 5005]    Overall Loss 1.267871    Objective Loss 1.267871    Top1 69.817423    Top5 87.661494    LR 0.000102    Time 0.182927    
2019-09-13 07:55:22,576 - Epoch: [9][ 3700/ 5005]    Overall Loss 1.268121    Objective Loss 1.268121    Top1 69.812078    Top5 87.656778    LR 0.000102    Time 0.182880    
2019-09-13 07:55:31,536 - Epoch: [9][ 3750/ 5005]    Overall Loss 1.268293    Objective Loss 1.268293    Top1 69.809063    Top5 87.653437    LR 0.000101    Time 0.182830    
2019-09-13 07:55:40,499 - Epoch: [9][ 3800/ 5005]    Overall Loss 1.268095    Objective Loss 1.268095    Top1 69.810855    Top5 87.655016    LR 0.000101    Time 0.182781    
2019-09-13 07:55:49,523 - Epoch: [9][ 3850/ 5005]    Overall Loss 1.267828    Objective Loss 1.267828    Top1 69.814326    Top5 87.657873    LR 0.000101    Time 0.182751    
2019-09-13 07:55:58,655 - Epoch: [9][ 3900/ 5005]    Overall Loss 1.267566    Objective Loss 1.267566    Top1 69.819311    Top5 87.664864    LR 0.000101    Time 0.182748    
2019-09-13 07:56:07,622 - Epoch: [9][ 3950/ 5005]    Overall Loss 1.267631    Objective Loss 1.267631    Top1 69.819225    Top5 87.664854    LR 0.000101    Time 0.182704    
2019-09-13 07:56:16,883 - Epoch: [9][ 4000/ 5005]    Overall Loss 1.267646    Objective Loss 1.267646    Top1 69.817480    Top5 87.666504    LR 0.000101    Time 0.182735    
2019-09-13 07:56:25,868 - Epoch: [9][ 4050/ 5005]    Overall Loss 1.267811    Objective Loss 1.267811    Top1 69.817130    Top5 87.666088    LR 0.000101    Time 0.182696    
2019-09-13 07:56:34,902 - Epoch: [9][ 4100/ 5005]    Overall Loss 1.267667    Objective Loss 1.267667    Top1 69.819836    Top5 87.668921    LR 0.000101    Time 0.182671    
2019-09-13 07:56:43,983 - Epoch: [9][ 4150/ 5005]    Overall Loss 1.268017    Objective Loss 1.268017    Top1 69.809959    Top5 87.664816    LR 0.000101    Time 0.182657    
2019-09-13 07:56:52,980 - Epoch: [9][ 4200/ 5005]    Overall Loss 1.267979    Objective Loss 1.267979    Top1 69.814546    Top5 87.665830    LR 0.000101    Time 0.182624    
2019-09-13 07:57:01,989 - Epoch: [9][ 4250/ 5005]    Overall Loss 1.267802    Objective Loss 1.267802    Top1 69.815993    Top5 87.668199    LR 0.000101    Time 0.182594    
2019-09-13 07:57:11,145 - Epoch: [9][ 4300/ 5005]    Overall Loss 1.267834    Objective Loss 1.267834    Top1 69.815316    Top5 87.667333    LR 0.000100    Time 0.182599    
2019-09-13 07:57:20,207 - Epoch: [9][ 4350/ 5005]    Overall Loss 1.267657    Objective Loss 1.267657    Top1 69.818517    Top5 87.668912    LR 0.000100    Time 0.182583    
2019-09-13 07:57:29,153 - Epoch: [9][ 4400/ 5005]    Overall Loss 1.267582    Objective Loss 1.267582    Top1 69.819869    Top5 87.671609    LR 0.000100    Time 0.182540    
2019-09-13 07:57:38,415 - Epoch: [9][ 4450/ 5005]    Overall Loss 1.267384    Objective Loss 1.267384    Top1 69.825667    Top5 87.675123    LR 0.000100    Time 0.182570    
2019-09-13 07:57:47,433 - Epoch: [9][ 4500/ 5005]    Overall Loss 1.267554    Objective Loss 1.267554    Top1 69.821788    Top5 87.674306    LR 0.000100    Time 0.182544    
2019-09-13 07:57:56,409 - Epoch: [9][ 4550/ 5005]    Overall Loss 1.267335    Objective Loss 1.267335    Top1 69.821858    Top5 87.678400    LR 0.000100    Time 0.182510    
2019-09-13 07:58:05,491 - Epoch: [9][ 4600/ 5005]    Overall Loss 1.267569    Objective Loss 1.267569    Top1 69.815387    Top5 87.675357    LR 0.000100    Time 0.182500    
2019-09-13 07:58:14,593 - Epoch: [9][ 4650/ 5005]    Overall Loss 1.267846    Objective Loss 1.267846    Top1 69.806704    Top5 87.671623    LR 0.000100    Time 0.182494    
2019-09-13 07:58:23,634 - Epoch: [9][ 4700/ 5005]    Overall Loss 1.268139    Objective Loss 1.268139    Top1 69.802277    Top5 87.664561    LR 0.000100    Time 0.182476    
2019-09-13 07:58:32,611 - Epoch: [9][ 4750/ 5005]    Overall Loss 1.268282    Objective Loss 1.268282    Top1 69.804852    Top5 87.661513    LR 0.000100    Time 0.182444    
2019-09-13 07:58:41,676 - Epoch: [9][ 4800/ 5005]    Overall Loss 1.268540    Objective Loss 1.268540    Top1 69.796794    Top5 87.657145    LR 0.000100    Time 0.182431    
2019-09-13 07:58:50,733 - Epoch: [9][ 4850/ 5005]    Overall Loss 1.268757    Objective Loss 1.268757    Top1 69.790110    Top5 87.651659    LR 0.000100    Time 0.182417    
2019-09-13 07:59:00,037 - Epoch: [9][ 4900/ 5005]    Overall Loss 1.268698    Objective Loss 1.268698    Top1 69.792172    Top5 87.652742    LR 0.000100    Time 0.182453    
2019-09-13 07:59:09,008 - Epoch: [9][ 4950/ 5005]    Overall Loss 1.269059    Objective Loss 1.269059    Top1 69.788826    Top5 87.650016    LR 0.000100    Time 0.182422    
2019-09-13 07:59:17,901 - Epoch: [9][ 5000/ 5005]    Overall Loss 1.268986    Objective Loss 1.268986    Top1 69.788984    Top5 87.651016    LR 0.000100    Time 0.182376    
2019-09-13 07:59:19,082 - 
Parameters:
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                      | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.float_weight                 | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12657 |  0.00012 |    0.07416 |
|  1 | module.conv1.weight                       | (64, 3, 7, 7)    |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16000 |  0.00029 |    0.09676 |
|  2 | module.layer1.0.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05212 | -0.00311 |    0.03084 |
|  3 | module.layer1.0.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08024 | -0.00445 |    0.04858 |
|  4 | module.layer1.0.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04410 | -0.00084 |    0.03123 |
|  5 | module.layer1.0.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10261 | -0.00194 |    0.07290 |
|  6 | module.layer1.1.conv1.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04961 | -0.00229 |    0.03343 |
|  7 | module.layer1.1.conv1.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08892 | -0.00411 |    0.06048 |
|  8 | module.layer1.1.conv2.float_weight        | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04290 | -0.00116 |    0.03073 |
|  9 | module.layer1.1.conv2.weight              | (64, 64, 3, 3)   |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12420 | -0.00336 |    0.08921 |
| 10 | module.layer2.0.conv1.float_weight        | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04057 | -0.00133 |    0.02868 |
| 11 | module.layer2.0.conv1.weight              | (128, 64, 3, 3)  |         73728 |          73728 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13091 | -0.00429 |    0.09278 |
| 12 | module.layer2.0.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03318 | -0.00121 |    0.02334 |
| 13 | module.layer2.0.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08794 | -0.00324 |    0.06204 |
| 14 | module.layer2.0.downsample.0.float_weight | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06885 | -0.00254 |    0.04319 |
| 15 | module.layer2.0.downsample.0.weight       | (128, 64, 1, 1)  |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10512 | -0.00389 |    0.06704 |
| 16 | module.layer2.1.conv1.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03334 | -0.00144 |    0.02367 |
| 17 | module.layer2.1.conv1.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08618 | -0.00372 |    0.06134 |
| 18 | module.layer2.1.conv2.float_weight        | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02932 | -0.00122 |    0.02170 |
| 19 | module.layer2.1.conv2.weight              | (128, 128, 3, 3) |        147456 |         147456 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09450 | -0.00395 |    0.07004 |
| 20 | module.layer3.0.conv1.float_weight        | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02833 | -0.00132 |    0.02041 |
| 21 | module.layer3.0.conv1.weight              | (256, 128, 3, 3) |        294912 |         294912 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08254 | -0.00384 |    0.05958 |
| 22 | module.layer3.0.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02443 | -0.00074 |    0.01790 |
| 23 | module.layer3.0.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08611 | -0.00263 |    0.06318 |
| 24 | module.layer3.0.downsample.0.float_weight | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03212 | -0.00183 |    0.02317 |
| 25 | module.layer3.0.downsample.0.weight       | (256, 128, 1, 1) |         32768 |          32768 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12690 | -0.00724 |    0.09168 |
| 26 | module.layer3.1.conv1.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02183 | -0.00159 |    0.01625 |
| 27 | module.layer3.1.conv1.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08504 | -0.00622 |    0.06338 |
| 28 | module.layer3.1.conv2.float_weight        | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02018 | -0.00138 |    0.01515 |
| 29 | module.layer3.1.conv2.weight              | (256, 256, 3, 3) |        589824 |         589824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07273 | -0.00500 |    0.05469 |
| 30 | module.layer4.0.conv1.float_weight        | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01939 | -0.00150 |    0.01484 |
| 31 | module.layer4.0.conv1.weight              | (512, 256, 3, 3) |       1179648 |        1179648 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06797 | -0.00526 |    0.05208 |
| 32 | module.layer4.0.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01691 | -0.00126 |    0.01306 |
| 33 | module.layer4.0.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06244 | -0.00466 |    0.04829 |
| 34 | module.layer4.0.downsample.0.float_weight | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03197 | -0.00083 |    0.02330 |
| 35 | module.layer4.0.downsample.0.weight       | (512, 256, 1, 1) |        131072 |         131072 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05308 | -0.00138 |    0.03884 |
| 36 | module.layer4.1.conv1.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01740 | -0.00218 |    0.01370 |
| 37 | module.layer4.1.conv1.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08021 | -0.01003 |    0.06319 |
| 38 | module.layer4.1.conv2.float_weight        | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01288 | -0.00008 |    0.00986 |
| 39 | module.layer4.1.conv2.weight              | (512, 512, 3, 3) |       2359296 |        2359296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05600 | -0.00037 |    0.04292 |
| 40 | module.fc.float_weight                    | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06760 |  0.00000 |    0.04960 |
| 41 | module.fc.weight                          | (1000, 512)      |        512000 |         512000 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09377 | -0.00020 |    0.06925 |
| 42 | Total sparsity:                           | -                |      23357824 |       23357824 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2019-09-13 07:59:19,083 - Total sparsity: 0.00

2019-09-13 07:59:19,083 - --- validate (epoch=9)-----------
2019-09-13 07:59:19,083 - 50000 samples (256 per mini-batch)
2019-09-13 07:59:30,256 - Epoch: [9][   50/  195]    Loss 0.917869    Top1 76.312500    Top5 93.507812    
2019-09-13 07:59:38,183 - Epoch: [9][  100/  195]    Loss 1.050477    Top1 73.960938    Top5 91.957031    
2019-09-13 07:59:46,544 - Epoch: [9][  150/  195]    Loss 1.192539    Top1 71.052083    Top5 90.013021    
2019-09-13 07:59:54,129 - ==> Top1: 70.072    Top5: 89.342    Loss: 1.250

2019-09-13 07:59:54,139 - ==> Best Top1: 70.106 on Epoch: 7
2019-09-13 07:59:54,140 - Saving checkpoint to: 8b_logs/res18___2019.09.13-052127/res18_checkpoint.pth.tar
2019-09-13 07:59:57,419 - Saving PACT param_value.......
2019-09-13 07:59:57,420 - The PACT Clip Parameter Value............
2019-09-13 07:59:57,425 - 

2019-09-13 07:59:57,425 - +--------------------------------+--------------+
| Layers                         |   PACT_alpha |
|--------------------------------+--------------|
| module.relu.clip_val           |      7.78208 |
| module.layer1.0.relu1.clip_val |      7.7821  |
| module.layer1.0.relu2.clip_val |      7.7821  |
| module.layer1.1.relu1.clip_val |      7.7821  |
| module.layer1.1.relu2.clip_val |      7.78213 |
| module.layer2.0.relu1.clip_val |      7.7821  |
| module.layer2.0.relu2.clip_val |      7.78211 |
| module.layer2.1.relu1.clip_val |      7.7821  |
| module.layer2.1.relu2.clip_val |      7.78216 |
| module.layer3.0.relu1.clip_val |      7.7821  |
| module.layer3.0.relu2.clip_val |      7.7821  |
| module.layer3.1.relu1.clip_val |      7.7821  |
| module.layer3.1.relu2.clip_val |      7.78217 |
| module.layer4.0.relu1.clip_val |      7.7821  |
| module.layer4.0.relu2.clip_val |      7.78221 |
| module.layer4.1.relu1.clip_val |      7.7821  |
| module.layer4.1.relu2.clip_val |      8.11655 |
+--------------------------------+--------------+
2019-09-13 07:59:57,839 - 
2019-09-13 07:59:57,840 - Log file for this run: /home/mdl/mzk591/var/resnet8b_training/res18/examples/classifier_compression/8b_logs/res18___2019.09.13-052127/res18___2019.09.13-052127.log
