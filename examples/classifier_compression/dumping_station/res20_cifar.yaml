quantizers:
  pact_quantizer:
    class: PACTQuantizer
    bits_activations: 8
    bits_weights: 8
    bits_overrides:
      conv1:
        wts: 8
        acts: 8
      relu:
        wts: 8
        acts: 8
      layer1.0.conv1:
        wts: 8
        acts: 8
      layer1.0.relu1:
        wts: 8
        acts: 8
      layer1.0.conv2:
        wts: 8
        acts: 8
      layer1.0.relu2:
        wts: 8
        acts: 8
      layer1.1.conv1:
        wts: 8
        acts: 8
      layer1.1.relu1:
        wts: 8
        acts: 8
      layer1.1.conv2:
        wts: 8
        acts: 8
      layer1.1.relu2:
        wts: 8
        acts: 8
      layer1.2.conv1:
        wts: 8
        acts: 8
      layer1.2.relu1:
        wts: 8
        acts: 8
      layer1.2.conv2:
        wts: 8
        acts: 8
      layer1.2.relu2:
        wts: 8
        acts: 8
      layer2.0.conv1:
        wts: 8
        acts: 8
      layer2.0.relu1:
        wts: 8
        acts: 8
      layer2.0.conv2:
        wts: 8
        acts: 8
      layer2.0.relu2:
        wts: 8
        acts: 8
      layer2.0.downsample.0:
        wts: 8
        acts: 8
      layer2.1.conv1:
        wts: 8
        acts: 8
      layer2.1.relu1:
        wts: 8
        acts: 8
      layer2.1.conv2:
        wts: 8
        acts: 8
      layer2.1.relu2:
        wts: 8
        acts: 8
      layer2.2.conv1:
        wts: 8
        acts: 8
      layer2.2.relu1:
        wts: 8
        acts: 8
      layer2.2.conv2:
        wts: 8
        acts: 8
      layer2.2.relu2:
        wts: 8
        acts: 8
      layer3.0.conv1:
        wts: 8
        acts: 8
      layer3.0.relu1:
        wts: 8
        acts: 8
      layer3.0.conv2:
        wts: 8
        acts: 8
      layer3.0.relu2:
        wts: 8
        acts: 8
      layer3.0.downsample.0:
        wts: 8
        acts: 8
      layer3.1.conv1:
        wts: 8
        acts: 8
      layer3.1.relu1:
        wts: 8
        acts: 8
      layer3.1.conv2:
        wts: 8
        acts: 8
      layer3.1.relu2:
        wts: 8
        acts: 8
      layer3.2.conv1:
        wts: 8
        acts: 8
      layer3.2.relu1:
        wts: 8
        acts: 8
      layer3.2.conv2:
        wts: 8
        acts: 8
      layer3.2.relu2:
        wts: 8
        acts: 8
      fc:
        wts: 8
        acts: 8
lr_schedulers:
  training_lr:
    class: StepLR
    step_size: 3
    gamma: 0.2
policies:
- quantizer:
    instance_name: pact_quantizer
  starting_epoch: 0
  ending_epoch: 800
  frequency: 1
- lr_scheduler:
    instance_name: training_lr
  starting_epoch: 0
  ending_epoch: 800
  frequency: 1
