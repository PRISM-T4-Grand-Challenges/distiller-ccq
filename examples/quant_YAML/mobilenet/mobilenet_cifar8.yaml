quantizers:
  wrpn_quantizer:
    class: WRPNQuantizer
    bits_activations: 8
    bits_weights: 8
    bits_overrides:
    # Don't quantize first and last layer
       conv1: #conv1
        wts: 8
        acts: 8
      # 'layers.0.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.0.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.1.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.1.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.2.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.2.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.3.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.3.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.4.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.4.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.5.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.5.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.6.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.6.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.7.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.7.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.8.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.8.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.9.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.9.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.10.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.10.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.11.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.11.conv2': #Pointwise conv
        # wts: null
        # acts: null
      # 'layers.12.conv1': #Depthwise conv
        # wts: null
        # acts: null
      # 'layers.12.conv2': #Pointwise conv
        # wts: null
        # acts: null
       linear: #fc_softmax
        wts: 8
        acts: 8

lr_schedulers:
  training_lr1:
    class: MultiStepLR
    milestones: [40, 60, 80, 100, 120, 140]
    gamma: 0.5
  training_lr2:
    class: StepLR
    step_size: 2
    gamma: 0.74
    
policies:  
    - quantizer:
        instance_name: wrpn_quantizer
      starting_epoch: 0
      ending_epoch: 200
      frequency: 1
    - lr_scheduler:
        instance_name: training_lr2
      starting_epoch: 0
      ending_epoch: 161
      frequency: 1