quantizers:
  wrpn_quantizer:
    class: WRPNQuantizer
    bits_activations: 8
    bits_weights: 8
    bits_overrides:
    # Don't quantize first and last layer
      # model.0.0: #conv1
        # wts: 4
        # acts: 4
      # model.1.0: #Depthwise conv
        # wts: 4
        # acts: 4
      model.1.3: #Pointwise conv
        wts: 4
        acts: 4
      # model.2.0: #Depthwise conv
        # wts: 4
        # acts: 4
      model.2.3: #Pointwise conv
        wts: 4
        acts: 4
      # model.3.0: #Depthwise conv
        # wts: 4
        # acts: 4
      model.3.3: #Pointwise conv
        wts: 4
        acts: 4
      # model.4.0: #Depthwise conv
        # wts: 4
        # acts: 4
      # model.4.3: #Pointwise conv
        # wts: 4
        # acts: 4
      # model.5.0: #Depthwise conv
        # wts: 4
        # acts: 4
      # model.5.3: #Pointwise conv
        # wts: 4
        # acts: 4
      # model.6.0: #Depthwise conv
        # wts: 4
        # acts: 4
      model.6.3: #Pointwise conv
        wts: 4
        acts: 4
      # model.7.0: #Depthwise conv
        # wts: 4
        # acts: 4
      # model.7.3: #Pointwise conv
         # wts: 4
         # acts: 4
      # model.8.0: #Depthwise conv
        # wts: 4
        # acts: 4
      # model.8.3: #Pointwise conv
        # wts: 4
        # acts: 4
      # model.9.0: #Depthwise conv
        # wts: 4
        # acts: 4
      # model.9.3: #Pointwise conv
        # wts: 4
        # acts: 4
      # model.10.0: #Depthwise conv
        # wts: 4
        # acts: 4 
      # model.10.3: #Pointwise conv
        # wts: 4
        # acts: 4
      model.11.0: #Depthwise conv
        wts: 4
        acts: 4
      # model.11.3: #Pointwise conv
        # wts: 4
        # acts: 4
      # model.12.0: #Depthwise conv
        # wts: 4
        # acts: 4
      model.12.3: #Pointwise conv
        wts: 4
        acts: 4
      # model.13.0: #Depthwise conv
        # wts: 2
        # acts: 2
      model.13.3: #Pointwise conv
        wts: 4
        acts: 4
      # fc: #fc_softmax
        # wts: 8
        # acts: 8

lr_schedulers:
  training_lr:
    class: StepLR
    step_size: 2
    gamma: 0.22
    
policies:  
    - quantizer:
        instance_name: wrpn_quantizer
      starting_epoch: 0
      ending_epoch: 200
      frequency: 1
    - lr_scheduler:
        instance_name: training_lr
      starting_epoch: 0
      ending_epoch: 141
      frequency: 1